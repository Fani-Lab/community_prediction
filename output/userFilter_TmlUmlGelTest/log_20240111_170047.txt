Running pipeline for LDA and RecurrentGCN ....
1. Data Reading & Preparation ...
##################################################
Loading perprocessed files ...
documents.shape: (4566, 6)
2. Topic modeling ...
##################################################
Loading LDA model ...
loading Dictionary object from ../output/19/LDA.RecurrentGCN/tml/gensim_30topics_TopicModelingDictionary.mm
{'uri': '../output/19/LDA.RecurrentGCN/tml/gensim_30topics_TopicModelingDictionary.mm', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
Loading LDA model failed! Training LDA model ...
TopicModeling: num_topics=30,  filterExtremes=True, library=gensim
adding document #0 to Dictionary<0 unique tokens: []>
built Dictionary<64523 unique tokens: ['broadband', 'door', 'fcc', 'impact', 'long']...> from 4566 documents (total 503640 corpus positions)
starting a new internal lifecycle event log for Dictionary
Dictionary lifecycle event {'msg': "built Dictionary<64523 unique tokens: ['broadband', 'door', 'fcc', 'impact', 'long']...> from 4566 documents (total 503640 corpus positions)", 'datetime': '2024-01-11T17:00:51.772142', 'gensim': '4.3.2', 'python': '3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}
discarding 0 tokens: []...
keeping 64523 tokens which were in no less than 1 and no more than 1598 (=35.0%) documents
rebuilding dictionary, shrinking gaps
resulting dictionary: Dictionary<64523 unique tokens: ['broadband', 'door', 'fcc', 'impact', 'long']...>
using autotuned alpha, starting with [0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335, 0.033333335]
using symmetric eta at 0.03333333333333333
using serial LDA version on this node
running online (multi-pass) LDA training, 30 topics, 100 passes over the supplied corpus of 4566 documents, updating model once every 2000 documents, evaluating perplexity every 4566 documents, iterating 50x with a convergence threshold of 0.001000
PROGRESS: pass 0, at document #2000/4566
performing inference on a chunk of 2000 documents
1110/2000 documents converged within 50 iterations
optimized alpha [0.032597158, 0.032972176, 0.032822385, 0.033161048, 0.033184834, 0.03499962, 0.03417581, 0.033174053, 0.033589035, 0.03401524, 0.032471996, 0.034006033, 0.034251567, 0.032761503, 0.032369427, 0.03315463, 0.03371769, 0.033932462, 0.034494992, 0.033789627, 0.034848336, 0.033784237, 0.031831287, 0.034007713, 0.034228552, 0.03319587, 0.03330976, 0.03448398, 0.032820906, 0.03335178]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #22 (0.032): 0.004*"day" + 0.004*"video" + 0.004*"wikileaks" + 0.002*"qatar" + 0.002*"news" + 0.002*"youtube" + 0.002*"people" + 0.002*"years" + 0.002*"media" + 0.001*"online"
topic #14 (0.032): 0.004*"cup" + 0.004*"wikileaks" + 0.003*"news" + 0.003*"host" + 0.003*"fifa" + 0.002*"gop" + 0.002*"live" + 0.002*"assange" + 0.002*"day" + 0.002*"aid"
topic #27 (0.034): 0.007*"wikileaks" + 0.003*"dont" + 0.003*"cup" + 0.003*"day" + 0.003*"good" + 0.003*"today" + 0.002*"russia" + 0.002*"qatar" + 0.002*"video" + 0.002*"time"
topic #20 (0.035): 0.010*"wikileaks" + 0.005*"day" + 0.005*"today" + 0.004*"work" + 0.003*"news" + 0.003*"love" + 0.003*"dont" + 0.003*"intro" + 0.003*"lol" + 0.003*"cup"
topic #5 (0.035): 0.005*"day" + 0.004*"work" + 0.004*"today" + 0.004*"dont" + 0.004*"people" + 0.003*"wikileaks" + 0.003*"lol" + 0.003*"meet" + 0.003*"aids" + 0.002*"obama"
topic diff=21.286398, rho=1.000000
PROGRESS: pass 0, at document #4000/4566
performing inference on a chunk of 2000 documents
1336/2000 documents converged within 50 iterations
optimized alpha [0.032509107, 0.03184854, 0.03280165, 0.03348272, 0.033039182, 0.042065714, 0.03718887, 0.0331384, 0.034228243, 0.03777656, 0.030547725, 0.03570935, 0.03711419, 0.031869896, 0.030985653, 0.032333896, 0.035740864, 0.037620146, 0.03852729, 0.03367122, 0.039832685, 0.035354823, 0.030154463, 0.03611138, 0.03663247, 0.033226967, 0.034208097, 0.03762883, 0.03212374, 0.034825742]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #22 (0.030): 0.006*"shourie" + 0.004*"alla" + 0.004*"arun" + 0.004*"niira" + 0.003*"wishes" + 0.003*"della" + 0.003*"day" + 0.003*"radia" + 0.002*"video" + 0.002*"wikileaks"
topic #10 (0.031): 0.003*"wikileaks" + 0.003*"health" + 0.003*"november" + 0.003*"att" + 0.002*"aristotle" + 0.002*"payrolls" + 0.002*"time" + 0.002*"day" + 0.002*"jobs" + 0.002*"news"
topic #18 (0.039): 0.010*"wikileaks" + 0.009*"news" + 0.005*"cup" + 0.004*"day" + 0.004*"russia" + 0.004*"tax" + 0.004*"today" + 0.004*"gop" + 0.003*"host" + 0.003*"cont"
topic #20 (0.040): 0.008*"wikileaks" + 0.008*"day" + 0.007*"today" + 0.005*"love" + 0.004*"good" + 0.003*"aids" + 0.003*"news" + 0.003*"dont" + 0.003*"time" + 0.003*"happy"
topic #5 (0.042): 0.008*"day" + 0.006*"today" + 0.006*"people" + 0.005*"lol" + 0.005*"dont" + 0.005*"aids" + 0.005*"good" + 0.004*"love" + 0.004*"work" + 0.003*"time"
topic diff=1.963083, rho=0.707107
bound: at document #0
-14.940 per-word bound, 31422.6 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 0, at document #4566/4566
performing inference on a chunk of 566 documents
431/566 documents converged within 50 iterations
optimized alpha [0.031857003, 0.031121809, 0.032878216, 0.033409894, 0.032258186, 0.054127134, 0.040786352, 0.032574546, 0.034745187, 0.04290785, 0.028856806, 0.037126686, 0.04002906, 0.030495768, 0.029763537, 0.031449076, 0.037509605, 0.044067934, 0.04505487, 0.032863002, 0.04731502, 0.03649093, 0.02910661, 0.03747438, 0.03972509, 0.032553677, 0.03454435, 0.04190204, 0.031363685, 0.035371795]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.029): 0.005*"cop" + 0.004*"churchill" + 0.004*"trunk" + 0.004*"skiing" + 0.003*"november" + 0.003*"donnerstag" + 0.003*"luncheon" + 0.003*"aristotle" + 0.003*"kyoto" + 0.003*"ihr"
topic #22 (0.029): 0.018*"jyj" + 0.014*"ist" + 0.012*"ezb" + 0.012*"die" + 0.012*"der" + 0.009*"ein" + 0.009*"auf" + 0.008*"aus" + 0.008*"den" + 0.007*"jaejoongs"
topic #18 (0.045): 0.011*"news" + 0.011*"wikileaks" + 0.005*"cup" + 0.004*"day" + 0.004*"tax" + 0.004*"russia" + 0.003*"gop" + 0.003*"business" + 0.003*"today" + 0.003*"cont"
topic #20 (0.047): 0.015*"iphone" + 0.010*"omg" + 0.009*"free" + 0.008*"day" + 0.006*"today" + 0.006*"wikileaks" + 0.005*"love" + 0.004*"news" + 0.004*"good" + 0.003*"life"
topic #5 (0.054): 0.010*"day" + 0.007*"today" + 0.006*"dont" + 0.006*"people" + 0.006*"lol" + 0.006*"good" + 0.006*"love" + 0.005*"aids" + 0.004*"time" + 0.004*"year"
topic diff=1.426133, rho=0.577350
PROGRESS: pass 1, at document #2000/4566
performing inference on a chunk of 2000 documents
1841/2000 documents converged within 50 iterations
optimized alpha [0.030569797, 0.02991613, 0.03158786, 0.032345086, 0.030975534, 0.058034062, 0.04168379, 0.031341765, 0.03373721, 0.042671975, 0.027613677, 0.03598434, 0.03950572, 0.029445695, 0.028477948, 0.030246798, 0.03622899, 0.044585444, 0.04690195, 0.03163254, 0.04702628, 0.035351865, 0.027898679, 0.03617786, 0.04059229, 0.031278465, 0.03333638, 0.04115186, 0.030157946, 0.034082174]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.028): 0.004*"november" + 0.004*"jobs" + 0.004*"fewer" + 0.004*"cop" + 0.003*"expected" + 0.003*"economy" + 0.003*"trunk" + 0.003*"churchill" + 0.002*"skiing" + 0.002*"aristotle"
topic #22 (0.028): 0.013*"jyj" + 0.010*"ist" + 0.009*"die" + 0.008*"der" + 0.008*"auf" + 0.007*"ezb" + 0.007*"mit" + 0.007*"ein" + 0.007*"eine" + 0.006*"den"
topic #18 (0.047): 0.012*"wikileaks" + 0.010*"news" + 0.005*"cup" + 0.004*"russia" + 0.004*"tax" + 0.004*"gop" + 0.004*"day" + 0.004*"host" + 0.003*"cont" + 0.003*"iran"
topic #20 (0.047): 0.012*"iphone" + 0.008*"day" + 0.007*"omg" + 0.007*"free" + 0.007*"wikileaks" + 0.006*"today" + 0.005*"love" + 0.004*"news" + 0.004*"twitter" + 0.004*"good"
topic #5 (0.058): 0.009*"day" + 0.006*"today" + 0.006*"dont" + 0.006*"good" + 0.006*"lol" + 0.006*"people" + 0.005*"love" + 0.004*"aids" + 0.004*"time" + 0.004*"work"
topic diff=0.919225, rho=0.483199
PROGRESS: pass 1, at document #4000/4566
performing inference on a chunk of 2000 documents
1859/2000 documents converged within 50 iterations
optimized alpha [0.03036816, 0.029245045, 0.031495463, 0.032156207, 0.030584829, 0.06971823, 0.044244267, 0.030956093, 0.034285635, 0.046054292, 0.026629345, 0.03680628, 0.041962743, 0.02869265, 0.027706716, 0.029478692, 0.037342023, 0.04886298, 0.05221548, 0.031069878, 0.05155809, 0.036416657, 0.027025247, 0.036911763, 0.043211464, 0.030931976, 0.03365007, 0.04357504, 0.029573012, 0.034618486]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.027): 0.005*"november" + 0.005*"jobs" + 0.005*"aristotle" + 0.005*"fewer" + 0.004*"economy" + 0.004*"expected" + 0.004*"att" + 0.004*"payrolls" + 0.003*"fujitsu" + 0.003*"skiing"
topic #22 (0.027): 0.009*"jyj" + 0.008*"die" + 0.007*"ist" + 0.007*"der" + 0.006*"auf" + 0.006*"shourie" + 0.006*"mit" + 0.006*"ein" + 0.006*"den" + 0.005*"eine"
topic #20 (0.052): 0.010*"iphone" + 0.007*"day" + 0.007*"free" + 0.006*"today" + 0.006*"wikileaks" + 0.005*"omg" + 0.005*"love" + 0.004*"twitter" + 0.004*"life" + 0.004*"good"
topic #18 (0.052): 0.012*"wikileaks" + 0.010*"news" + 0.006*"cup" + 0.005*"russia" + 0.005*"iran" + 0.004*"host" + 0.004*"cont" + 0.003*"day" + 0.003*"tax" + 0.003*"today"
topic #5 (0.070): 0.010*"day" + 0.007*"today" + 0.007*"good" + 0.006*"dont" + 0.006*"people" + 0.006*"love" + 0.006*"lol" + 0.005*"aids" + 0.005*"time" + 0.004*"work"
topic diff=0.752642, rho=0.483199
bound: at document #0
-14.322 per-word bound, 20479.7 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 1, at document #4566/4566
performing inference on a chunk of 566 documents
541/566 documents converged within 50 iterations
optimized alpha [0.029926762, 0.028907161, 0.03140686, 0.032014977, 0.030020742, 0.08511977, 0.04752856, 0.030586062, 0.034586534, 0.050411053, 0.025696838, 0.037638, 0.044326495, 0.027936475, 0.026973382, 0.028965464, 0.03852097, 0.054654922, 0.058205847, 0.030434493, 0.05779887, 0.037502017, 0.026481193, 0.037730396, 0.04583109, 0.030376391, 0.03402948, 0.04714943, 0.029057372, 0.035142716]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.026): 0.007*"fewer" + 0.006*"churchill" + 0.006*"trunk" + 0.005*"november" + 0.005*"donnerstag" + 0.005*"ihr" + 0.005*"jobs" + 0.005*"economy" + 0.005*"expected" + 0.005*"skiing"
topic #22 (0.026): 0.023*"jyj" + 0.021*"ist" + 0.018*"die" + 0.017*"der" + 0.013*"ezb" + 0.012*"ein" + 0.010*"aus" + 0.010*"mit" + 0.009*"neue" + 0.009*"den"
topic #20 (0.058): 0.008*"iphone" + 0.008*"day" + 0.006*"today" + 0.006*"free" + 0.005*"wikileaks" + 0.005*"nasa" + 0.005*"love" + 0.004*"news" + 0.004*"twitter" + 0.004*"life"
topic #18 (0.058): 0.012*"wikileaks" + 0.011*"news" + 0.006*"cup" + 0.005*"russia" + 0.004*"iran" + 0.004*"cont" + 0.004*"host" + 0.003*"obama" + 0.003*"state" + 0.003*"day"
topic #5 (0.085): 0.011*"day" + 0.007*"today" + 0.007*"good" + 0.007*"dont" + 0.007*"love" + 0.006*"people" + 0.005*"lol" + 0.005*"time" + 0.005*"aids" + 0.004*"video"
topic diff=0.632853, rho=0.483199
PROGRESS: pass 2, at document #2000/4566
performing inference on a chunk of 2000 documents
1915/2000 documents converged within 50 iterations
optimized alpha [0.028979152, 0.02815727, 0.03042424, 0.03118877, 0.029121593, 0.09182778, 0.049350142, 0.029711243, 0.033866234, 0.05049845, 0.024919044, 0.03668913, 0.043902207, 0.02731637, 0.026065473, 0.028123474, 0.03742117, 0.055733204, 0.061474394, 0.029740456, 0.05739561, 0.036657263, 0.025641926, 0.036641464, 0.047727168, 0.029474711, 0.03312998, 0.046401896, 0.028254634, 0.034127768]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.025): 0.008*"fewer" + 0.008*"jobs" + 0.008*"november" + 0.007*"economy" + 0.007*"expected" + 0.004*"rate" + 0.004*"trunk" + 0.004*"donnerstag" + 0.004*"adds" + 0.003*"churchill"
topic #22 (0.026): 0.016*"jyj" + 0.015*"ist" + 0.013*"die" + 0.013*"der" + 0.009*"ein" + 0.009*"mit" + 0.008*"eine" + 0.008*"ezb" + 0.008*"aus" + 0.008*"neue"
topic #20 (0.057): 0.008*"iphone" + 0.007*"day" + 0.006*"today" + 0.005*"wikileaks" + 0.005*"free" + 0.004*"nasa" + 0.004*"twitter" + 0.004*"love" + 0.004*"news" + 0.004*"life"
topic #18 (0.061): 0.013*"wikileaks" + 0.011*"news" + 0.006*"cup" + 0.005*"russia" + 0.004*"host" + 0.004*"iran" + 0.004*"cont" + 0.003*"obama" + 0.003*"state" + 0.003*"day"
topic #5 (0.092): 0.010*"day" + 0.007*"good" + 0.007*"today" + 0.007*"dont" + 0.006*"love" + 0.006*"people" + 0.005*"lol" + 0.005*"time" + 0.005*"aids" + 0.004*"work"
topic diff=0.411523, rho=0.435071
PROGRESS: pass 2, at document #4000/4566
performing inference on a chunk of 2000 documents
1918/2000 documents converged within 50 iterations
optimized alpha [0.02890494, 0.027778283, 0.030400302, 0.031048719, 0.02889361, 0.10876788, 0.052036826, 0.029474672, 0.034472853, 0.054063812, 0.024321992, 0.037427478, 0.046351336, 0.026818456, 0.025578465, 0.02760596, 0.038333576, 0.060280386, 0.067995764, 0.029465182, 0.06211449, 0.03800876, 0.025063872, 0.03724098, 0.050927084, 0.029273894, 0.03347755, 0.048867285, 0.027893815, 0.034635406]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.024): 0.010*"jobs" + 0.009*"fewer" + 0.008*"november" + 0.008*"economy" + 0.007*"expected" + 0.006*"aristotle" + 0.005*"rate" + 0.004*"adds" + 0.004*"payrolls" + 0.004*"att"
topic #22 (0.025): 0.012*"ist" + 0.012*"jyj" + 0.011*"die" + 0.010*"der" + 0.008*"ein" + 0.007*"mit" + 0.007*"eine" + 0.006*"auf" + 0.006*"den" + 0.006*"aus"
topic #20 (0.062): 0.008*"iphone" + 0.007*"day" + 0.006*"today" + 0.005*"free" + 0.005*"wikileaks" + 0.004*"twitter" + 0.004*"nasa" + 0.004*"life" + 0.004*"love" + 0.004*"video"
topic #18 (0.068): 0.013*"wikileaks" + 0.011*"news" + 0.007*"cup" + 0.005*"russia" + 0.005*"iran" + 0.004*"host" + 0.004*"cont" + 0.003*"fifa" + 0.003*"state" + 0.003*"obama"
topic #5 (0.109): 0.011*"day" + 0.008*"good" + 0.008*"today" + 0.007*"love" + 0.007*"dont" + 0.007*"people" + 0.005*"aids" + 0.005*"time" + 0.005*"lol" + 0.004*"video"
topic diff=0.329082, rho=0.435071
bound: at document #0
-14.153 per-word bound, 18215.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 2, at document #4566/4566
performing inference on a chunk of 566 documents
556/566 documents converged within 50 iterations
optimized alpha [0.028594995, 0.027579658, 0.030374303, 0.030903952, 0.028557992, 0.12828447, 0.055038303, 0.029247949, 0.034803987, 0.05836833, 0.023740213, 0.03827058, 0.048617773, 0.02634824, 0.025117721, 0.027257353, 0.03930064, 0.06585081, 0.07380579, 0.029095821, 0.0680931, 0.039172493, 0.024724137, 0.03783852, 0.053388946, 0.028901007, 0.033872094, 0.052256126, 0.027662463, 0.035031267]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.024): 0.011*"fewer" + 0.009*"jobs" + 0.009*"economy" + 0.008*"november" + 0.008*"expected" + 0.006*"trunk" + 0.006*"churchill" + 0.005*"ihr" + 0.005*"donnerstag" + 0.005*"skiing"
topic #22 (0.025): 0.025*"jyj" + 0.023*"ist" + 0.017*"die" + 0.014*"der" + 0.013*"ein" + 0.013*"ezb" + 0.010*"tvxq" + 0.010*"neue" + 0.009*"eine" + 0.008*"einen"
topic #20 (0.068): 0.007*"day" + 0.007*"iphone" + 0.006*"nasa" + 0.005*"today" + 0.005*"free" + 0.005*"twitter" + 0.005*"wikileaks" + 0.004*"news" + 0.004*"life" + 0.004*"video"
topic #18 (0.074): 0.012*"wikileaks" + 0.011*"news" + 0.007*"cup" + 0.005*"russia" + 0.004*"iran" + 0.004*"host" + 0.004*"cont" + 0.004*"state" + 0.004*"obama" + 0.003*"fifa"
topic #5 (0.128): 0.011*"day" + 0.008*"good" + 0.008*"today" + 0.008*"love" + 0.007*"dont" + 0.007*"people" + 0.006*"time" + 0.005*"aids" + 0.004*"lol" + 0.004*"video"
topic diff=0.311002, rho=0.435071
PROGRESS: pass 3, at document #2000/4566
performing inference on a chunk of 2000 documents
1938/2000 documents converged within 50 iterations
optimized alpha [0.027874462, 0.027083248, 0.029614009, 0.030274063, 0.027910028, 0.13707541, 0.05702008, 0.028586902, 0.034237504, 0.058692157, 0.023194464, 0.03748003, 0.048264295, 0.025968313, 0.024464158, 0.026648382, 0.038356874, 0.067139, 0.077897586, 0.02863431, 0.067500226, 0.038596127, 0.02410141, 0.036956556, 0.05587582, 0.028259449, 0.033179816, 0.05186304, 0.02714338, 0.03420484]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.023): 0.011*"fewer" + 0.011*"jobs" + 0.010*"economy" + 0.010*"november" + 0.009*"expected" + 0.006*"rate" + 0.005*"adds" + 0.004*"trunk" + 0.004*"donnerstag" + 0.004*"churchill"
topic #22 (0.024): 0.018*"jyj" + 0.017*"ist" + 0.012*"die" + 0.010*"der" + 0.010*"ein" + 0.009*"ezb" + 0.008*"neue" + 0.008*"eine" + 0.007*"tvxq" + 0.007*"mit"
topic #20 (0.068): 0.007*"iphone" + 0.007*"day" + 0.006*"nasa" + 0.005*"today" + 0.005*"twitter" + 0.005*"wikileaks" + 0.005*"free" + 0.004*"google" + 0.004*"news" + 0.004*"life"
topic #18 (0.078): 0.013*"wikileaks" + 0.011*"news" + 0.006*"cup" + 0.005*"russia" + 0.004*"iran" + 0.004*"host" + 0.004*"cont" + 0.004*"obama" + 0.004*"state" + 0.003*"fifa"
topic #5 (0.137): 0.011*"day" + 0.008*"good" + 0.008*"today" + 0.007*"dont" + 0.007*"love" + 0.006*"people" + 0.006*"time" + 0.005*"aids" + 0.004*"work" + 0.004*"video"
topic diff=0.209497, rho=0.398948
PROGRESS: pass 3, at document #4000/4566
performing inference on a chunk of 2000 documents
1944/2000 documents converged within 50 iterations
optimized alpha [0.027889851, 0.026892409, 0.02967982, 0.030253574, 0.027828448, 0.15861781, 0.059742335, 0.028479036, 0.03487704, 0.06238957, 0.022801543, 0.038268328, 0.050632074, 0.02566026, 0.024150355, 0.026316347, 0.039244007, 0.07196943, 0.08496413, 0.02854639, 0.072294064, 0.040163334, 0.02367505, 0.037522834, 0.059513155, 0.028157122, 0.033557724, 0.054280933, 0.026932795, 0.034731176]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.023): 0.013*"jobs" + 0.012*"fewer" + 0.011*"economy" + 0.010*"november" + 0.010*"expected" + 0.007*"rate" + 0.006*"adds" + 0.006*"aristotle" + 0.004*"payrolls" + 0.004*"att"
topic #22 (0.024): 0.013*"jyj" + 0.013*"ist" + 0.010*"die" + 0.008*"ein" + 0.008*"der" + 0.006*"eine" + 0.006*"neue" + 0.006*"shourie" + 0.006*"tvxq" + 0.006*"arun"
topic #20 (0.072): 0.007*"iphone" + 0.006*"day" + 0.005*"nasa" + 0.005*"today" + 0.005*"twitter" + 0.005*"free" + 0.005*"google" + 0.004*"wikileaks" + 0.004*"facebook" + 0.004*"life"
topic #18 (0.085): 0.012*"wikileaks" + 0.011*"news" + 0.007*"cup" + 0.005*"iran" + 0.005*"russia" + 0.004*"host" + 0.004*"cont" + 0.003*"state" + 0.003*"fifa" + 0.003*"bbc"
topic #5 (0.159): 0.012*"day" + 0.008*"good" + 0.008*"today" + 0.008*"love" + 0.007*"dont" + 0.007*"people" + 0.006*"time" + 0.006*"aids" + 0.004*"video" + 0.004*"work"
topic diff=0.173132, rho=0.398948
bound: at document #0
-14.074 per-word bound, 17248.5 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 3, at document #4566/4566
performing inference on a chunk of 566 documents
558/566 documents converged within 50 iterations
optimized alpha [0.027717154, 0.026789848, 0.029710243, 0.030180905, 0.02757627, 0.18152292, 0.062459163, 0.028340342, 0.0352526, 0.06668035, 0.02238209, 0.039110027, 0.05278355, 0.025419163, 0.023834016, 0.026116515, 0.040002722, 0.077495776, 0.09044731, 0.028320625, 0.07815167, 0.041471213, 0.023457969, 0.038149204, 0.061757322, 0.027894825, 0.03389548, 0.05774815, 0.026804468, 0.035204586]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.022): 0.013*"fewer" + 0.012*"jobs" + 0.012*"economy" + 0.010*"november" + 0.010*"expected" + 0.006*"adds" + 0.005*"trunk" + 0.005*"churchill" + 0.005*"ihr" + 0.005*"donnerstag"
topic #22 (0.023): 0.026*"jyj" + 0.021*"ist" + 0.014*"die" + 0.013*"ezb" + 0.012*"ein" + 0.012*"tvxq" + 0.009*"neue" + 0.009*"einen" + 0.009*"der" + 0.008*"eine"
topic #20 (0.078): 0.008*"nasa" + 0.007*"iphone" + 0.006*"day" + 0.005*"twitter" + 0.005*"today" + 0.005*"free" + 0.005*"google" + 0.004*"wikileaks" + 0.004*"news" + 0.004*"app"
topic #18 (0.090): 0.012*"wikileaks" + 0.011*"news" + 0.006*"cup" + 0.005*"russia" + 0.005*"iran" + 0.004*"state" + 0.004*"cont" + 0.004*"obama" + 0.004*"host" + 0.003*"bbc"
topic #5 (0.182): 0.012*"day" + 0.008*"good" + 0.008*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.006*"time" + 0.005*"aids" + 0.004*"video" + 0.004*"morning"
topic diff=0.194001, rho=0.398948
PROGRESS: pass 4, at document #2000/4566
performing inference on a chunk of 2000 documents
1945/2000 documents converged within 50 iterations
optimized alpha [0.027137421, 0.026465034, 0.02909932, 0.029664557, 0.027092915, 0.19198467, 0.064440146, 0.027833562, 0.034768302, 0.0670179, 0.0219938, 0.038435154, 0.052368406, 0.025212841, 0.023325954, 0.025641989, 0.039221562, 0.07861443, 0.094721705, 0.027976772, 0.077586606, 0.040967643, 0.022970265, 0.0374011, 0.06449145, 0.027393365, 0.033306293, 0.057583522, 0.026452806, 0.034540772]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.022): 0.014*"jobs" + 0.013*"fewer" + 0.013*"economy" + 0.012*"november" + 0.011*"expected" + 0.007*"rate" + 0.007*"adds" + 0.004*"trunk" + 0.004*"donnerstag" + 0.004*"aristotle"
topic #22 (0.023): 0.020*"jyj" + 0.015*"ist" + 0.010*"die" + 0.009*"ein" + 0.009*"ezb" + 0.008*"tvxq" + 0.007*"neue" + 0.007*"eine" + 0.007*"einen" + 0.007*"der"
topic #17 (0.079): 0.007*"cop" + 0.007*"climate" + 0.005*"green" + 0.004*"dec" + 0.004*"today" + 0.004*"change" + 0.004*"cancun" + 0.004*"video" + 0.003*"great" + 0.003*"love"
topic #18 (0.095): 0.012*"wikileaks" + 0.011*"news" + 0.006*"cup" + 0.005*"russia" + 0.005*"iran" + 0.004*"state" + 0.004*"host" + 0.004*"cont" + 0.004*"obama" + 0.003*"bbc"
topic #5 (0.192): 0.012*"day" + 0.008*"good" + 0.008*"today" + 0.008*"love" + 0.007*"dont" + 0.006*"people" + 0.006*"time" + 0.005*"aids" + 0.004*"video" + 0.004*"work"
topic diff=0.142100, rho=0.370548
PROGRESS: pass 4, at document #4000/4566
performing inference on a chunk of 2000 documents
1962/2000 documents converged within 50 iterations
optimized alpha [0.027218388, 0.026383538, 0.029219987, 0.029700777, 0.02710929, 0.21855092, 0.06719771, 0.027810875, 0.03546294, 0.070678085, 0.021706868, 0.03927528, 0.054636627, 0.025030114, 0.023127465, 0.025421277, 0.040122345, 0.083424956, 0.10197025, 0.027960094, 0.08223731, 0.042626332, 0.022643918, 0.037985377, 0.0683287, 0.027367242, 0.03368683, 0.06027468, 0.026345499, 0.03508692]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.022): 0.015*"jobs" + 0.014*"fewer" + 0.013*"economy" + 0.012*"november" + 0.011*"expected" + 0.008*"rate" + 0.007*"adds" + 0.006*"aristotle" + 0.004*"alert" + 0.004*"payrolls"
topic #22 (0.023): 0.015*"jyj" + 0.012*"ist" + 0.008*"die" + 0.007*"ein" + 0.007*"radia" + 0.007*"tvxq" + 0.006*"arun" + 0.006*"ezb" + 0.006*"shourie" + 0.006*"eine"
topic #17 (0.083): 0.007*"climate" + 0.006*"cop" + 0.005*"dec" + 0.005*"green" + 0.004*"change" + 0.004*"today" + 0.004*"energy" + 0.004*"video" + 0.004*"cancun" + 0.004*"great"
topic #18 (0.102): 0.012*"wikileaks" + 0.011*"news" + 0.006*"cup" + 0.006*"iran" + 0.005*"russia" + 0.004*"bbc" + 0.004*"state" + 0.004*"cont" + 0.004*"host" + 0.003*"police"
topic #5 (0.219): 0.012*"day" + 0.009*"good" + 0.008*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.006*"time" + 0.006*"aids" + 0.004*"video" + 0.004*"work"
topic diff=0.111894, rho=0.370548
bound: at document #0
-14.029 per-word bound, 16722.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 4, at document #4566/4566
performing inference on a chunk of 566 documents
560/566 documents converged within 50 iterations
optimized alpha [0.02713751, 0.026357349, 0.029303275, 0.029655123, 0.026921833, 0.24379617, 0.06964043, 0.027761908, 0.03587099, 0.07476724, 0.02138968, 0.040122002, 0.05681257, 0.024895715, 0.022902258, 0.025301654, 0.04092193, 0.08821145, 0.10712923, 0.027794207, 0.087868206, 0.04405579, 0.022489822, 0.038637593, 0.070448294, 0.02719198, 0.034021944, 0.06372354, 0.026280247, 0.0355964]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.021): 0.014*"jobs" + 0.014*"fewer" + 0.013*"economy" + 0.012*"november" + 0.011*"expected" + 0.007*"adds" + 0.006*"rate" + 0.005*"trunk" + 0.005*"ihr" + 0.005*"churchill"
topic #22 (0.022): 0.027*"jyj" + 0.018*"ist" + 0.013*"ezb" + 0.013*"tvxq" + 0.010*"ein" + 0.010*"einen" + 0.010*"die" + 0.008*"kein" + 0.008*"jaejoongs" + 0.007*"eine"
topic #17 (0.088): 0.008*"cop" + 0.007*"climate" + 0.006*"green" + 0.005*"dec" + 0.004*"change" + 0.004*"today" + 0.004*"cancun" + 0.004*"video" + 0.004*"energy" + 0.003*"great"
topic #18 (0.107): 0.012*"wikileaks" + 0.011*"news" + 0.006*"cup" + 0.005*"iran" + 0.005*"russia" + 0.004*"state" + 0.004*"cont" + 0.004*"bbc" + 0.004*"police" + 0.004*"obama"
topic #5 (0.244): 0.012*"day" + 0.009*"good" + 0.008*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.006*"time" + 0.005*"aids" + 0.004*"video" + 0.004*"morning"
topic diff=0.143984, rho=0.370548
PROGRESS: pass 5, at document #2000/4566
performing inference on a chunk of 2000 documents
1962/2000 documents converged within 50 iterations
optimized alpha [0.026655152, 0.02612431, 0.028798955, 0.029228704, 0.026526276, 0.25482213, 0.071661845, 0.027347704, 0.035439275, 0.07507244, 0.021097189, 0.03949623, 0.056375157, 0.024762047, 0.022495838, 0.024930654, 0.040244896, 0.08905831, 0.11132226, 0.027523108, 0.08720895, 0.04356312, 0.0220981, 0.03796986, 0.07332074, 0.026810326, 0.033505812, 0.0636651, 0.026011778, 0.035037737]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.021): 0.015*"jobs" + 0.014*"fewer" + 0.014*"economy" + 0.012*"november" + 0.012*"expected" + 0.007*"rate" + 0.007*"adds" + 0.004*"alert" + 0.004*"trunk" + 0.004*"donnerstag"
topic #22 (0.022): 0.021*"jyj" + 0.013*"ist" + 0.009*"ezb" + 0.009*"tvxq" + 0.008*"ein" + 0.007*"einen" + 0.007*"die" + 0.006*"kein" + 0.006*"eine" + 0.006*"jaejoongs"
topic #17 (0.089): 0.008*"cop" + 0.008*"climate" + 0.005*"green" + 0.005*"dec" + 0.004*"change" + 0.004*"today" + 0.004*"cancun" + 0.004*"video" + 0.004*"energy" + 0.003*"art"
topic #18 (0.111): 0.012*"wikileaks" + 0.011*"news" + 0.005*"cup" + 0.005*"iran" + 0.004*"russia" + 0.004*"state" + 0.004*"bbc" + 0.004*"police" + 0.004*"cont" + 0.004*"obama"
topic #5 (0.255): 0.012*"day" + 0.009*"good" + 0.008*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.006*"time" + 0.005*"aids" + 0.004*"video" + 0.004*"work"
topic diff=0.111672, rho=0.347461
PROGRESS: pass 5, at document #4000/4566
performing inference on a chunk of 2000 documents
1959/2000 documents converged within 50 iterations
optimized alpha [0.026757024, 0.026102966, 0.028971903, 0.02930727, 0.026593551, 0.28584677, 0.074335076, 0.027350776, 0.036169175, 0.07872424, 0.02088068, 0.040340904, 0.058625266, 0.024629664, 0.022372194, 0.024777243, 0.04110526, 0.09379618, 0.11915909, 0.027545631, 0.09197604, 0.045319382, 0.021858484, 0.038568836, 0.077134036, 0.026826644, 0.03388034, 0.06649857, 0.025959885, 0.035611752]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.021): 0.016*"jobs" + 0.014*"fewer" + 0.013*"economy" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.007*"adds" + 0.006*"aristotle" + 0.005*"alert" + 0.004*"payrolls"
topic #22 (0.022): 0.016*"jyj" + 0.010*"ist" + 0.008*"radia" + 0.008*"tvxq" + 0.006*"ezb" + 0.006*"arun" + 0.006*"ein" + 0.006*"shourie" + 0.006*"einen" + 0.006*"die"
topic #17 (0.094): 0.008*"climate" + 0.007*"cop" + 0.005*"green" + 0.005*"dec" + 0.005*"change" + 0.004*"energy" + 0.004*"today" + 0.004*"cancun" + 0.004*"art" + 0.004*"video"
topic #18 (0.119): 0.012*"wikileaks" + 0.011*"news" + 0.006*"iran" + 0.005*"cup" + 0.004*"russia" + 0.004*"bbc" + 0.004*"state" + 0.004*"police" + 0.004*"cont" + 0.003*"obama"
topic #5 (0.286): 0.012*"day" + 0.009*"good" + 0.009*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.006*"time" + 0.006*"aids" + 0.004*"video" + 0.004*"life"
topic diff=0.085138, rho=0.347461
bound: at document #0
-14.000 per-word bound, 16381.7 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 5, at document #4566/4566
performing inference on a chunk of 566 documents
561/566 documents converged within 50 iterations
optimized alpha [0.026724642, 0.026097627, 0.029089343, 0.0292925, 0.026464503, 0.31206685, 0.07660751, 0.027348857, 0.03660064, 0.082646064, 0.020645414, 0.041169226, 0.060692176, 0.024526287, 0.022207651, 0.024710609, 0.041915406, 0.09804807, 0.12379354, 0.027435094, 0.09747122, 0.04683737, 0.021743923, 0.039218962, 0.079006, 0.026709646, 0.034208596, 0.06993176, 0.025936747, 0.036124334]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.021): 0.015*"fewer" + 0.015*"jobs" + 0.014*"economy" + 0.012*"november" + 0.012*"expected" + 0.007*"adds" + 0.006*"rate" + 0.005*"trunk" + 0.005*"ihr" + 0.005*"aristotle"
topic #22 (0.022): 0.028*"jyj" + 0.014*"ist" + 0.014*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.008*"kein" + 0.008*"ein" + 0.008*"jaejoongs" + 0.007*"pasa" + 0.007*"composed"
topic #17 (0.098): 0.008*"cop" + 0.007*"climate" + 0.006*"green" + 0.005*"dec" + 0.005*"change" + 0.004*"cancun" + 0.004*"today" + 0.004*"energy" + 0.004*"video" + 0.003*"great"
topic #18 (0.124): 0.011*"news" + 0.011*"wikileaks" + 0.005*"iran" + 0.005*"cup" + 0.004*"state" + 0.004*"russia" + 0.004*"bbc" + 0.004*"police" + 0.004*"cont" + 0.004*"obama"
topic #5 (0.312): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.006*"time" + 0.006*"aids" + 0.004*"video" + 0.004*"morning"
topic diff=0.118804, rho=0.347461
PROGRESS: pass 6, at document #2000/4566
performing inference on a chunk of 2000 documents
1972/2000 documents converged within 50 iterations
optimized alpha [0.026313687, 0.025907777, 0.028658785, 0.02895121, 0.026140086, 0.32308465, 0.0786454, 0.027006809, 0.036206976, 0.08285764, 0.020414114, 0.04062731, 0.060209446, 0.024441969, 0.021873483, 0.024406318, 0.041302994, 0.09873947, 0.12778495, 0.027229143, 0.09665405, 0.04640873, 0.02142408, 0.038612027, 0.081924744, 0.02639936, 0.03377674, 0.06991409, 0.025728125, 0.035629738]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.020): 0.016*"jobs" + 0.015*"fewer" + 0.014*"economy" + 0.013*"november" + 0.013*"expected" + 0.008*"rate" + 0.008*"adds" + 0.005*"alert" + 0.004*"nyt" + 0.004*"trunk"
topic #22 (0.021): 0.022*"jyj" + 0.010*"tvxq" + 0.010*"ist" + 0.010*"ezb" + 0.008*"einen" + 0.006*"kein" + 0.006*"ein" + 0.006*"jaejoongs" + 0.005*"pasa" + 0.005*"composed"
topic #17 (0.099): 0.008*"cop" + 0.008*"climate" + 0.006*"green" + 0.005*"dec" + 0.004*"change" + 0.004*"cancun" + 0.004*"energy" + 0.004*"today" + 0.004*"video" + 0.004*"art"
topic #18 (0.128): 0.012*"wikileaks" + 0.011*"news" + 0.005*"iran" + 0.004*"cup" + 0.004*"bbc" + 0.004*"state" + 0.004*"police" + 0.004*"russia" + 0.004*"cont" + 0.003*"obama"
topic #5 (0.323): 0.013*"day" + 0.009*"good" + 0.008*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.006*"time" + 0.005*"aids" + 0.004*"video" + 0.004*"work"
topic diff=0.094203, rho=0.328213
PROGRESS: pass 6, at document #4000/4566
performing inference on a chunk of 2000 documents
1956/2000 documents converged within 50 iterations
optimized alpha [0.026447851, 0.025918568, 0.028860437, 0.029072572, 0.026221652, 0.3579156, 0.08127493, 0.027046148, 0.036963448, 0.08656386, 0.020243134, 0.041488808, 0.062400572, 0.024341, 0.021795802, 0.024303945, 0.042133555, 0.10352026, 0.13565437, 0.027280958, 0.1015463, 0.048284158, 0.021243656, 0.03920325, 0.08581175, 0.02644713, 0.034159333, 0.07283943, 0.025694419, 0.036242522]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.020): 0.016*"jobs" + 0.015*"fewer" + 0.014*"economy" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.006*"aristotle" + 0.005*"alert" + 0.004*"nyt"
topic #22 (0.021): 0.017*"jyj" + 0.009*"radia" + 0.009*"tvxq" + 0.008*"ist" + 0.007*"ezb" + 0.006*"arun" + 0.006*"einen" + 0.006*"shourie" + 0.005*"pasa" + 0.005*"jaejoongs"
topic #17 (0.104): 0.008*"climate" + 0.007*"cop" + 0.006*"green" + 0.005*"dec" + 0.005*"change" + 0.005*"energy" + 0.004*"cancun" + 0.004*"today" + 0.004*"art" + 0.004*"video"
topic #18 (0.136): 0.011*"wikileaks" + 0.011*"news" + 0.006*"iran" + 0.004*"bbc" + 0.004*"police" + 0.004*"cup" + 0.004*"state" + 0.004*"russia" + 0.004*"cont" + 0.003*"obama"
topic #5 (0.358): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.006*"time" + 0.006*"aids" + 0.004*"video" + 0.004*"life"
topic diff=0.068950, rho=0.328213
bound: at document #0
-13.980 per-word bound, 16155.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 6, at document #4566/4566
performing inference on a chunk of 566 documents
557/566 documents converged within 50 iterations
optimized alpha [0.026450163, 0.025941588, 0.028985055, 0.029094715, 0.026135303, 0.3857153, 0.08348054, 0.02707783, 0.037395895, 0.090526156, 0.020056, 0.0423019, 0.06434143, 0.024272265, 0.02167441, 0.024274783, 0.042932533, 0.10742384, 0.13957751, 0.027210725, 0.10693481, 0.049845412, 0.02116757, 0.03985076, 0.08753443, 0.026341194, 0.034479033, 0.07633643, 0.02570279, 0.03675574]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.020): 0.016*"fewer" + 0.015*"jobs" + 0.014*"economy" + 0.012*"expected" + 0.012*"november" + 0.007*"adds" + 0.007*"rate" + 0.005*"aristotle" + 0.005*"trunk" + 0.005*"ihr"
topic #22 (0.021): 0.029*"jyj" + 0.014*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.009*"ist" + 0.008*"jaejoongs" + 0.008*"kein" + 0.007*"pasa" + 0.007*"composed" + 0.006*"tiers"
topic #17 (0.107): 0.009*"cop" + 0.008*"climate" + 0.006*"green" + 0.006*"dec" + 0.005*"change" + 0.004*"cancun" + 0.004*"energy" + 0.004*"today" + 0.004*"video" + 0.003*"art"
topic #18 (0.140): 0.011*"news" + 0.011*"wikileaks" + 0.005*"iran" + 0.004*"police" + 0.004*"bbc" + 0.004*"state" + 0.004*"cup" + 0.004*"russia" + 0.004*"cont" + 0.004*"korea"
topic #5 (0.386): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.006*"time" + 0.006*"aids" + 0.004*"video" + 0.004*"life"
topic diff=0.103357, rho=0.328213
PROGRESS: pass 7, at document #2000/4566
performing inference on a chunk of 2000 documents
1972/2000 documents converged within 50 iterations
optimized alpha [0.026093137, 0.025787797, 0.0286072, 0.028795894, 0.025861118, 0.39684096, 0.08551785, 0.026790682, 0.037037123, 0.09059922, 0.019869896, 0.041806508, 0.06378712, 0.024225572, 0.021390779, 0.024027187, 0.042360526, 0.1078009, 0.14361006, 0.027042074, 0.106040396, 0.049376965, 0.020897834, 0.039285358, 0.090356246, 0.026093854, 0.03409435, 0.07623044, 0.025537372, 0.036294073]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.020): 0.016*"fewer" + 0.016*"jobs" + 0.015*"economy" + 0.013*"expected" + 0.013*"november" + 0.008*"rate" + 0.008*"adds" + 0.005*"alert" + 0.004*"nyt" + 0.004*"aristotle"
topic #22 (0.021): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"ezb" + 0.008*"einen" + 0.006*"ist" + 0.006*"kein" + 0.006*"jaejoongs" + 0.006*"pasa" + 0.005*"composed" + 0.005*"tiers"
topic #17 (0.108): 0.009*"cop" + 0.008*"climate" + 0.006*"green" + 0.005*"dec" + 0.005*"change" + 0.004*"energy" + 0.004*"cancun" + 0.004*"today" + 0.004*"video" + 0.004*"art"
topic #18 (0.144): 0.011*"wikileaks" + 0.011*"news" + 0.005*"iran" + 0.004*"bbc" + 0.004*"police" + 0.004*"state" + 0.004*"cup" + 0.004*"cont" + 0.004*"russia" + 0.004*"korea"
topic #5 (0.397): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.006*"time" + 0.006*"aids" + 0.004*"video" + 0.004*"work"
topic diff=0.083677, rho=0.311846
PROGRESS: pass 7, at document #4000/4566
performing inference on a chunk of 2000 documents
1977/2000 documents converged within 50 iterations
optimized alpha [0.026246207, 0.025821658, 0.028833898, 0.028940504, 0.025961524, 0.43452767, 0.08805306, 0.026851369, 0.037788276, 0.094331324, 0.019734524, 0.042664073, 0.06593489, 0.024153944, 0.021336263, 0.023961814, 0.043189667, 0.112677746, 0.15141927, 0.027110683, 0.11090744, 0.051276192, 0.020751549, 0.039885864, 0.094194755, 0.026163366, 0.034475535, 0.07921002, 0.02552616, 0.036918677]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.020): 0.016*"jobs" + 0.015*"fewer" + 0.014*"economy" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.006*"aristotle" + 0.005*"alert" + 0.004*"jobless"
topic #22 (0.021): 0.017*"jyj" + 0.010*"radia" + 0.009*"tvxq" + 0.007*"ezb" + 0.007*"arun" + 0.006*"einen" + 0.006*"shourie" + 0.005*"pasa" + 0.005*"jaejoongs" + 0.005*"ist"
topic #17 (0.113): 0.009*"climate" + 0.007*"cop" + 0.006*"green" + 0.005*"dec" + 0.005*"change" + 0.005*"energy" + 0.004*"cancun" + 0.004*"art" + 0.004*"today" + 0.004*"video"
topic #18 (0.151): 0.011*"news" + 0.011*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.004*"police" + 0.004*"state" + 0.004*"russia" + 0.003*"cup" + 0.003*"cont" + 0.003*"korea"
topic #5 (0.435): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.006*"time" + 0.006*"aids" + 0.004*"life" + 0.004*"video"
topic diff=0.060174, rho=0.311846
bound: at document #0
-13.965 per-word bound, 15990.6 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 7, at document #4566/4566
performing inference on a chunk of 566 documents
561/566 documents converged within 50 iterations
optimized alpha [0.02627231, 0.025877934, 0.028975045, 0.028987736, 0.025919313, 0.46152166, 0.08999594, 0.026905885, 0.038216915, 0.09819382, 0.019582087, 0.043459855, 0.06780686, 0.02412309, 0.021245724, 0.023958318, 0.043996274, 0.11623237, 0.15456167, 0.027068947, 0.11603563, 0.052795667, 0.020702416, 0.040526684, 0.09559416, 0.026089555, 0.03478266, 0.0827275, 0.025555955, 0.037428573]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.020): 0.016*"fewer" + 0.015*"jobs" + 0.015*"economy" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.005*"aristotle" + 0.005*"trunk" + 0.005*"ihr"
topic #22 (0.021): 0.029*"jyj" + 0.015*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.008*"jaejoongs" + 0.008*"kein" + 0.007*"pasa" + 0.007*"composed" + 0.007*"radia" + 0.006*"tiers"
topic #17 (0.116): 0.009*"cop" + 0.008*"climate" + 0.007*"green" + 0.006*"dec" + 0.005*"change" + 0.005*"energy" + 0.005*"cancun" + 0.004*"today" + 0.004*"video" + 0.004*"art"
topic #18 (0.155): 0.011*"news" + 0.011*"wikileaks" + 0.005*"iran" + 0.005*"police" + 0.004*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"cont" + 0.004*"russia" + 0.003*"cup"
topic #5 (0.462): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.009*"love" + 0.008*"dont" + 0.007*"people" + 0.006*"time" + 0.006*"aids" + 0.004*"video" + 0.004*"life"
topic diff=0.093142, rho=0.311846
PROGRESS: pass 8, at document #2000/4566
performing inference on a chunk of 2000 documents
1975/2000 documents converged within 50 iterations
optimized alpha [0.02595534, 0.025753526, 0.028635766, 0.028727334, 0.025681589, 0.46992424, 0.09196914, 0.026659742, 0.03787704, 0.09821297, 0.019432293, 0.04299142, 0.06722216, 0.024096735, 0.020996744, 0.023749802, 0.043444145, 0.11628078, 0.15832257, 0.026922751, 0.11500078, 0.05233806, 0.020466844, 0.03999528, 0.09832187, 0.025874931, 0.034433004, 0.08254324, 0.025418323, 0.036999173]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.019): 0.016*"fewer" + 0.016*"jobs" + 0.015*"economy" + 0.013*"expected" + 0.013*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.004*"nyt" + 0.004*"aristotle"
topic #22 (0.020): 0.023*"jyj" + 0.011*"tvxq" + 0.010*"ezb" + 0.008*"einen" + 0.006*"jaejoongs" + 0.006*"kein" + 0.006*"pasa" + 0.005*"radia" + 0.005*"composed" + 0.005*"tiers"
topic #17 (0.116): 0.009*"cop" + 0.009*"climate" + 0.007*"green" + 0.005*"dec" + 0.005*"change" + 0.005*"energy" + 0.004*"cancun" + 0.004*"today" + 0.004*"art" + 0.004*"video"
topic #18 (0.158): 0.011*"news" + 0.011*"wikileaks" + 0.005*"iran" + 0.005*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"cont" + 0.003*"obama" + 0.003*"russia"
topic #5 (0.470): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.004*"video" + 0.004*"life"
topic diff=0.076663, rho=0.297706
PROGRESS: pass 8, at document #4000/4566
performing inference on a chunk of 2000 documents
1979/2000 documents converged within 50 iterations
optimized alpha [0.026132103, 0.02580699, 0.028867636, 0.02887842, 0.025797175, 0.5085712, 0.094334364, 0.026741944, 0.038614724, 0.10195758, 0.0193201, 0.043836314, 0.06929904, 0.024049604, 0.020967161, 0.02370456, 0.044268183, 0.12101752, 0.16628169, 0.027012846, 0.119855784, 0.05427765, 0.020351328, 0.04058789, 0.102210656, 0.025954513, 0.034808386, 0.0854675, 0.025414811, 0.037625354]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.019): 0.016*"jobs" + 0.016*"fewer" + 0.014*"economy" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.006*"aristotle" + 0.005*"alert" + 0.005*"jobless"
topic #22 (0.020): 0.018*"jyj" + 0.011*"radia" + 0.010*"tvxq" + 0.007*"ezb" + 0.007*"arun" + 0.007*"einen" + 0.006*"shourie" + 0.005*"pasa" + 0.005*"jaejoongs" + 0.005*"bogot"
topic #17 (0.121): 0.009*"climate" + 0.008*"cop" + 0.006*"green" + 0.006*"dec" + 0.005*"energy" + 0.005*"change" + 0.004*"cancun" + 0.004*"art" + 0.004*"today" + 0.004*"video"
topic #18 (0.166): 0.011*"news" + 0.011*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"police" + 0.004*"state" + 0.004*"korea" + 0.003*"cont" + 0.003*"russia" + 0.003*"obama"
topic #5 (0.509): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.004*"great"
topic diff=0.054424, rho=0.297706
bound: at document #0
-13.953 per-word bound, 15863.1 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 8, at document #4566/4566
performing inference on a chunk of 566 documents
563/566 documents converged within 50 iterations
optimized alpha [0.026174208, 0.025875228, 0.029019019, 0.0289427, 0.025775306, 0.53309906, 0.096101895, 0.026811583, 0.03903601, 0.10559333, 0.019193264, 0.04465939, 0.07117775, 0.024035105, 0.020898951, 0.023718933, 0.045009796, 0.12419358, 0.1688266, 0.026991189, 0.12469953, 0.05577761, 0.020321548, 0.041176498, 0.10343879, 0.025903886, 0.035100464, 0.08871063, 0.025459338, 0.038108382]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.019): 0.016*"fewer" + 0.015*"jobs" + 0.015*"economy" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.005*"aristotle" + 0.005*"trunk" + 0.005*"ihr"
topic #22 (0.020): 0.029*"jyj" + 0.015*"tvxq" + 0.013*"ezb" + 0.011*"einen" + 0.008*"jaejoongs" + 0.008*"pasa" + 0.007*"radia" + 0.007*"kein" + 0.007*"composed" + 0.006*"tiers"
topic #20 (0.125): 0.012*"google" + 0.010*"nasa" + 0.008*"twitter" + 0.008*"ipad" + 0.007*"iphone" + 0.007*"app" + 0.007*"android" + 0.006*"facebook" + 0.006*"apple" + 0.005*"web"
topic #18 (0.169): 0.011*"news" + 0.010*"wikileaks" + 0.005*"iran" + 0.005*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"cont" + 0.004*"man" + 0.003*"obama"
topic #5 (0.533): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.009*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.004*"video" + 0.004*"life"
topic diff=0.085729, rho=0.297706
PROGRESS: pass 9, at document #2000/4566
performing inference on a chunk of 2000 documents
1974/2000 documents converged within 50 iterations
optimized alpha [0.025887154, 0.025772939, 0.028708538, 0.028706681, 0.025564881, 0.5375417, 0.097969934, 0.026588818, 0.03870802, 0.105413094, 0.019063277, 0.044200994, 0.07051478, 0.024030052, 0.02067887, 0.023536816, 0.04446459, 0.123970166, 0.17226657, 0.026863746, 0.123560265, 0.05528276, 0.020117398, 0.04066496, 0.106065296, 0.025720287, 0.03477211, 0.08847367, 0.025331588, 0.037692387]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.019): 0.016*"fewer" + 0.015*"jobs" + 0.015*"economy" + 0.013*"expected" + 0.013*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.004*"nyt" + 0.004*"aristotle"
topic #22 (0.020): 0.023*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.008*"einen" + 0.006*"jaejoongs" + 0.006*"pasa" + 0.006*"radia" + 0.006*"kein" + 0.005*"composed" + 0.005*"tiers"
topic #17 (0.124): 0.009*"cop" + 0.009*"climate" + 0.007*"green" + 0.005*"dec" + 0.005*"energy" + 0.005*"change" + 0.005*"cancun" + 0.004*"art" + 0.004*"video" + 0.004*"today"
topic #18 (0.172): 0.011*"news" + 0.010*"wikileaks" + 0.005*"iran" + 0.005*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.003*"cont" + 0.003*"obama" + 0.003*"man"
topic #5 (0.538): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.004*"video" + 0.004*"life"
topic diff=0.070978, rho=0.285330
PROGRESS: pass 9, at document #4000/4566
performing inference on a chunk of 2000 documents
1978/2000 documents converged within 50 iterations
optimized alpha [0.026074301, 0.025840312, 0.028949685, 0.028867569, 0.025690243, 0.575826, 0.10015128, 0.026675075, 0.039451886, 0.108983554, 0.018970732, 0.045035668, 0.07249068, 0.024000868, 0.02066474, 0.023512032, 0.045268394, 0.12856916, 0.18029487, 0.026965221, 0.12840776, 0.057177044, 0.020025153, 0.04124075, 0.10986162, 0.025808515, 0.035133578, 0.09135539, 0.025335051, 0.038300868]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.019): 0.016*"fewer" + 0.016*"jobs" + 0.014*"economy" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.006*"aristotle" + 0.005*"alert" + 0.005*"jobless"
topic #22 (0.020): 0.018*"jyj" + 0.011*"radia" + 0.010*"tvxq" + 0.007*"ezb" + 0.007*"arun" + 0.007*"einen" + 0.006*"shourie" + 0.006*"pasa" + 0.005*"jaejoongs" + 0.005*"bogot"
topic #17 (0.129): 0.009*"climate" + 0.008*"cop" + 0.007*"green" + 0.006*"dec" + 0.005*"energy" + 0.005*"change" + 0.004*"cancun" + 0.004*"art" + 0.004*"today" + 0.004*"video"
topic #18 (0.180): 0.011*"news" + 0.010*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"police" + 0.004*"state" + 0.004*"korea" + 0.003*"cont" + 0.003*"obama" + 0.003*"man"
topic #5 (0.576): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.049630, rho=0.285330
bound: at document #0
-13.944 per-word bound, 15763.4 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 9, at document #4566/4566
performing inference on a chunk of 566 documents
562/566 documents converged within 50 iterations
optimized alpha [0.026127353, 0.02591638, 0.029106967, 0.02894346, 0.025683008, 0.597219, 0.101748206, 0.026741996, 0.039863236, 0.112760045, 0.018863436, 0.04583578, 0.07424741, 0.023997867, 0.020613147, 0.02353905, 0.045991395, 0.13126501, 0.18217564, 0.026957987, 0.1331642, 0.058655802, 0.020009466, 0.041819513, 0.1107447, 0.025774786, 0.035426423, 0.09457448, 0.025390081, 0.038775407]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.019): 0.016*"fewer" + 0.015*"jobs" + 0.015*"economy" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.005*"aristotle" + 0.005*"trunk" + 0.005*"ihr"
topic #22 (0.020): 0.029*"jyj" + 0.015*"tvxq" + 0.013*"ezb" + 0.011*"einen" + 0.008*"jaejoongs" + 0.008*"pasa" + 0.008*"radia" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.133): 0.013*"google" + 0.011*"nasa" + 0.008*"twitter" + 0.008*"ipad" + 0.007*"app" + 0.007*"iphone" + 0.007*"android" + 0.007*"facebook" + 0.006*"apple" + 0.006*"web"
topic #18 (0.182): 0.011*"news" + 0.010*"wikileaks" + 0.005*"iran" + 0.005*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"man" + 0.004*"cont" + 0.003*"obama"
topic #5 (0.597): 0.013*"day" + 0.009*"today" + 0.009*"good" + 0.009*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.004*"video"
topic diff=0.080546, rho=0.285330
PROGRESS: pass 10, at document #2000/4566
performing inference on a chunk of 2000 documents
1984/2000 documents converged within 50 iterations
optimized alpha [0.025863359, 0.025827311, 0.028818829, 0.028725564, 0.025496893, 0.5973948, 0.10351458, 0.02654088, 0.039541367, 0.11241177, 0.01875097, 0.0453756, 0.07351394, 0.024006043, 0.020415602, 0.023380259, 0.04545477, 0.13072637, 0.18530491, 0.026843915, 0.13188076, 0.058154266, 0.019827249, 0.041326534, 0.113295205, 0.025611937, 0.035118334, 0.09415939, 0.025268292, 0.03837764]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.019): 0.016*"fewer" + 0.015*"economy" + 0.015*"jobs" + 0.013*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.004*"nyt" + 0.004*"jobless"
topic #22 (0.020): 0.023*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.008*"einen" + 0.006*"radia" + 0.006*"jaejoongs" + 0.006*"pasa" + 0.005*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.132): 0.014*"google" + 0.010*"nasa" + 0.009*"twitter" + 0.008*"ipad" + 0.008*"app" + 0.007*"iphone" + 0.007*"android" + 0.007*"facebook" + 0.006*"social" + 0.006*"web"
topic #18 (0.185): 0.011*"news" + 0.010*"wikileaks" + 0.005*"iran" + 0.005*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.003*"cont" + 0.003*"obama" + 0.003*"man"
topic #5 (0.597): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"video"
topic diff=0.066976, rho=0.274380
PROGRESS: pass 10, at document #4000/4566
performing inference on a chunk of 2000 documents
1982/2000 documents converged within 50 iterations
optimized alpha [0.02605402, 0.025901532, 0.029054414, 0.028876979, 0.025631916, 0.6346273, 0.10556196, 0.026642881, 0.04027327, 0.11586763, 0.01867347, 0.046197668, 0.075444326, 0.023977656, 0.020423908, 0.02336795, 0.04622464, 0.13526057, 0.19341286, 0.026956681, 0.13673888, 0.060069207, 0.019745028, 0.04189488, 0.11696338, 0.025708646, 0.03547417, 0.09699198, 0.025275726, 0.038977474]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.019): 0.016*"fewer" + 0.015*"jobs" + 0.014*"economy" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.006*"aristotle" + 0.005*"alert" + 0.005*"jobless"
topic #22 (0.020): 0.019*"jyj" + 0.011*"radia" + 0.010*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.007*"arun" + 0.006*"shourie" + 0.006*"pasa" + 0.005*"jaejoongs" + 0.005*"bogot"
topic #20 (0.137): 0.015*"google" + 0.009*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"iphone" + 0.007*"app" + 0.007*"facebook" + 0.007*"android" + 0.007*"social" + 0.006*"web"
topic #18 (0.193): 0.011*"news" + 0.010*"wikileaks" + 0.006*"iran" + 0.005*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.003*"cont" + 0.003*"man" + 0.003*"israel"
topic #5 (0.635): 0.013*"day" + 0.009*"good" + 0.009*"today" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.046370, rho=0.274380
bound: at document #0
-13.937 per-word bound, 15685.2 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 10, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.02612693, 0.025982628, 0.029200912, 0.028974958, 0.02563515, 0.65334636, 0.10696006, 0.026717406, 0.040673148, 0.11941074, 0.01858136, 0.046929494, 0.077188656, 0.023983078, 0.020384688, 0.023403984, 0.04690516, 0.13762902, 0.19464943, 0.02697254, 0.14126301, 0.061519288, 0.019739958, 0.04246177, 0.11751755, 0.025687402, 0.03574778, 0.10009645, 0.025338298, 0.039422527]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.019): 0.016*"fewer" + 0.015*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.005*"aristotle" + 0.005*"alert" + 0.005*"trunk"
topic #22 (0.020): 0.029*"jyj" + 0.015*"tvxq" + 0.013*"ezb" + 0.011*"einen" + 0.008*"jaejoongs" + 0.008*"radia" + 0.008*"pasa" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.141): 0.014*"google" + 0.011*"nasa" + 0.008*"twitter" + 0.008*"ipad" + 0.007*"app" + 0.007*"iphone" + 0.007*"android" + 0.007*"facebook" + 0.006*"apple" + 0.006*"web"
topic #18 (0.195): 0.012*"news" + 0.010*"wikileaks" + 0.005*"iran" + 0.005*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"man" + 0.003*"cont" + 0.003*"obama"
topic #5 (0.653): 0.013*"day" + 0.009*"today" + 0.009*"good" + 0.009*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.076062, rho=0.274380
PROGRESS: pass 11, at document #2000/4566
performing inference on a chunk of 2000 documents
1975/2000 documents converged within 50 iterations
optimized alpha [0.025884451, 0.025903802, 0.028930912, 0.028770724, 0.025465218, 0.649551, 0.108643666, 0.026543757, 0.040354278, 0.11891998, 0.018482737, 0.04646033, 0.07640872, 0.023995373, 0.020202335, 0.023257924, 0.04638077, 0.13689184, 0.19763514, 0.02687132, 0.13978805, 0.060968112, 0.019575438, 0.041987482, 0.11999648, 0.025540873, 0.035451017, 0.0994965, 0.025230076, 0.039034158]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.015*"economy" + 0.015*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.004*"nyt" + 0.004*"aristotle"
topic #22 (0.020): 0.023*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.008*"einen" + 0.007*"radia" + 0.006*"jaejoongs" + 0.006*"pasa" + 0.005*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.140): 0.015*"google" + 0.010*"nasa" + 0.009*"twitter" + 0.008*"ipad" + 0.008*"app" + 0.007*"iphone" + 0.007*"android" + 0.007*"facebook" + 0.006*"social" + 0.006*"web"
topic #18 (0.198): 0.011*"news" + 0.010*"wikileaks" + 0.005*"iran" + 0.005*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.003*"man" + 0.003*"cont" + 0.003*"obama"
topic #5 (0.650): 0.013*"day" + 0.009*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"video"
topic diff=0.062799, rho=0.264600
PROGRESS: pass 11, at document #4000/4566
performing inference on a chunk of 2000 documents
1982/2000 documents converged within 50 iterations
optimized alpha [0.026076302, 0.025982354, 0.029166907, 0.028922275, 0.025603782, 0.68535054, 0.11060897, 0.026654301, 0.041062355, 0.12222314, 0.018412113, 0.04726968, 0.07831388, 0.02397533, 0.020215893, 0.023254825, 0.047133867, 0.14123298, 0.20555168, 0.026992023, 0.14458638, 0.06286368, 0.019505532, 0.042540565, 0.12353354, 0.02563647, 0.035799235, 0.10225837, 0.02524558, 0.03963437]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.015*"jobs" + 0.014*"economy" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.006*"aristotle" + 0.005*"alert" + 0.005*"jobless"
topic #22 (0.020): 0.019*"jyj" + 0.012*"radia" + 0.010*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.007*"arun" + 0.006*"shourie" + 0.006*"pasa" + 0.005*"jaejoongs" + 0.005*"bogot"
topic #20 (0.145): 0.016*"google" + 0.009*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"iphone" + 0.008*"app" + 0.007*"facebook" + 0.007*"android" + 0.007*"social" + 0.006*"web"
topic #18 (0.206): 0.011*"news" + 0.010*"wikileaks" + 0.006*"iran" + 0.005*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.003*"man" + 0.003*"cont" + 0.003*"israel"
topic #5 (0.685): 0.013*"day" + 0.009*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.043380, rho=0.264600
bound: at document #0
-13.931 per-word bound, 15620.6 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 11, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.026141405, 0.02606642, 0.029315103, 0.02902484, 0.025626266, 0.7013854, 0.111756854, 0.02673357, 0.041449707, 0.12553178, 0.018332073, 0.04799959, 0.079969436, 0.023986826, 0.020186257, 0.023297332, 0.047794126, 0.14333017, 0.2060954, 0.02701452, 0.14897925, 0.06428187, 0.019508425, 0.04307433, 0.12376372, 0.025624571, 0.03607001, 0.10523796, 0.025313243, 0.040068466]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.005*"aristotle" + 0.005*"alert" + 0.005*"trunk"
topic #22 (0.020): 0.029*"jyj" + 0.015*"tvxq" + 0.013*"ezb" + 0.011*"einen" + 0.008*"radia" + 0.008*"jaejoongs" + 0.008*"pasa" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.149): 0.015*"google" + 0.011*"nasa" + 0.009*"twitter" + 0.008*"ipad" + 0.008*"app" + 0.007*"iphone" + 0.007*"android" + 0.007*"facebook" + 0.006*"social" + 0.006*"web"
topic #18 (0.206): 0.012*"news" + 0.010*"wikileaks" + 0.005*"iran" + 0.005*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"man" + 0.003*"cont" + 0.003*"obama"
topic #5 (0.701): 0.014*"day" + 0.009*"today" + 0.009*"good" + 0.009*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.072437, rho=0.264600
PROGRESS: pass 12, at document #2000/4566
performing inference on a chunk of 2000 documents
1981/2000 documents converged within 50 iterations
optimized alpha [0.025913741, 0.025998957, 0.029059716, 0.028838461, 0.025469078, 0.6945043, 0.113330774, 0.026572783, 0.041126896, 0.12491766, 0.018242368, 0.04751848, 0.07913523, 0.024004618, 0.020018743, 0.023164162, 0.047284648, 0.14248216, 0.20889261, 0.0269199, 0.14728032, 0.063689135, 0.019358361, 0.04261581, 0.12614956, 0.025487896, 0.035790484, 0.104541354, 0.025215548, 0.039694928]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.004*"nyt" + 0.004*"aristotle"
topic #22 (0.019): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.007*"radia" + 0.006*"pasa" + 0.006*"jaejoongs" + 0.005*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.147): 0.015*"google" + 0.011*"nasa" + 0.009*"twitter" + 0.009*"ipad" + 0.008*"app" + 0.008*"iphone" + 0.007*"android" + 0.007*"facebook" + 0.007*"social" + 0.006*"web"
topic #18 (0.209): 0.011*"news" + 0.010*"wikileaks" + 0.005*"police" + 0.005*"iran" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.003*"man" + 0.003*"cont" + 0.003*"obama"
topic #5 (0.695): 0.013*"day" + 0.009*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.059974, rho=0.255797
PROGRESS: pass 12, at document #4000/4566
performing inference on a chunk of 2000 documents
1981/2000 documents converged within 50 iterations
optimized alpha [0.026105762, 0.026080387, 0.0292911, 0.028992286, 0.025609601, 0.72904444, 0.115131326, 0.026689857, 0.04181083, 0.12826627, 0.018183865, 0.048326448, 0.08096549, 0.023987953, 0.020038443, 0.023165228, 0.04800871, 0.14674355, 0.21667856, 0.027046733, 0.15197648, 0.065580405, 0.019298337, 0.043164436, 0.12961125, 0.025587609, 0.036139324, 0.10716358, 0.025236918, 0.040288936]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.015*"jobs" + 0.014*"economy" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.006*"aristotle" + 0.005*"alert" + 0.005*"jobless"
topic #22 (0.019): 0.019*"jyj" + 0.012*"radia" + 0.010*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.007*"arun" + 0.006*"pasa" + 0.006*"shourie" + 0.005*"jaejoongs" + 0.005*"bogot"
topic #20 (0.152): 0.016*"google" + 0.010*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"app" + 0.008*"iphone" + 0.007*"facebook" + 0.007*"social" + 0.007*"android" + 0.007*"web"
topic #18 (0.217): 0.011*"news" + 0.009*"wikileaks" + 0.006*"iran" + 0.005*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.003*"man" + 0.003*"cont" + 0.003*"israel"
topic #5 (0.729): 0.013*"day" + 0.009*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.041170, rho=0.255797
bound: at document #0
-13.926 per-word bound, 15565.9 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 12, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.026174402, 0.026154755, 0.029426541, 0.02909773, 0.025625894, 0.74318665, 0.11604355, 0.02678408, 0.042185526, 0.1314621, 0.018113656, 0.049055647, 0.08250289, 0.02400407, 0.020016432, 0.023212623, 0.048628047, 0.14851719, 0.21677205, 0.027074106, 0.15614223, 0.06696512, 0.019298902, 0.043685496, 0.1295371, 0.02558303, 0.03640611, 0.10998074, 0.025308188, 0.04071174]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.005*"aristotle" + 0.005*"alert" + 0.005*"trunk"
topic #22 (0.019): 0.029*"jyj" + 0.015*"tvxq" + 0.013*"ezb" + 0.011*"einen" + 0.008*"radia" + 0.008*"jaejoongs" + 0.008*"pasa" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.156): 0.015*"google" + 0.011*"nasa" + 0.009*"twitter" + 0.009*"ipad" + 0.008*"app" + 0.007*"android" + 0.007*"iphone" + 0.007*"facebook" + 0.007*"social" + 0.006*"web"
topic #18 (0.217): 0.012*"news" + 0.009*"wikileaks" + 0.005*"police" + 0.005*"iran" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"man" + 0.003*"cont" + 0.003*"obama"
topic #5 (0.743): 0.014*"day" + 0.009*"today" + 0.009*"good" + 0.009*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.069172, rho=0.255797
PROGRESS: pass 13, at document #2000/4566
performing inference on a chunk of 2000 documents
1986/2000 documents converged within 50 iterations
optimized alpha [0.02595567, 0.026087295, 0.02918341, 0.02892257, 0.025479266, 0.7336449, 0.11755371, 0.026633296, 0.041857425, 0.1307707, 0.01803546, 0.048572667, 0.081611305, 0.024026, 0.019861234, 0.02308999, 0.048114676, 0.14751592, 0.21936452, 0.026987484, 0.15430507, 0.06632211, 0.019158645, 0.043234147, 0.13178694, 0.02545402, 0.036131542, 0.10912975, 0.025219016, 0.04035326]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.004*"nyt" + 0.004*"aristotle"
topic #22 (0.019): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.007*"radia" + 0.006*"pasa" + 0.006*"jaejoongs" + 0.005*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.154): 0.016*"google" + 0.011*"nasa" + 0.009*"twitter" + 0.009*"ipad" + 0.008*"app" + 0.008*"iphone" + 0.007*"android" + 0.007*"facebook" + 0.007*"social" + 0.007*"web"
topic #18 (0.219): 0.011*"news" + 0.009*"wikileaks" + 0.005*"police" + 0.005*"iran" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"man" + 0.003*"cont" + 0.003*"obama"
topic #5 (0.734): 0.013*"day" + 0.009*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.057545, rho=0.247818
PROGRESS: pass 13, at document #4000/4566
performing inference on a chunk of 2000 documents
1989/2000 documents converged within 50 iterations
optimized alpha [0.026146982, 0.026164277, 0.029413328, 0.029081002, 0.02561758, 0.7670268, 0.11926104, 0.026751937, 0.042544007, 0.13406858, 0.01798471, 0.04935403, 0.08337964, 0.024011418, 0.019885613, 0.023093715, 0.048810508, 0.15162955, 0.22711761, 0.027112294, 0.15881233, 0.0681904, 0.019106785, 0.04376672, 0.13509431, 0.025559608, 0.036470983, 0.11170327, 0.025244957, 0.040925916]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"jobs" + 0.014*"economy" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.006*"aristotle" + 0.005*"alert" + 0.005*"att"
topic #22 (0.019): 0.019*"jyj" + 0.012*"radia" + 0.010*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.007*"arun" + 0.006*"pasa" + 0.006*"shourie" + 0.005*"jaejoongs" + 0.005*"bogot"
topic #20 (0.159): 0.017*"google" + 0.010*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"app" + 0.008*"social" + 0.008*"iphone" + 0.008*"facebook" + 0.007*"android" + 0.007*"web"
topic #18 (0.227): 0.011*"news" + 0.009*"wikileaks" + 0.006*"iran" + 0.005*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.003*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.767): 0.013*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.039422, rho=0.247818
bound: at document #0
-13.922 per-word bound, 15519.9 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 13, at document #4566/4566
performing inference on a chunk of 566 documents
559/566 documents converged within 50 iterations
optimized alpha [0.026218016, 0.026240235, 0.029549021, 0.029188022, 0.025638277, 0.77926904, 0.120008595, 0.026847752, 0.042906124, 0.13714728, 0.017922567, 0.05006078, 0.08483889, 0.024031065, 0.019869704, 0.02314478, 0.049390372, 0.15328617, 0.22676212, 0.027143251, 0.1629226, 0.06951275, 0.019112762, 0.044274844, 0.13473915, 0.025560686, 0.03673323, 0.114408605, 0.025318697, 0.04133727]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.005*"aristotle" + 0.005*"alert" + 0.005*"trunk"
topic #22 (0.019): 0.029*"jyj" + 0.015*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.008*"radia" + 0.008*"jaejoongs" + 0.008*"pasa" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.163): 0.016*"google" + 0.011*"nasa" + 0.009*"twitter" + 0.009*"ipad" + 0.008*"app" + 0.008*"android" + 0.007*"iphone" + 0.007*"facebook" + 0.007*"social" + 0.007*"web"
topic #18 (0.227): 0.012*"news" + 0.009*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"man" + 0.003*"cont" + 0.003*"israel"
topic #5 (0.779): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.066722, rho=0.247818
PROGRESS: pass 14, at document #2000/4566
performing inference on a chunk of 2000 documents
1978/2000 documents converged within 50 iterations
optimized alpha [0.026009658, 0.026175128, 0.029316155, 0.029021999, 0.025500512, 0.7679362, 0.1214252, 0.026708424, 0.04258201, 0.13630581, 0.017851992, 0.04956995, 0.08389647, 0.024056198, 0.019724932, 0.023031002, 0.048885267, 0.15222225, 0.22913004, 0.027063144, 0.16081654, 0.06883893, 0.018982884, 0.04382901, 0.13685037, 0.025440695, 0.036466617, 0.113379404, 0.025239497, 0.040976]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.004*"nyt" + 0.004*"aristotle"
topic #22 (0.019): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.007*"radia" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.005*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.161): 0.016*"google" + 0.011*"nasa" + 0.009*"twitter" + 0.009*"ipad" + 0.008*"app" + 0.008*"iphone" + 0.008*"android" + 0.007*"social" + 0.007*"facebook" + 0.007*"web"
topic #18 (0.229): 0.011*"news" + 0.009*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"man" + 0.003*"cont" + 0.003*"obama"
topic #5 (0.768): 0.013*"day" + 0.009*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.055303, rho=0.240542
PROGRESS: pass 14, at document #4000/4566
performing inference on a chunk of 2000 documents
1990/2000 documents converged within 50 iterations
optimized alpha [0.026199633, 0.026256574, 0.029543981, 0.029180411, 0.025639156, 0.80039406, 0.12306394, 0.026837243, 0.043239914, 0.13947843, 0.017807612, 0.05033757, 0.085573934, 0.024048576, 0.019752938, 0.023039252, 0.049559813, 0.15624358, 0.2366487, 0.027188512, 0.16518597, 0.07067482, 0.018937731, 0.044355877, 0.14000891, 0.02554484, 0.036800705, 0.115844734, 0.025262764, 0.04154703]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"jobs" + 0.014*"economy" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.006*"aristotle" + 0.005*"alert" + 0.005*"att"
topic #22 (0.019): 0.019*"jyj" + 0.012*"radia" + 0.010*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.007*"arun" + 0.006*"pasa" + 0.006*"shourie" + 0.006*"jaejoongs" + 0.005*"bogot"
topic #20 (0.165): 0.017*"google" + 0.010*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"social" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.007*"web"
topic #18 (0.237): 0.011*"news" + 0.009*"wikileaks" + 0.006*"iran" + 0.006*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.003*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.800): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.037226, rho=0.240542
bound: at document #0
-13.918 per-word bound, 15480.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 14, at document #4566/4566
performing inference on a chunk of 566 documents
562/566 documents converged within 50 iterations
optimized alpha [0.0262609, 0.02633325, 0.029679056, 0.029287932, 0.025663061, 0.81100595, 0.12370699, 0.026933488, 0.04358941, 0.14233509, 0.017752128, 0.051021647, 0.08695744, 0.02407079, 0.019741919, 0.023092931, 0.050101243, 0.15767665, 0.23597792, 0.027221879, 0.16907337, 0.07190296, 0.018947963, 0.044850666, 0.13940369, 0.025550265, 0.037057705, 0.1183937, 0.025338054, 0.041946575]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.005*"aristotle" + 0.005*"alert" + 0.005*"trunk"
topic #22 (0.019): 0.028*"jyj" + 0.015*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.008*"radia" + 0.008*"jaejoongs" + 0.008*"pasa" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.169): 0.016*"google" + 0.012*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"app" + 0.008*"android" + 0.007*"iphone" + 0.007*"facebook" + 0.007*"social" + 0.007*"web"
topic #18 (0.236): 0.012*"news" + 0.009*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"cont" + 0.003*"israel"
topic #5 (0.811): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.063650, rho=0.240542
PROGRESS: pass 15, at document #2000/4566
performing inference on a chunk of 2000 documents
1976/2000 documents converged within 50 iterations
optimized alpha [0.02605544, 0.026275618, 0.02945477, 0.029129477, 0.025532698, 0.79819447, 0.124989204, 0.026800651, 0.04325866, 0.14133163, 0.017687974, 0.05052247, 0.08596194, 0.024095539, 0.019606043, 0.02298656, 0.04959751, 0.15653484, 0.2382134, 0.027147062, 0.16678089, 0.07117183, 0.01882694, 0.044408586, 0.14141655, 0.025437847, 0.03679743, 0.117229864, 0.025264474, 0.04159097]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.004*"nyt" + 0.004*"aristotle"
topic #22 (0.019): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.007*"radia" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.167): 0.017*"google" + 0.011*"nasa" + 0.009*"twitter" + 0.009*"ipad" + 0.008*"app" + 0.008*"social" + 0.008*"iphone" + 0.008*"android" + 0.007*"facebook" + 0.007*"web"
topic #18 (0.238): 0.011*"news" + 0.009*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"man" + 0.003*"cont" + 0.003*"obama"
topic #5 (0.798): 0.014*"day" + 0.009*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.053444, rho=0.233871
PROGRESS: pass 15, at document #4000/4566
performing inference on a chunk of 2000 documents
1990/2000 documents converged within 50 iterations
optimized alpha [0.026243828, 0.026354713, 0.029680127, 0.029287325, 0.02567116, 0.8298413, 0.12653688, 0.026932348, 0.04389371, 0.14440803, 0.017651021, 0.051276755, 0.08755829, 0.024088288, 0.019636871, 0.022995742, 0.05025718, 0.1604933, 0.2456201, 0.027275585, 0.1710047, 0.072990425, 0.018787393, 0.044919368, 0.1444529, 0.025543064, 0.03712577, 0.1196132, 0.025293538, 0.042160418]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"jobs" + 0.014*"economy" + 0.012*"november" + 0.011*"expected" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.006*"aristotle" + 0.005*"alert"
topic #22 (0.019): 0.019*"jyj" + 0.012*"radia" + 0.010*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.007*"arun" + 0.006*"pasa" + 0.006*"shourie" + 0.006*"jaejoongs" + 0.005*"bogot"
topic #20 (0.171): 0.018*"google" + 0.010*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"social" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.007*"web"
topic #18 (0.246): 0.011*"news" + 0.009*"wikileaks" + 0.006*"iran" + 0.006*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.003*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.830): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.036040, rho=0.233871
bound: at document #0
-13.915 per-word bound, 15448.1 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 15, at document #4566/4566
performing inference on a chunk of 566 documents
561/566 documents converged within 50 iterations
optimized alpha [0.026306568, 0.026431736, 0.029814258, 0.029382814, 0.025697615, 0.83934826, 0.12705433, 0.027028583, 0.0442315, 0.14716418, 0.017601186, 0.051939357, 0.088840015, 0.024102917, 0.019629933, 0.023051478, 0.050783273, 0.16166668, 0.2446875, 0.027310727, 0.17471512, 0.074186675, 0.018801142, 0.04540158, 0.14376608, 0.025552033, 0.03737756, 0.122015886, 0.025369681, 0.04254837]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.005*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.019): 0.028*"jyj" + 0.015*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"jaejoongs" + 0.008*"pasa" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.175): 0.017*"google" + 0.012*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"app" + 0.008*"android" + 0.008*"facebook" + 0.007*"iphone" + 0.007*"social" + 0.007*"web"
topic #18 (0.245): 0.012*"news" + 0.009*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.839): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.061716, rho=0.233871
PROGRESS: pass 16, at document #2000/4566
performing inference on a chunk of 2000 documents
1986/2000 documents converged within 50 iterations
optimized alpha [0.026109207, 0.026377685, 0.029597342, 0.029231073, 0.025576558, 0.8252912, 0.12825017, 0.026904257, 0.04389935, 0.14605917, 0.0175425, 0.051432002, 0.08782199, 0.024132406, 0.01950178, 0.02295153, 0.050280362, 0.1604179, 0.24683934, 0.027243303, 0.17234325, 0.073392406, 0.018687747, 0.044962637, 0.14568317, 0.025446046, 0.037122473, 0.120765485, 0.025300909, 0.042192515]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.004*"nyt" + 0.004*"aristotle"
topic #22 (0.019): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.007*"radia" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.172): 0.017*"google" + 0.011*"nasa" + 0.009*"twitter" + 0.009*"ipad" + 0.008*"app" + 0.008*"social" + 0.008*"iphone" + 0.008*"android" + 0.008*"facebook" + 0.007*"web"
topic #18 (0.247): 0.011*"news" + 0.009*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"man" + 0.003*"cont" + 0.003*"obama"
topic #5 (0.825): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.051171, rho=0.227726
PROGRESS: pass 16, at document #4000/4566
performing inference on a chunk of 2000 documents
1986/2000 documents converged within 50 iterations
optimized alpha [0.026295781, 0.026460147, 0.029819842, 0.029388098, 0.025714446, 0.8563586, 0.12971272, 0.027041472, 0.044527292, 0.14902714, 0.017508047, 0.052173674, 0.089349635, 0.024130639, 0.01953264, 0.022963775, 0.050920162, 0.16422716, 0.2542024, 0.02737445, 0.17644951, 0.075202145, 0.018652942, 0.045462824, 0.14861953, 0.02555187, 0.037441224, 0.123104915, 0.025335014, 0.042746037]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.018): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.011*"expected" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.006*"aristotle" + 0.005*"alert"
topic #22 (0.019): 0.020*"jyj" + 0.011*"radia" + 0.010*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.007*"arun" + 0.006*"pasa" + 0.006*"shourie" + 0.006*"jaejoongs" + 0.005*"bogot"
topic #20 (0.176): 0.018*"google" + 0.010*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.007*"web"
topic #18 (0.254): 0.011*"news" + 0.009*"wikileaks" + 0.006*"iran" + 0.006*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.003*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.856): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.034722, rho=0.227726
bound: at document #0
-13.913 per-word bound, 15423.4 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 16, at document #4566/4566
performing inference on a chunk of 566 documents
562/566 documents converged within 50 iterations
optimized alpha [0.02635947, 0.026537085, 0.029952679, 0.029483635, 0.025742786, 0.86483634, 0.13017456, 0.027137188, 0.044853553, 0.15169215, 0.017463058, 0.052815553, 0.09057037, 0.024147142, 0.019529121, 0.023021024, 0.05143149, 0.16529137, 0.25296554, 0.027399726, 0.17999613, 0.07634007, 0.01866955, 0.045932718, 0.14779791, 0.02556365, 0.037687726, 0.12536912, 0.025411628, 0.04310612]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.006*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.019): 0.028*"jyj" + 0.015*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"jaejoongs" + 0.008*"pasa" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.180): 0.017*"google" + 0.012*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"app" + 0.008*"android" + 0.008*"social" + 0.008*"facebook" + 0.008*"iphone" + 0.007*"web"
topic #18 (0.253): 0.012*"news" + 0.009*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.865): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.059765, rho=0.227726
PROGRESS: pass 17, at document #2000/4566
performing inference on a chunk of 2000 documents
1992/2000 documents converged within 50 iterations
optimized alpha [0.026169166, 0.026485993, 0.029742142, 0.029340908, 0.02562717, 0.84988743, 0.13127716, 0.027026478, 0.044519525, 0.15057872, 0.017409114, 0.052300353, 0.08951568, 0.024178242, 0.019407757, 0.022926606, 0.050929144, 0.16396342, 0.25496745, 0.027332975, 0.17751515, 0.075501494, 0.018562835, 0.045501195, 0.14958557, 0.025460463, 0.037437066, 0.12402377, 0.02534404, 0.042755075]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.004*"att" + 0.004*"nyt"
topic #22 (0.019): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.007*"radia" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.178): 0.017*"google" + 0.011*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"app" + 0.008*"social" + 0.008*"iphone" + 0.008*"android" + 0.008*"facebook" + 0.007*"web"
topic #18 (0.255): 0.011*"news" + 0.009*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.004*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"cont" + 0.003*"putin"
topic #5 (0.850): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.049648, rho=0.222041
PROGRESS: pass 17, at document #4000/4566
performing inference on a chunk of 2000 documents
1981/2000 documents converged within 50 iterations
optimized alpha [0.026350735, 0.026565488, 0.029961877, 0.029496737, 0.025764156, 0.88023084, 0.13268992, 0.027162446, 0.04514047, 0.15344521, 0.017378528, 0.053011563, 0.091015, 0.024181245, 0.01944051, 0.022941316, 0.051555365, 0.16769013, 0.26220465, 0.027466359, 0.18154433, 0.077294536, 0.01853205, 0.045990735, 0.15242396, 0.02556648, 0.037741877, 0.12628546, 0.02537967, 0.043293085]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.006*"aristotle" + 0.005*"alert"
topic #22 (0.019): 0.020*"jyj" + 0.011*"radia" + 0.010*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.006*"arun" + 0.006*"pasa" + 0.006*"jaejoongs" + 0.006*"shourie" + 0.005*"bogot"
topic #20 (0.182): 0.018*"google" + 0.010*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.007*"web"
topic #18 (0.262): 0.011*"news" + 0.009*"wikileaks" + 0.006*"iran" + 0.006*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.880): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.033504, rho=0.222041
bound: at document #0
-13.910 per-word bound, 15396.5 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 17, at document #4566/4566
performing inference on a chunk of 566 documents
563/566 documents converged within 50 iterations
optimized alpha [0.026414976, 0.02664205, 0.030093113, 0.029591851, 0.025793858, 0.8879639, 0.13306636, 0.02725722, 0.045455296, 0.15591154, 0.017337695, 0.05363365, 0.09217869, 0.02419911, 0.019439824, 0.022999618, 0.052052222, 0.16859527, 0.26066634, 0.027503507, 0.18485808, 0.07840964, 0.018550994, 0.04644843, 0.15144554, 0.025580488, 0.03798309, 0.12842037, 0.025446411, 0.043642905]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.006*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.019): 0.028*"jyj" + 0.014*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.008*"jaejoongs" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.185): 0.017*"google" + 0.012*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"app" + 0.008*"social" + 0.008*"android" + 0.008*"facebook" + 0.008*"iphone" + 0.007*"web"
topic #18 (0.261): 0.012*"news" + 0.009*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.888): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.057581, rho=0.222041
PROGRESS: pass 18, at document #2000/4566
performing inference on a chunk of 2000 documents
1987/2000 documents converged within 50 iterations
optimized alpha [0.026230833, 0.026593374, 0.029888045, 0.029453924, 0.025682868, 0.87223536, 0.13408239, 0.02715, 0.045118958, 0.15468346, 0.017287843, 0.053105738, 0.09111985, 0.024231307, 0.019324424, 0.02290753, 0.05154995, 0.1671942, 0.26258913, 0.027442604, 0.18225428, 0.077514306, 0.018450119, 0.04601861, 0.15312825, 0.02548216, 0.037727997, 0.1270061, 0.025385175, 0.043291435]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.005*"att" + 0.004*"nyt"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.007*"radia" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.182): 0.018*"google" + 0.011*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.009*"app" + 0.008*"social" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.007*"web"
topic #18 (0.263): 0.011*"news" + 0.009*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.004*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"cont" + 0.003*"putin"
topic #5 (0.872): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.048185, rho=0.216762
PROGRESS: pass 18, at document #4000/4566
performing inference on a chunk of 2000 documents
1979/2000 documents converged within 50 iterations
optimized alpha [0.0264131, 0.026669754, 0.030104894, 0.02960835, 0.02581878, 0.9019854, 0.1354381, 0.027287519, 0.045723155, 0.15748933, 0.017260592, 0.053799883, 0.09256268, 0.024238532, 0.019358695, 0.022924278, 0.052157037, 0.17084883, 0.2697333, 0.027571809, 0.1862609, 0.07927821, 0.018424809, 0.04650286, 0.15584438, 0.025585335, 0.03801935, 0.1291719, 0.02541931, 0.043824]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.006*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.020*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.006*"arun" + 0.006*"pasa" + 0.006*"jaejoongs" + 0.006*"shourie" + 0.005*"bogot"
topic #20 (0.186): 0.019*"google" + 0.010*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.008*"web"
topic #18 (0.270): 0.011*"news" + 0.008*"wikileaks" + 0.006*"iran" + 0.006*"police" + 0.005*"bbc" + 0.004*"state" + 0.004*"korea" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.902): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.032355, rho=0.216762
bound: at document #0
-13.908 per-word bound, 15372.8 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 18, at document #4566/4566
performing inference on a chunk of 566 documents
563/566 documents converged within 50 iterations
optimized alpha [0.026477437, 0.026745655, 0.030234233, 0.029702652, 0.025849372, 0.9090344, 0.13571472, 0.027381023, 0.046008755, 0.15971355, 0.017223317, 0.05440276, 0.09367209, 0.024257299, 0.019360341, 0.022983262, 0.05263966, 0.17154737, 0.26784742, 0.02760918, 0.18929203, 0.08033949, 0.018445607, 0.046948373, 0.15471868, 0.025601055, 0.038255285, 0.13123748, 0.025486197, 0.0441635]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.006*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.028*"jyj" + 0.014*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.008*"jaejoongs" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.189): 0.018*"google" + 0.012*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"app" + 0.008*"social" + 0.008*"android" + 0.008*"facebook" + 0.008*"iphone" + 0.007*"web"
topic #18 (0.268): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.909): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.056161, rho=0.216762
PROGRESS: pass 19, at document #2000/4566
performing inference on a chunk of 2000 documents
1993/2000 documents converged within 50 iterations
optimized alpha [0.026298633, 0.026698994, 0.030030712, 0.029571934, 0.025744978, 0.8926543, 0.13668214, 0.027276667, 0.04567068, 0.15840858, 0.017178861, 0.05387409, 0.09257473, 0.02429024, 0.019250203, 0.022895422, 0.05213725, 0.17003714, 0.26973015, 0.0275506, 0.18656169, 0.07939172, 0.01834986, 0.04651949, 0.15626754, 0.025506942, 0.038003948, 0.12974712, 0.02542807, 0.043811027]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.005*"att" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.007*"radia" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.187): 0.018*"google" + 0.011*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.009*"app" + 0.009*"social" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.008*"web"
topic #18 (0.270): 0.011*"news" + 0.009*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"cont" + 0.003*"putin"
topic #5 (0.893): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.046609, rho=0.211843
PROGRESS: pass 19, at document #4000/4566
performing inference on a chunk of 2000 documents
1984/2000 documents converged within 50 iterations
optimized alpha [0.026478706, 0.026772143, 0.030244606, 0.0297247, 0.025882348, 0.9218644, 0.13798043, 0.027412511, 0.04626372, 0.16115288, 0.017154472, 0.05455154, 0.094002835, 0.024298701, 0.019285657, 0.022913795, 0.052725926, 0.1735781, 0.2767677, 0.027684193, 0.19040489, 0.0811576, 0.018327465, 0.04699349, 0.15890604, 0.025609832, 0.03828599, 0.13183723, 0.025463168, 0.044333365]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.006*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.020*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.006*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.006*"shourie" + 0.005*"bogot"
topic #20 (0.190): 0.019*"google" + 0.011*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.008*"web"
topic #18 (0.277): 0.011*"news" + 0.008*"wikileaks" + 0.006*"iran" + 0.006*"police" + 0.005*"bbc" + 0.004*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.922): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.031857, rho=0.211843
bound: at document #0
-13.906 per-word bound, 15349.2 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 19, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.026542991, 0.026847348, 0.030372074, 0.029818056, 0.025913548, 0.9282777, 0.1382197, 0.027504724, 0.046539318, 0.16327533, 0.017120315, 0.0551363, 0.095025994, 0.02431818, 0.019289313, 0.022973256, 0.053195085, 0.1741614, 0.27458113, 0.027731746, 0.19330129, 0.08216709, 0.018349832, 0.047427565, 0.15765867, 0.025626972, 0.03851691, 0.13384649, 0.025530057, 0.04466315]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.006*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.028*"jyj" + 0.014*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.008*"jaejoongs" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.193): 0.018*"google" + 0.012*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"app" + 0.008*"social" + 0.008*"facebook" + 0.008*"android" + 0.008*"iphone" + 0.007*"web"
topic #18 (0.275): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.928): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.054798, rho=0.211843
PROGRESS: pass 20, at document #2000/4566
performing inference on a chunk of 2000 documents
1991/2000 documents converged within 50 iterations
optimized alpha [0.026369004, 0.026802467, 0.030172916, 0.029690834, 0.025815165, 0.91138697, 0.13913605, 0.027402861, 0.04620439, 0.16190419, 0.017078964, 0.054607183, 0.09391538, 0.024351666, 0.019183887, 0.022889191, 0.052687198, 0.172648, 0.27640796, 0.027674936, 0.19051737, 0.081170894, 0.018258661, 0.046994634, 0.15912744, 0.02553659, 0.03826899, 0.132289, 0.025472049, 0.044309914]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.005*"att" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.191): 0.018*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.008*"web"
topic #18 (0.276): 0.011*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"cont" + 0.003*"putin"
topic #5 (0.911): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.044790, rho=0.207243
PROGRESS: pass 20, at document #4000/4566
performing inference on a chunk of 2000 documents
1987/2000 documents converged within 50 iterations
optimized alpha [0.026549475, 0.026880587, 0.03038382, 0.029841812, 0.025951074, 0.9400136, 0.14037082, 0.027536936, 0.046781763, 0.16453062, 0.017057061, 0.05527396, 0.09531507, 0.024361065, 0.019218298, 0.022908878, 0.053263515, 0.176114, 0.28338003, 0.027804043, 0.19423649, 0.08290643, 0.018236905, 0.047463406, 0.16169484, 0.025639014, 0.038546056, 0.13430707, 0.02550786, 0.044826794]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.013*"economy" + 0.013*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.020*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.006*"shourie" + 0.005*"bogot"
topic #20 (0.194): 0.019*"google" + 0.011*"nasa" + 0.010*"ipad" + 0.009*"social" + 0.009*"twitter" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.008*"web"
topic #18 (0.283): 0.011*"news" + 0.008*"wikileaks" + 0.006*"iran" + 0.006*"police" + 0.005*"bbc" + 0.004*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.940): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.030455, rho=0.207243
bound: at document #0
-13.904 per-word bound, 15330.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 20, at document #4566/4566
performing inference on a chunk of 566 documents
561/566 documents converged within 50 iterations
optimized alpha [0.0266135, 0.026954902, 0.03050935, 0.029934082, 0.025982626, 0.94587433, 0.14053158, 0.027637484, 0.047047798, 0.16658476, 0.017025663, 0.05584131, 0.09629409, 0.02438105, 0.01922369, 0.022968626, 0.05371998, 0.17659457, 0.2809608, 0.027851284, 0.1970135, 0.08389674, 0.018260596, 0.04788648, 0.16034065, 0.025657281, 0.038772035, 0.1362163, 0.025574606, 0.045147177]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.006*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.028*"jyj" + 0.014*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.008*"jaejoongs" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.197): 0.018*"google" + 0.012*"nasa" + 0.009*"ipad" + 0.009*"twitter" + 0.008*"social" + 0.008*"app" + 0.008*"facebook" + 0.008*"android" + 0.008*"iphone" + 0.008*"web"
topic #18 (0.281): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.946): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.053432, rho=0.207243
PROGRESS: pass 21, at document #2000/4566
performing inference on a chunk of 2000 documents
1985/2000 documents converged within 50 iterations
optimized alpha [0.026443832, 0.026911467, 0.030311005, 0.029812943, 0.0258872, 0.92870235, 0.14140418, 0.027540334, 0.04672078, 0.16516387, 0.01698535, 0.05530143, 0.09517327, 0.024414925, 0.019122534, 0.02288795, 0.053207293, 0.1751009, 0.28280023, 0.027796034, 0.19413497, 0.08286437, 0.018173568, 0.047449514, 0.16169524, 0.025570221, 0.038527172, 0.13458595, 0.025516467, 0.044788405]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.005*"att" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.194): 0.018*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.008*"web"
topic #18 (0.283): 0.011*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"cont" + 0.003*"putin"
topic #5 (0.929): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.043983, rho=0.202931
PROGRESS: pass 21, at document #4000/4566
performing inference on a chunk of 2000 documents
1989/2000 documents converged within 50 iterations
optimized alpha [0.026619388, 0.02698615, 0.030522019, 0.029962057, 0.026021622, 0.95682055, 0.14257224, 0.027672462, 0.047283035, 0.16769198, 0.016965665, 0.055957984, 0.09655187, 0.024425093, 0.019159693, 0.022908734, 0.05376738, 0.1785232, 0.28971586, 0.027926233, 0.19779609, 0.08458728, 0.018154105, 0.047913674, 0.16418953, 0.025672078, 0.038791608, 0.13653824, 0.025552846, 0.045291387]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.013*"economy" + 0.013*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.020*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.198): 0.019*"google" + 0.011*"nasa" + 0.010*"ipad" + 0.009*"social" + 0.009*"twitter" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.290): 0.012*"news" + 0.008*"wikileaks" + 0.006*"iran" + 0.006*"police" + 0.005*"bbc" + 0.004*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.957): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.029677, rho=0.202931
bound: at document #0
-13.902 per-word bound, 15309.8 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 21, at document #4566/4566
performing inference on a chunk of 566 documents
563/566 documents converged within 50 iterations
optimized alpha [0.026683116, 0.0270596, 0.030645609, 0.030053161, 0.02605341, 0.9622276, 0.1427044, 0.027771823, 0.047539994, 0.16964893, 0.016936744, 0.05650904, 0.09749021, 0.02444547, 0.01916658, 0.022968633, 0.054191902, 0.17890622, 0.2871916, 0.02797295, 0.20054916, 0.085531235, 0.018178929, 0.04832638, 0.16274853, 0.025691282, 0.039012954, 0.13835768, 0.0256194, 0.04560305]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.006*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.028*"jyj" + 0.014*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.008*"jaejoongs" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.201): 0.018*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.008*"app" + 0.008*"facebook" + 0.008*"android" + 0.008*"iphone" + 0.008*"web"
topic #18 (0.287): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"cont"
topic #5 (0.962): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.052177, rho=0.202931
PROGRESS: pass 22, at document #2000/4566
performing inference on a chunk of 2000 documents
1990/2000 documents converged within 50 iterations
optimized alpha [0.026517402, 0.027017415, 0.030450871, 0.029934758, 0.025960576, 0.9447613, 0.14354406, 0.027676467, 0.04720658, 0.16812946, 0.01690063, 0.05596435, 0.09636125, 0.024479605, 0.019069286, 0.022890974, 0.053675458, 0.17738935, 0.28908423, 0.027918996, 0.19766659, 0.08446628, 0.018095648, 0.047890346, 0.16407792, 0.025607202, 0.038771022, 0.13669436, 0.025563544, 0.045248225]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"alert" + 0.005*"att" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.198): 0.018*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.008*"web"
topic #18 (0.289): 0.011*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"cont" + 0.003*"putin"
topic #5 (0.945): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.043130, rho=0.198878
PROGRESS: pass 22, at document #4000/4566
performing inference on a chunk of 2000 documents
1990/2000 documents converged within 50 iterations
optimized alpha [0.026690803, 0.02709407, 0.030658992, 0.030079093, 0.026093524, 0.9725092, 0.14464028, 0.02780677, 0.047773056, 0.17059164, 0.016882895, 0.056606226, 0.09771354, 0.024490414, 0.019103268, 0.022912694, 0.054224078, 0.18078351, 0.29595748, 0.028041948, 0.20121586, 0.086147495, 0.01807822, 0.048335996, 0.16651902, 0.0257084, 0.03903097, 0.1385859, 0.025597835, 0.045742143]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.013*"economy" + 0.013*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.020*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.008*"ezb" + 0.007*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.201): 0.019*"google" + 0.011*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.296): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.004*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (0.973): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.029022, rho=0.198878
bound: at document #0
-13.901 per-word bound, 15294.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 22, at document #4566/4566
performing inference on a chunk of 566 documents
563/566 documents converged within 50 iterations
optimized alpha [0.026754064, 0.0271665, 0.030780548, 0.030168938, 0.026125362, 0.97748053, 0.14475648, 0.027904354, 0.04802101, 0.17249735, 0.016856141, 0.05714159, 0.098613344, 0.024511002, 0.019111453, 0.022972591, 0.054637805, 0.18107498, 0.29316962, 0.028088037, 0.2038317, 0.08707847, 0.018103965, 0.048738744, 0.16499694, 0.025728293, 0.039234433, 0.14032076, 0.025664069, 0.046045225]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.006*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.028*"jyj" + 0.014*"tvxq" + 0.013*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.008*"jaejoongs" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.204): 0.018*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.008*"app" + 0.008*"facebook" + 0.008*"android" + 0.008*"iphone" + 0.008*"web"
topic #18 (0.293): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"cont"
topic #5 (0.977): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.051025, rho=0.198878
PROGRESS: pass 23, at document #2000/4566
performing inference on a chunk of 2000 documents
1989/2000 documents converged within 50 iterations
optimized alpha [0.026591953, 0.0271254, 0.03058904, 0.030052956, 0.026037393, 0.9598479, 0.14558373, 0.027807774, 0.047685795, 0.17093675, 0.016820617, 0.056592554, 0.097468525, 0.024545286, 0.019017711, 0.022897668, 0.054128118, 0.1795116, 0.29502517, 0.028035266, 0.20096993, 0.08598443, 0.018024076, 0.04830386, 0.16628607, 0.025646875, 0.03899545, 0.13860753, 0.025610242, 0.04568966]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.201): 0.018*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.008*"web"
topic #18 (0.295): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.005*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"cont" + 0.003*"putin"
topic #5 (0.960): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.042080, rho=0.195057
PROGRESS: pass 23, at document #4000/4566
performing inference on a chunk of 2000 documents
1992/2000 documents converged within 50 iterations
optimized alpha [0.026765727, 0.027201202, 0.030794257, 0.030192478, 0.026168799, 0.9871464, 0.14662573, 0.027936237, 0.04824234, 0.1733064, 0.016804637, 0.057209432, 0.09878642, 0.024556538, 0.019054126, 0.022920124, 0.054655634, 0.18292929, 0.30180708, 0.02815394, 0.20442031, 0.087647244, 0.018008422, 0.04874563, 0.1686736, 0.025747303, 0.039247524, 0.14044887, 0.02564486, 0.046179026]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.013*"economy" + 0.013*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.020*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.009*"ezb" + 0.007*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.204): 0.019*"google" + 0.011*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.302): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"report"
topic #5 (0.987): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.028545, rho=0.195057
bound: at document #0
-13.899 per-word bound, 15279.9 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 23, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.026828418, 0.027272576, 0.03091378, 0.03028105, 0.026200539, 0.9918633, 0.14668031, 0.028041946, 0.04848171, 0.17515996, 0.016779842, 0.057730135, 0.0996508, 0.024577226, 0.019063419, 0.022979913, 0.055039283, 0.18319842, 0.29872903, 0.028199354, 0.20690086, 0.088536054, 0.018034942, 0.049138762, 0.1670287, 0.025767725, 0.039446995, 0.14210464, 0.025710681, 0.046473816]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.028*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.008*"jaejoongs" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.207): 0.018*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.008*"app" + 0.008*"facebook" + 0.008*"android" + 0.008*"iphone" + 0.008*"web"
topic #18 (0.299): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"cont"
topic #5 (0.992): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.049820, rho=0.195057
PROGRESS: pass 24, at document #2000/4566
performing inference on a chunk of 2000 documents
1983/2000 documents converged within 50 iterations
optimized alpha [0.026669517, 0.027234977, 0.030725192, 0.030167166, 0.026114624, 0.9741109, 0.14748892, 0.027946658, 0.04814941, 0.17355546, 0.01674637, 0.05717793, 0.098502964, 0.024611557, 0.018972876, 0.022907441, 0.054532252, 0.18156494, 0.30060163, 0.02814765, 0.2040333, 0.08740874, 0.01795813, 0.048704837, 0.16826542, 0.025688693, 0.039206836, 0.14036234, 0.02565867, 0.04611296]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.204): 0.019*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.301): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"cont" + 0.003*"israel"
topic #5 (0.974): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.040971, rho=0.191449
PROGRESS: pass 24, at document #4000/4566
performing inference on a chunk of 2000 documents
1992/2000 documents converged within 50 iterations
optimized alpha [0.026841098, 0.027312333, 0.030930506, 0.030302031, 0.026244458, 1.0009707, 0.14849047, 0.02807849, 0.048691925, 0.17586836, 0.016731916, 0.057781514, 0.099787705, 0.024623131, 0.019007899, 0.022930453, 0.05505505, 0.18488052, 0.30729952, 0.028264754, 0.20735347, 0.089038245, 0.017942337, 0.04913812, 0.17059188, 0.025788277, 0.039454766, 0.1421565, 0.025693493, 0.046593703]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.013*"economy" + 0.013*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.020*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.207): 0.019*"google" + 0.011*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.307): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"report"
topic #5 (1.001): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.027651, rho=0.191449
bound: at document #0
-13.898 per-word bound, 15266.5 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 24, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.026903115, 0.027382536, 0.03104793, 0.0303893, 0.026275985, 1.0053056, 0.14848313, 0.028172854, 0.048922975, 0.17766991, 0.016708864, 0.05828812, 0.10061891, 0.024643809, 0.019018145, 0.02299003, 0.05542933, 0.18507417, 0.30402344, 0.028309405, 0.20970596, 0.089916304, 0.017969502, 0.04952194, 0.16890725, 0.025809068, 0.039650317, 0.14369328, 0.025758795, 0.046880532]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.008*"jaejoongs" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.210): 0.018*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.009*"app" + 0.008*"facebook" + 0.008*"android" + 0.008*"iphone" + 0.008*"web"
topic #18 (0.304): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"cont"
topic #5 (1.005): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"love" + 0.008*"dont" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.048993, rho=0.191449
PROGRESS: pass 25, at document #2000/4566
performing inference on a chunk of 2000 documents
1989/2000 documents converged within 50 iterations
optimized alpha [0.026747195, 0.027345553, 0.030861996, 0.030277476, 0.0261919, 0.98744106, 0.14924793, 0.028078804, 0.048584566, 0.17603353, 0.016677251, 0.057733193, 0.099451795, 0.024678119, 0.018930579, 0.022921968, 0.054924607, 0.18345422, 0.3059398, 0.028258625, 0.20685929, 0.0887741, 0.017893834, 0.049089063, 0.1701398, 0.025732188, 0.039416503, 0.1419369, 0.025706004, 0.046523575]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.007*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.207): 0.019*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.306): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"cont" + 0.003*"israel"
topic #5 (0.987): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.040431, rho=0.188034
PROGRESS: pass 25, at document #4000/4566
performing inference on a chunk of 2000 documents
1992/2000 documents converged within 50 iterations
optimized alpha [0.026916657, 0.027421873, 0.031067386, 0.030410636, 0.026320193, 1.0139248, 0.15019965, 0.028208738, 0.049122624, 0.17826831, 0.01666419, 0.05832432, 0.10068689, 0.024689944, 0.018967718, 0.022945445, 0.055432864, 0.18668191, 0.31260675, 0.028374152, 0.21011268, 0.09038928, 0.01787782, 0.04951864, 0.17239021, 0.025830902, 0.039660405, 0.14367792, 0.025740953, 0.046991654]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.020*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.210): 0.019*"google" + 0.011*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.313): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"report"
topic #5 (1.014): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.027206, rho=0.188034
bound: at document #0
-13.897 per-word bound, 15253.8 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 25, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.026977979, 0.027490905, 0.031182714, 0.03049659, 0.026351457, 1.0179743, 0.15013742, 0.028292067, 0.049345806, 0.17997688, 0.016642716, 0.058817625, 0.10148862, 0.024710555, 0.018978782, 0.023004733, 0.05579836, 0.18680698, 0.30913275, 0.028417962, 0.21233913, 0.09123265, 0.017905558, 0.049893506, 0.1707689, 0.025851967, 0.03985214, 0.14510098, 0.025805729, 0.047270883]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.008*"jaejoongs" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.212): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.008*"web"
topic #18 (0.309): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"cont"
topic #5 (1.018): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.047971, rho=0.188034
PROGRESS: pass 26, at document #2000/4566
performing inference on a chunk of 2000 documents
1992/2000 documents converged within 50 iterations
optimized alpha [0.026824703, 0.027456963, 0.03099902, 0.030386541, 0.026268937, 0.9999304, 0.15084635, 0.02820428, 0.049010318, 0.17830217, 0.016612757, 0.05825994, 0.10033186, 0.024744712, 0.018893875, 0.022936447, 0.055295523, 0.18520547, 0.31093365, 0.028362669, 0.20946817, 0.09008579, 0.017832544, 0.049461197, 0.17194644, 0.025776962, 0.039616708, 0.14333482, 0.02575676, 0.046908747]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.005*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.007*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.209): 0.019*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.311): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"cont" + 0.003*"israel"
topic #5 (1.000): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.039380, rho=0.184796
PROGRESS: pass 26, at document #4000/4566
performing inference on a chunk of 2000 documents
1992/2000 documents converged within 50 iterations
optimized alpha [0.02699207, 0.027537284, 0.031201577, 0.030518021, 0.026395695, 1.0259515, 0.15178075, 0.028332366, 0.04954866, 0.18049887, 0.016600944, 0.058828093, 0.101538725, 0.024758967, 0.018929519, 0.022960305, 0.05580015, 0.18843102, 0.3175155, 0.028479226, 0.21270087, 0.09166918, 0.017817928, 0.04988288, 0.17414093, 0.025874786, 0.039853126, 0.14503048, 0.025791736, 0.04736462]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.020*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.213): 0.020*"google" + 0.011*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.318): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"report"
topic #5 (1.026): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026523, rho=0.184796
bound: at document #0
-13.896 per-word bound, 15242.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 26, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.027052632, 0.02760504, 0.031314757, 0.030602608, 0.026426604, 1.0296471, 0.15166914, 0.028414134, 0.04976396, 0.18211648, 0.016580887, 0.05930883, 0.10231217, 0.024779394, 0.018941298, 0.023019252, 0.056156993, 0.18848804, 0.31389433, 0.028522182, 0.21482311, 0.09247584, 0.017846126, 0.050249077, 0.17248666, 0.025895994, 0.04004115, 0.146399, 0.02585587, 0.04763661]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.008*"jaejoongs" + 0.007*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.215): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"android" + 0.008*"web"
topic #18 (0.314): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"cont"
topic #5 (1.030): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.047229, rho=0.184796
PROGRESS: pass 27, at document #2000/4566
performing inference on a chunk of 2000 documents
1990/2000 documents converged within 50 iterations
optimized alpha [0.026901793, 0.027568886, 0.031130385, 0.030494122, 0.0263455, 1.011486, 0.15233847, 0.028327277, 0.04942209, 0.18040074, 0.01655243, 0.058749214, 0.10114028, 0.024813283, 0.018858872, 0.022952778, 0.05565588, 0.18685843, 0.31566998, 0.028467618, 0.2119568, 0.091312215, 0.017775558, 0.049822006, 0.1736153, 0.025822688, 0.039811462, 0.14462656, 0.025808139, 0.0472784]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.007*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.212): 0.019*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.316): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (1.011): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.038478, rho=0.181719
PROGRESS: pass 27, at document #4000/4566
performing inference on a chunk of 2000 documents
1993/2000 documents converged within 50 iterations
optimized alpha [0.0270671, 0.027645646, 0.03133023, 0.03062394, 0.026470765, 1.0371923, 0.15325645, 0.02845352, 0.049951695, 0.18256018, 0.01654175, 0.059311427, 0.10232124, 0.024827613, 0.01889474, 0.022979034, 0.05615182, 0.19002227, 0.32217777, 0.02858264, 0.21511766, 0.09286556, 0.01776219, 0.050236113, 0.17578366, 0.025919612, 0.040044177, 0.1463031, 0.025843091, 0.047731332]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"aristotle" + 0.005*"alert"
topic #22 (0.018): 0.021*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.215): 0.020*"google" + 0.011*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.008*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.322): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"report"
topic #5 (1.037): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026115, rho=0.181719
bound: at document #0
-13.895 per-word bound, 15231.6 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 27, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.027126884, 0.027712187, 0.031441346, 0.03070717, 0.026501281, 1.040637, 0.15309934, 0.02852458, 0.050159585, 0.18415864, 0.016522978, 0.059780158, 0.10306891, 0.024847824, 0.018907141, 0.023037577, 0.056500405, 0.19001928, 0.3184012, 0.028624738, 0.21713877, 0.09363799, 0.01779077, 0.050593946, 0.17409095, 0.025940895, 0.040228553, 0.14757179, 0.025906557, 0.04799629]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.017): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.008*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.217): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"social" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.318): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"cont"
topic #5 (1.041): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.046485, rho=0.181719
PROGRESS: pass 28, at document #2000/4566
performing inference on a chunk of 2000 documents
1988/2000 documents converged within 50 iterations
optimized alpha [0.02697832, 0.027676377, 0.031259023, 0.030597411, 0.026421499, 1.0224279, 0.15372987, 0.028438717, 0.049820766, 0.18239224, 0.016495911, 0.059218936, 0.101884514, 0.024881404, 0.01882701, 0.022972735, 0.056001164, 0.18839602, 0.32019258, 0.028563276, 0.21424273, 0.092465974, 0.017722454, 0.050167434, 0.17521076, 0.02586916, 0.040000767, 0.14581789, 0.025859974, 0.047637697]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.007*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.214): 0.019*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.009*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.320): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (1.022): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.037939, rho=0.178791
PROGRESS: pass 28, at document #4000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.02714166, 0.027754515, 0.031456217, 0.03072563, 0.026545303, 1.0478362, 0.15461195, 0.028560756, 0.050333325, 0.1845185, 0.01648627, 0.05977037, 0.10304943, 0.024895752, 0.018863043, 0.02299918, 0.056488883, 0.1915028, 0.32668212, 0.028676784, 0.21734306, 0.093998104, 0.01771023, 0.05057873, 0.17733859, 0.025965193, 0.040233474, 0.14747803, 0.02589252, 0.048079323]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.021*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.217): 0.020*"google" + 0.011*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.327): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.048): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.025319, rho=0.178791
bound: at document #0
-13.894 per-word bound, 15221.8 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 28, at document #4566/4566
performing inference on a chunk of 566 documents
562/566 documents converged within 50 iterations
optimized alpha [0.02720063, 0.0278284, 0.031565282, 0.030807508, 0.026575383, 1.0510119, 0.15441522, 0.028630525, 0.05053416, 0.18603757, 0.016468665, 0.06022761, 0.10377294, 0.024915691, 0.018875977, 0.023057282, 0.0568295, 0.19140172, 0.32277066, 0.028718086, 0.21927811, 0.094738364, 0.017739113, 0.050928436, 0.1756112, 0.02598648, 0.040414225, 0.14870036, 0.025947085, 0.048337523]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.008*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.219): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.009*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.323): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"cont"
topic #5 (1.051): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.045421, rho=0.178791
PROGRESS: pass 29, at document #2000/4566
performing inference on a chunk of 2000 documents
1989/2000 documents converged within 50 iterations
optimized alpha [0.027054146, 0.027792694, 0.031387452, 0.030699095, 0.026496751, 1.0326697, 0.155013, 0.028545506, 0.0501985, 0.18422897, 0.01644286, 0.059664927, 0.102603614, 0.024945997, 0.018797964, 0.022993919, 0.05633192, 0.18975711, 0.3245664, 0.028659862, 0.21639223, 0.09355481, 0.017672883, 0.05050229, 0.17667381, 0.025913874, 0.040184468, 0.14693753, 0.025901612, 0.047974236]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.216): 0.019*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.325): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (1.033): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.037178, rho=0.176000
PROGRESS: pass 29, at document #4000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.027215507, 0.027867248, 0.03158203, 0.030825684, 0.026619058, 1.0577507, 0.15586866, 0.028660843, 0.05070756, 0.18631862, 0.016434135, 0.06020589, 0.103753045, 0.024960317, 0.018834079, 0.023020465, 0.056811582, 0.19280642, 0.3310498, 0.02877441, 0.21940194, 0.09505898, 0.017661672, 0.050906368, 0.17873855, 0.026008977, 0.04041009, 0.1485614, 0.02593414, 0.048408605]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.021*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.219): 0.020*"google" + 0.011*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.331): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.058): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024988, rho=0.176000
bound: at document #0
-13.893 per-word bound, 15212.8 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 29, at document #4566/4566
performing inference on a chunk of 566 documents
559/566 documents converged within 50 iterations
optimized alpha [0.027273716, 0.0279485, 0.031689133, 0.030906305, 0.026648736, 1.0607182, 0.15564281, 0.028729448, 0.050901745, 0.18781574, 0.016417619, 0.060652517, 0.1044542, 0.024980048, 0.018847506, 0.023078147, 0.057144858, 0.19266678, 0.32700875, 0.02881493, 0.22130877, 0.0958201, 0.017690834, 0.051248513, 0.17700958, 0.026030296, 0.040587537, 0.14974354, 0.025988286, 0.048660614]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.008*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.221): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.009*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.327): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"cont"
topic #5 (1.061): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.044623, rho=0.176000
PROGRESS: pass 30, at document #2000/4566
performing inference on a chunk of 2000 documents
1990/2000 documents converged within 50 iterations
optimized alpha [0.02712917, 0.027912788, 0.03151302, 0.030801801, 0.026571166, 1.0423282, 0.15624899, 0.028645273, 0.050560266, 0.1860047, 0.016392965, 0.060088743, 0.10326427, 0.025008772, 0.018771455, 0.023016144, 0.056653775, 0.19103174, 0.32875568, 0.028757323, 0.21839015, 0.09460829, 0.017626528, 0.050822865, 0.17800301, 0.02595686, 0.04036298, 0.14798291, 0.025943842, 0.048301242]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.218): 0.019*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.329): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (1.042): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.036488, rho=0.173336
PROGRESS: pass 30, at document #4000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.027288588, 0.027988397, 0.031705007, 0.030926745, 0.02669202, 1.0670652, 0.15708886, 0.028759075, 0.051057227, 0.18805347, 0.016385077, 0.060619626, 0.104391515, 0.025023038, 0.018807627, 0.023042733, 0.057125594, 0.19402772, 0.33516806, 0.02887037, 0.22133423, 0.09609027, 0.017616246, 0.051219996, 0.18002293, 0.026051039, 0.040585123, 0.14958325, 0.02597629, 0.04873303]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.021*"jyj" + 0.011*"radia" + 0.011*"tvxq" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.221): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.335): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.004*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.067): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024535, rho=0.173336
bound: at document #0
-13.892 per-word bound, 15204.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 30, at document #4566/4566
performing inference on a chunk of 566 documents
561/566 documents converged within 50 iterations
optimized alpha [0.027346026, 0.02806824, 0.031810205, 0.031006085, 0.026721274, 1.069838, 0.15691298, 0.02882653, 0.051259633, 0.18950121, 0.016369555, 0.06105613, 0.10507247, 0.025042536, 0.018821483, 0.023099968, 0.057451736, 0.19385093, 0.33103183, 0.028910102, 0.22317342, 0.096829675, 0.01764563, 0.0515549, 0.17829083, 0.026072362, 0.04075932, 0.15072815, 0.02602999, 0.04897896]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.011*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.008*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.223): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.009*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.331): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"cont"
topic #5 (1.070): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.043947, rho=0.173336
PROGRESS: pass 31, at document #2000/4566
performing inference on a chunk of 2000 documents
1989/2000 documents converged within 50 iterations
optimized alpha [0.027203301, 0.028032498, 0.031635687, 0.030900044, 0.0266469, 1.0514688, 0.15746018, 0.028740792, 0.050916884, 0.18766418, 0.016345982, 0.060491722, 0.10389088, 0.025070999, 0.018747283, 0.023039248, 0.05696256, 0.19222215, 0.33276746, 0.028855458, 0.22027744, 0.09560847, 0.01758162, 0.051129933, 0.17925435, 0.02599809, 0.040536303, 0.14898571, 0.025986483, 0.048619464]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.220): 0.019*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.333): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"cont"
topic #5 (1.051): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.035799, rho=0.170789
PROGRESS: pass 31, at document #4000/4566
performing inference on a chunk of 2000 documents
1991/2000 documents converged within 50 iterations
optimized alpha [0.027360851, 0.028111598, 0.03182519, 0.03102341, 0.026766308, 1.0759078, 0.15826921, 0.028853131, 0.05141509, 0.18966039, 0.016338853, 0.061013076, 0.10499737, 0.02508518, 0.018783474, 0.023063958, 0.057426903, 0.19518007, 0.33916417, 0.02896462, 0.22317705, 0.09706728, 0.017572196, 0.051520422, 0.18122876, 0.026091365, 0.040755138, 0.15055245, 0.02601884, 0.04903234]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.223): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.339): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.076): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024148, rho=0.170789
bound: at document #0
-13.891 per-word bound, 15194.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 31, at document #4566/4566
performing inference on a chunk of 566 documents
562/566 documents converged within 50 iterations
optimized alpha [0.027417488, 0.02818995, 0.031928502, 0.031101461, 0.026795063, 1.0784636, 0.15807287, 0.028919443, 0.05161162, 0.19104822, 0.016324235, 0.061439816, 0.10565887, 0.025104403, 0.018797688, 0.02312073, 0.057746053, 0.19496723, 0.33493197, 0.029003521, 0.22497754, 0.097779624, 0.01760175, 0.051848266, 0.17948607, 0.026112646, 0.04092612, 0.15166125, 0.026072038, 0.049272534]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.008*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.225): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.009*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.335): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"cont"
topic #5 (1.078): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.043135, rho=0.170789
PROGRESS: pass 32, at document #2000/4566
performing inference on a chunk of 2000 documents
1985/2000 documents converged within 50 iterations
optimized alpha [0.027276473, 0.028151762, 0.031755432, 0.03099908, 0.02672158, 1.0600524, 0.15861398, 0.028834486, 0.051267453, 0.18920211, 0.016302995, 0.060874946, 0.10448619, 0.025130479, 0.018725205, 0.023061203, 0.05725853, 0.19333677, 0.33661807, 0.028946873, 0.22208424, 0.096556515, 0.017539466, 0.05142398, 0.18039803, 0.026039647, 0.04070108, 0.1499559, 0.026031489, 0.048912972]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.018): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.222): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.337): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.060): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.035496, rho=0.168352
PROGRESS: pass 32, at document #4000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.02743222, 0.028229686, 0.03194257, 0.03112092, 0.026839618, 1.0842419, 0.15939407, 0.02894541, 0.051741257, 0.19118111, 0.016296577, 0.06138237, 0.10558109, 0.025144603, 0.0187614, 0.023085972, 0.05771584, 0.1962522, 0.3430019, 0.02905704, 0.22495757, 0.09799881, 0.017530838, 0.05180821, 0.18235648, 0.026132062, 0.040916767, 0.15150245, 0.026063725, 0.049336065]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.225): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.343): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.084): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.023865, rho=0.168352
bound: at document #0
-13.891 per-word bound, 15186.9 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 32, at document #4566/4566
performing inference on a chunk of 566 documents
563/566 documents converged within 50 iterations
optimized alpha [0.027488057, 0.028306592, 0.032044064, 0.03119761, 0.026867874, 1.0866057, 0.1591691, 0.029019149, 0.051932015, 0.1925079, 0.01628278, 0.061799917, 0.106224015, 0.025163556, 0.018775929, 0.02314227, 0.058028325, 0.1960068, 0.3386874, 0.029095128, 0.22670718, 0.0986849, 0.01756053, 0.05212933, 0.18061942, 0.026153265, 0.041084677, 0.15257643, 0.0261164, 0.04957052]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.008*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.227): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.009*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.339): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"north"
topic #5 (1.087): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.042701, rho=0.168352
PROGRESS: pass 33, at document #2000/4566
performing inference on a chunk of 2000 documents
1988/2000 documents converged within 50 iterations
optimized alpha [0.027348664, 0.028268633, 0.031872403, 0.031096164, 0.026795212, 1.068233, 0.159691, 0.02893482, 0.05158708, 0.19065598, 0.016262434, 0.061235126, 0.105058946, 0.025189402, 0.018705055, 0.023081992, 0.05754253, 0.19436102, 0.34037498, 0.029041318, 0.22382055, 0.09745503, 0.017499868, 0.0517059, 0.18150513, 0.026081454, 0.04086451, 0.15087323, 0.02607667, 0.049210783]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.224): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.340): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.068): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.034887, rho=0.166015
PROGRESS: pass 33, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.027502635, 0.028342983, 0.03205718, 0.031216448, 0.026911875, 1.092164, 0.16044584, 0.029044291, 0.052066855, 0.19259378, 0.016256647, 0.061738614, 0.10613492, 0.025203416, 0.018741202, 0.023104865, 0.057992868, 0.19723742, 0.34666714, 0.029145354, 0.22666527, 0.09887322, 0.017491972, 0.05208398, 0.18343009, 0.026175141, 0.04107024, 0.15238863, 0.026108718, 0.049619492]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.227): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.347): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.092): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.023498, rho=0.166015
bound: at document #0
-13.890 per-word bound, 15180.1 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 33, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.027557686, 0.028418494, 0.03215693, 0.031291865, 0.026939623, 1.0943606, 0.16019556, 0.029125312, 0.052251793, 0.1939029, 0.01624361, 0.06214735, 0.106760435, 0.025222085, 0.018756006, 0.02316071, 0.058298983, 0.196967, 0.3422656, 0.02918266, 0.22835542, 0.09953467, 0.017521767, 0.052398674, 0.18169038, 0.026196213, 0.041235253, 0.15343006, 0.026160859, 0.0498486]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.018): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.008*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.228): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.009*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.342): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"north"
topic #5 (1.094): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.042159, rho=0.166015
PROGRESS: pass 34, at document #2000/4566
performing inference on a chunk of 2000 documents
1988/2000 documents converged within 50 iterations
optimized alpha [0.027419792, 0.028382476, 0.031986557, 0.031191256, 0.02686769, 1.07594, 0.16069652, 0.029041426, 0.051905833, 0.19202287, 0.016224092, 0.061582565, 0.105606236, 0.025247663, 0.018686635, 0.023101524, 0.057814837, 0.19534789, 0.3439122, 0.029126797, 0.22550415, 0.09830965, 0.017462606, 0.051976025, 0.18253998, 0.026125457, 0.041013118, 0.15172556, 0.026121795, 0.04948892]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.226): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.344): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.076): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.034379, rho=0.163774
PROGRESS: pass 34, at document #4000/4566
performing inference on a chunk of 2000 documents
1991/2000 documents converged within 50 iterations
optimized alpha [0.027571995, 0.028460154, 0.032169003, 0.031309985, 0.02698298, 1.0995575, 0.16142362, 0.029149378, 0.05237844, 0.19390395, 0.01621887, 0.062082622, 0.10667165, 0.025261512, 0.018722707, 0.02312628, 0.05826321, 0.19812657, 0.35014477, 0.029231833, 0.22828878, 0.09970764, 0.01745535, 0.05234808, 0.18445459, 0.026218183, 0.041215874, 0.15321104, 0.026153611, 0.049895734]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.228): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.350): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.100): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.023084, rho=0.163774
bound: at document #0
-13.889 per-word bound, 15173.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 34, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.027626226, 0.02853421, 0.03226701, 0.031384107, 0.027010191, 1.1015854, 0.16114931, 0.029229041, 0.05255768, 0.19511816, 0.016206529, 0.062482685, 0.10727988, 0.025279865, 0.018737735, 0.023181623, 0.058562998, 0.19783445, 0.3456573, 0.029268332, 0.22991909, 0.10034495, 0.017485209, 0.052656494, 0.18271227, 0.026239075, 0.041378006, 0.1542226, 0.026205178, 0.050119534]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.008*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.230): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.009*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.346): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"north"
topic #5 (1.102): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.041566, rho=0.163774
PROGRESS: pass 35, at document #2000/4566
performing inference on a chunk of 2000 documents
1985/2000 documents converged within 50 iterations
optimized alpha [0.027489744, 0.028497988, 0.03209787, 0.031284295, 0.026938936, 1.0831794, 0.16162048, 0.029145561, 0.05221509, 0.19321616, 0.016186465, 0.061917968, 0.10612659, 0.025305176, 0.01866978, 0.023123447, 0.05808039, 0.19623534, 0.34726927, 0.02921522, 0.22707835, 0.09911619, 0.017427452, 0.052234728, 0.18356913, 0.026169306, 0.04115729, 0.15252797, 0.026168766, 0.04975583]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.227): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.347): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.083): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.033769, rho=0.161621
PROGRESS: pass 35, at document #4000/4566
performing inference on a chunk of 2000 documents
1989/2000 documents converged within 50 iterations
optimized alpha [0.027640287, 0.028574461, 0.032278143, 0.031401586, 0.027052924, 1.1065987, 0.16232975, 0.029252073, 0.052681413, 0.19508293, 0.016181808, 0.062405087, 0.10718263, 0.025318896, 0.018705782, 0.02314818, 0.05852236, 0.19898815, 0.35345328, 0.029316608, 0.22984022, 0.100510135, 0.01742082, 0.0526012, 0.18545105, 0.026259052, 0.041353934, 0.1540185, 0.026200349, 0.050152943]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.230): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.353): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.107): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.022655, rho=0.161621
bound: at document #0
-13.889 per-word bound, 15167.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 35, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.027693737, 0.028647134, 0.03237451, 0.031474486, 0.02707963, 1.1085075, 0.16203377, 0.029330404, 0.052855253, 0.19629459, 0.016170124, 0.06279712, 0.10777501, 0.025344014, 0.018721014, 0.023203047, 0.058816217, 0.19867377, 0.34889248, 0.029352343, 0.23140799, 0.10112481, 0.017450728, 0.052903716, 0.18369885, 0.02627979, 0.041513402, 0.15499938, 0.026251348, 0.050371878]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.231): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.349): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"north"
topic #5 (1.109): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.041238, rho=0.161621
PROGRESS: pass 36, at document #2000/4566
performing inference on a chunk of 2000 documents
1990/2000 documents converged within 50 iterations
optimized alpha [0.027558602, 0.0286107, 0.032206528, 0.03137542, 0.027009003, 1.0901268, 0.16249526, 0.029247297, 0.052507613, 0.19439286, 0.01615209, 0.062232856, 0.10662288, 0.025368975, 0.018654386, 0.023145825, 0.05833518, 0.1970664, 0.35048553, 0.029299542, 0.2285916, 0.0998852, 0.017394297, 0.052482903, 0.18452685, 0.02621299, 0.04130044, 0.15330282, 0.02621549, 0.05001255]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.229): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.350): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.090): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.033402, rho=0.159550
PROGRESS: pass 36, at document #4000/4566
performing inference on a chunk of 2000 documents
1991/2000 documents converged within 50 iterations
optimized alpha [0.027707485, 0.028692797, 0.03238465, 0.0314912, 0.027121706, 1.1132832, 0.1632148, 0.029357003, 0.052963495, 0.19621247, 0.016147926, 0.062707365, 0.10767082, 0.025382468, 0.018690286, 0.02317051, 0.058770847, 0.19978936, 0.35663736, 0.029397387, 0.23132642, 0.1012598, 0.017388234, 0.052843895, 0.1863611, 0.026303882, 0.041497543, 0.15475783, 0.026246833, 0.050404362]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.011*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.231): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.357): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.113): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.022369, rho=0.159550
bound: at document #0
-13.888 per-word bound, 15161.4 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 36, at document #4566/4566
performing inference on a chunk of 566 documents
563/566 documents converged within 50 iterations
optimized alpha [0.027760174, 0.028764058, 0.032479424, 0.0315629, 0.027147902, 1.115088, 0.16293928, 0.029433988, 0.0531323, 0.19738607, 0.016136846, 0.063091844, 0.108278625, 0.02540719, 0.018705692, 0.02322489, 0.059059013, 0.19939785, 0.3520162, 0.029432392, 0.23283686, 0.10185323, 0.017418165, 0.053140752, 0.18460591, 0.026324406, 0.041654296, 0.15571196, 0.02629727, 0.050618563]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.233): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.352): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"north"
topic #5 (1.115): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.040381, rho=0.159550
PROGRESS: pass 37, at document #2000/4566
performing inference on a chunk of 2000 documents
1991/2000 documents converged within 50 iterations
optimized alpha [0.027626315, 0.028729541, 0.03231255, 0.031464513, 0.027077861, 1.0967288, 0.16338615, 0.029351171, 0.052784152, 0.19548103, 0.016119463, 0.06252866, 0.10712624, 0.0254318, 0.018640323, 0.023168538, 0.05857957, 0.19780153, 0.3535733, 0.029382208, 0.23000792, 0.10060423, 0.017362986, 0.052720904, 0.18541962, 0.026258446, 0.04144264, 0.15402667, 0.026263965, 0.05025569]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.230): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.354): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.097): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.032467, rho=0.157558
PROGRESS: pass 37, at document #4000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.027773576, 0.028808111, 0.03248601, 0.031578857, 0.027189296, 1.1196469, 0.16407362, 0.029459426, 0.053238127, 0.19727734, 0.01611574, 0.06300072, 0.10816795, 0.025445042, 0.018676117, 0.023193141, 0.059004422, 0.2005115, 0.3596721, 0.029476617, 0.23267737, 0.10195875, 0.01735742, 0.053072426, 0.18723123, 0.026348446, 0.0416371, 0.15544502, 0.026295004, 0.05064222]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.233): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.360): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.120): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.022193, rho=0.157558
bound: at document #0
-13.888 per-word bound, 15155.8 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 37, at document #4566/4566
performing inference on a chunk of 566 documents
562/566 documents converged within 50 iterations
optimized alpha [0.027825497, 0.028877992, 0.032579236, 0.031649362, 0.027214974, 1.1213427, 0.16377996, 0.029535089, 0.053402036, 0.19841364, 0.016105218, 0.06337784, 0.10876029, 0.025469331, 0.01869167, 0.023247033, 0.059287176, 0.20010543, 0.35499346, 0.02951086, 0.23413658, 0.102532335, 0.017387353, 0.053363893, 0.18548082, 0.026368737, 0.041791204, 0.15637524, 0.026344849, 0.05085192]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.234): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.355): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"north"
topic #5 (1.121): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.039681, rho=0.157558
PROGRESS: pass 38, at document #2000/4566
performing inference on a chunk of 2000 documents
1990/2000 documents converged within 50 iterations
optimized alpha [0.027692853, 0.02884328, 0.03241348, 0.03155165, 0.02714549, 1.1030575, 0.16420875, 0.029452557, 0.053057626, 0.19649963, 0.016088458, 0.06281065, 0.107615896, 0.025493594, 0.018627496, 0.023193328, 0.05880956, 0.19854325, 0.356541, 0.029458672, 0.23131356, 0.101276025, 0.01733336, 0.052945223, 0.18629056, 0.026305553, 0.0415807, 0.15468135, 0.026309945, 0.05048561]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.231): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.357): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.103): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.032160, rho=0.155638
PROGRESS: pass 38, at document #4000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.027840719, 0.028918466, 0.032584954, 0.031659782, 0.027255712, 1.1258023, 0.1648896, 0.02955942, 0.053501632, 0.19826514, 0.016085176, 0.063270934, 0.108633496, 0.025506614, 0.018663175, 0.023217821, 0.059228677, 0.20121497, 0.36259192, 0.029551983, 0.23395467, 0.10261919, 0.017328285, 0.053295914, 0.18809365, 0.026394678, 0.041769378, 0.15609835, 0.026340721, 0.050867133]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.234): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"facebook" + 0.008*"iphone" + 0.008*"web" + 0.008*"android"
topic #18 (0.363): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.126): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.021682, rho=0.155638
bound: at document #0
-13.887 per-word bound, 15153.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 38, at document #4566/4566
performing inference on a chunk of 566 documents
561/566 documents converged within 50 iterations
optimized alpha [0.027891882, 0.028987039, 0.032676697, 0.0317292, 0.027280899, 1.1274152, 0.16458112, 0.029633796, 0.05366091, 0.19940762, 0.016075177, 0.06364126, 0.10921158, 0.025530476, 0.018678857, 0.023271222, 0.059506305, 0.2007491, 0.35784763, 0.029577732, 0.2353655, 0.10317622, 0.01735821, 0.053582195, 0.18635857, 0.026414715, 0.041921, 0.15704177, 0.026390009, 0.051072612]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.011*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.235): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.358): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"north"
topic #5 (1.127): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.038951, rho=0.155638
PROGRESS: pass 39, at document #2000/4566
performing inference on a chunk of 2000 documents
1990/2000 documents converged within 50 iterations
optimized alpha [0.027760362, 0.02895206, 0.032512, 0.03163219, 0.02721193, 1.1091886, 0.16499391, 0.029551525, 0.05331209, 0.1975142, 0.016058994, 0.0630754, 0.10806026, 0.025552396, 0.018615814, 0.023218265, 0.05903053, 0.19918545, 0.35938415, 0.02952362, 0.23255613, 0.10192892, 0.017305337, 0.053160723, 0.18713558, 0.026352236, 0.041711625, 0.15535603, 0.026355507, 0.050710883]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.233): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.359): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.109): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.031747, rho=0.153786
PROGRESS: pass 39, at document #4000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.027904546, 0.029028235, 0.032681532, 0.03173904, 0.027320866, 1.1317105, 0.16564408, 0.029659273, 0.053754557, 0.19928387, 0.016056105, 0.06353402, 0.10907157, 0.02556519, 0.018651353, 0.02324086, 0.059444133, 0.20182775, 0.36537322, 0.029613646, 0.23518467, 0.10325352, 0.017300718, 0.053506583, 0.18893893, 0.026440483, 0.041897878, 0.15674905, 0.026386013, 0.051087506]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"shourie" + 0.005*"bogot"
topic #20 (0.235): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.365): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.132): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.021513, rho=0.153786
bound: at document #0
-13.887 per-word bound, 15148.4 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 39, at document #4566/4566
performing inference on a chunk of 566 documents
562/566 documents converged within 50 iterations
optimized alpha [0.02795499, 0.029095523, 0.032771844, 0.03180738, 0.027345568, 1.1332388, 0.16532053, 0.029732384, 0.053909443, 0.20039864, 0.016046599, 0.063897796, 0.10963644, 0.025588652, 0.018667148, 0.02329379, 0.05971687, 0.20135663, 0.36058667, 0.029638955, 0.23655581, 0.10381888, 0.017330619, 0.053787977, 0.18720697, 0.026460268, 0.042047102, 0.15767054, 0.026434757, 0.0512889]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.237): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.361): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"north"
topic #5 (1.133): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.038326, rho=0.153786
PROGRESS: pass 40, at document #2000/4566
performing inference on a chunk of 2000 documents
1990/2000 documents converged within 50 iterations
optimized alpha [0.027824562, 0.02906244, 0.032608155, 0.031711, 0.027277078, 1.114989, 0.16572793, 0.029650318, 0.053560358, 0.19851151, 0.016030956, 0.06333317, 0.10848687, 0.025610264, 0.018605173, 0.023239773, 0.059242863, 0.19981837, 0.36209804, 0.02958303, 0.23375072, 0.10256461, 0.0172788, 0.053371668, 0.18794942, 0.026398428, 0.041838776, 0.15599611, 0.02640262, 0.050927695]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.234): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.362): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.115): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.031158, rho=0.151999
PROGRESS: pass 40, at document #4000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.027971419, 0.029135313, 0.03277583, 0.03181665, 0.027382942, 1.1373603, 0.16636117, 0.029756753, 0.05400135, 0.20027821, 0.016028434, 0.063780256, 0.109491654, 0.02562094, 0.018640582, 0.023264058, 0.059651192, 0.20245782, 0.36806947, 0.029674357, 0.23635745, 0.10388537, 0.017274601, 0.05371288, 0.18969923, 0.026485836, 0.042019516, 0.15733859, 0.026432829, 0.051295754]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"bogot" + 0.005*"shourie"
topic #20 (0.236): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.368): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.137): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.021267, rho=0.151999
bound: at document #0
-13.886 per-word bound, 15143.5 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 40, at document #4566/4566
performing inference on a chunk of 566 documents
563/566 documents converged within 50 iterations
optimized alpha [0.028021106, 0.029201342, 0.032864742, 0.03188393, 0.027407177, 1.138799, 0.16602343, 0.029828621, 0.054151926, 0.20135969, 0.016019383, 0.064137794, 0.11004368, 0.025644004, 0.018656466, 0.023316514, 0.059919182, 0.20197415, 0.36324254, 0.029699216, 0.23770028, 0.10443351, 0.017304465, 0.053989466, 0.1879717, 0.02650535, 0.042166423, 0.15823981, 0.026481004, 0.051493242]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.238): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.363): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"north"
topic #5 (1.139): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.037821, rho=0.151999
PROGRESS: pass 41, at document #2000/4566
performing inference on a chunk of 2000 documents
1991/2000 documents converged within 50 iterations
optimized alpha [0.02789169, 0.029172268, 0.032702055, 0.031788193, 0.027339198, 1.120637, 0.1664189, 0.029746778, 0.05380268, 0.19945396, 0.016004255, 0.0635791, 0.10889635, 0.025665326, 0.01859551, 0.023264954, 0.05944711, 0.20044313, 0.3647578, 0.02964593, 0.23488213, 0.10318828, 0.017253656, 0.053574495, 0.18872033, 0.026444126, 0.041959226, 0.15656003, 0.026447203, 0.05113279]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.235): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.365): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.121): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.030825, rho=0.150273
PROGRESS: pass 41, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.028034981, 0.029243963, 0.032867875, 0.031892616, 0.02744394, 1.1427804, 0.16703607, 0.029851863, 0.054234326, 0.20118737, 0.016002074, 0.06401517, 0.10988777, 0.025675789, 0.018630773, 0.023289088, 0.05984578, 0.2030604, 0.37068382, 0.029736273, 0.23746799, 0.104491524, 0.017249841, 0.0539111, 0.19044706, 0.026530672, 0.042140845, 0.15789151, 0.026477119, 0.05150016]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"bogot" + 0.005*"shourie"
topic #20 (0.237): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.371): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.143): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020958, rho=0.150273
bound: at document #0
-13.886 per-word bound, 15139.1 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 41, at document #4566/4566
performing inference on a chunk of 566 documents
562/566 documents converged within 50 iterations
optimized alpha [0.028083956, 0.029308742, 0.03295543, 0.031958867, 0.027467716, 1.1441381, 0.16668563, 0.029922538, 0.0543809, 0.20223822, 0.015993454, 0.06436679, 0.11042786, 0.025698468, 0.018646738, 0.023341063, 0.06010931, 0.20257093, 0.3658208, 0.029760664, 0.23877771, 0.10504885, 0.017279655, 0.05418309, 0.18872127, 0.026549922, 0.042285495, 0.15877245, 0.026524752, 0.051693864]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.239): 0.019*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.366): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.003*"north"
topic #5 (1.144): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.037529, rho=0.150273
PROGRESS: pass 42, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.027955519, 0.029281452, 0.03279368, 0.03186371, 0.027400177, 1.1259882, 0.16706897, 0.029840885, 0.05403162, 0.20032793, 0.015978796, 0.06381002, 0.109283015, 0.025719492, 0.018586744, 0.023290126, 0.059639174, 0.20106108, 0.36732125, 0.02970553, 0.23599368, 0.103803985, 0.017229797, 0.05376943, 0.189427, 0.026489256, 0.042079292, 0.15709686, 0.026491258, 0.051337853]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.236): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.367): 0.012*"news" + 0.008*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.126): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.030376, rho=0.148605
PROGRESS: pass 42, at document #4000/4566
performing inference on a chunk of 2000 documents
1992/2000 documents converged within 50 iterations
optimized alpha [0.028097391, 0.029352017, 0.03295772, 0.03196695, 0.027503844, 1.1479396, 0.16768464, 0.029942404, 0.054462172, 0.20204674, 0.015976934, 0.06424028, 0.110258855, 0.025729772, 0.018623209, 0.02331413, 0.060032956, 0.20365046, 0.37320536, 0.02979494, 0.2385616, 0.10509, 0.017226359, 0.05410168, 0.19115151, 0.026574982, 0.042258695, 0.15841039, 0.026520899, 0.051696964]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"bogot" + 0.005*"shourie"
topic #20 (0.239): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.373): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.148): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020768, rho=0.148605
bound: at document #0
-13.886 per-word bound, 15134.6 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 42, at document #4566/4566
performing inference on a chunk of 566 documents
562/566 documents converged within 50 iterations
optimized alpha [0.028145662, 0.029415557, 0.03304396, 0.032032195, 0.02752717, 1.1492213, 0.16735621, 0.030011924, 0.054604836, 0.20306875, 0.015968714, 0.0645862, 0.11078781, 0.025752062, 0.018639226, 0.023365634, 0.0602922, 0.20315142, 0.36830634, 0.029818898, 0.23983447, 0.1056346, 0.017256116, 0.05436925, 0.1894244, 0.026593963, 0.042401146, 0.15927355, 0.026568001, 0.05188703]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.240): 0.019*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.368): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.004*"north"
topic #5 (1.149): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.037134, rho=0.148605
PROGRESS: pass 43, at document #2000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.028018195, 0.029385822, 0.03288316, 0.031937648, 0.027460093, 1.1311543, 0.16774662, 0.029928247, 0.05425564, 0.20116678, 0.015953349, 0.06403133, 0.1096465, 0.025772804, 0.01858015, 0.023315305, 0.059824187, 0.2016465, 0.36978477, 0.029764209, 0.23708506, 0.10440608, 0.017207175, 0.053957008, 0.19012626, 0.026533859, 0.042195983, 0.15760319, 0.026534822, 0.05153191]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.237): 0.019*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.370): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.131): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.030138, rho=0.146990
PROGRESS: pass 43, at document #4000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.028158681, 0.029455291, 0.033045463, 0.032039758, 0.02756662, 1.1529351, 0.16836731, 0.030028537, 0.054681167, 0.20286383, 0.01595179, 0.06445596, 0.11061297, 0.025782892, 0.018616453, 0.023339173, 0.060213275, 0.2042075, 0.3756121, 0.02985269, 0.23964652, 0.105681434, 0.017204074, 0.05428504, 0.19180247, 0.026618782, 0.042373218, 0.15890908, 0.02656417, 0.051890563]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"bogot" + 0.005*"shourie"
topic #20 (0.240): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.376): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.153): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020450, rho=0.146990
bound: at document #0
-13.885 per-word bound, 15130.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 43, at document #4566/4566
performing inference on a chunk of 566 documents
562/566 documents converged within 50 iterations
optimized alpha [0.028206266, 0.029517654, 0.033130433, 0.032104038, 0.027589474, 1.1541622, 0.16803393, 0.03009696, 0.054820113, 0.20385906, 0.01594396, 0.06479645, 0.11113135, 0.025804803, 0.018632514, 0.023390213, 0.06046841, 0.20370089, 0.37069753, 0.02987621, 0.24088073, 0.1062106, 0.017233765, 0.05454837, 0.19007519, 0.026637496, 0.042513553, 0.15975519, 0.026610747, 0.052077092]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.241): 0.019*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.371): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.004*"north"
topic #5 (1.154): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.036829, rho=0.146990
PROGRESS: pass 44, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.028079718, 0.02948544, 0.032970533, 0.032010034, 0.027522776, 1.1361586, 0.16841948, 0.030013535, 0.05447104, 0.2019603, 0.015929045, 0.06424814, 0.109993555, 0.025825255, 0.018574312, 0.023340458, 0.06000246, 0.20221597, 0.3721594, 0.029819626, 0.23813969, 0.10497724, 0.01718569, 0.05413754, 0.19076417, 0.026577905, 0.042312276, 0.15809014, 0.026577855, 0.05172268]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.004*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.238): 0.020*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.372): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.136): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.029925, rho=0.145428
PROGRESS: pass 44, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.028218854, 0.029553873, 0.033131164, 0.032111038, 0.02762826, 1.1577547, 0.1690243, 0.030112641, 0.054891754, 0.20365669, 0.01592777, 0.06466705, 0.110950865, 0.025835149, 0.018609097, 0.023364177, 0.06038702, 0.20475127, 0.3779531, 0.02990724, 0.24068801, 0.10624552, 0.017182903, 0.05446154, 0.19243476, 0.026662039, 0.042487413, 0.15936837, 0.026606914, 0.05207719]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"bogot" + 0.005*"shourie"
topic #20 (0.241): 0.020*"google" + 0.012*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.378): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.158): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020304, rho=0.145428
bound: at document #0
-13.885 per-word bound, 15126.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 44, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.028265765, 0.0296151, 0.03321488, 0.032174364, 0.027650643, 1.1589007, 0.16863665, 0.030179985, 0.055027097, 0.20462357, 0.015920298, 0.06500218, 0.11148812, 0.02585668, 0.018625194, 0.02341475, 0.060638145, 0.20423669, 0.37302476, 0.029930335, 0.24188776, 0.106759734, 0.017212516, 0.05472075, 0.19071035, 0.026680468, 0.042625636, 0.16019857, 0.026652966, 0.052260272]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.242): 0.019*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.373): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.004*"north"
topic #5 (1.159): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.036456, rho=0.145428
PROGRESS: pass 45, at document #2000/4566
performing inference on a chunk of 2000 documents
1991/2000 documents converged within 50 iterations
optimized alpha [0.028140105, 0.02958474, 0.033055868, 0.032080904, 0.027584318, 1.1409717, 0.16901521, 0.030096818, 0.054678272, 0.20277679, 0.01590581, 0.06445105, 0.11035297, 0.025876861, 0.018567838, 0.023365539, 0.060174294, 0.20274495, 0.37447056, 0.029876368, 0.23916379, 0.105529636, 0.01716527, 0.054311387, 0.19138587, 0.026621377, 0.04242532, 0.1585409, 0.026620345, 0.05190664]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.239): 0.020*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.374): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.141): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.029544, rho=0.143914
PROGRESS: pass 45, at document #4000/4566
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
optimized alpha [0.028277915, 0.029652132, 0.033214837, 0.032180816, 0.027688742, 1.1623608, 0.16961834, 0.030192537, 0.055094253, 0.20445007, 0.0159048, 0.06486072, 0.1113034, 0.025886541, 0.018602459, 0.023389092, 0.060554404, 0.20525332, 0.3802258, 0.029963087, 0.24170063, 0.10678221, 0.017162776, 0.0546314, 0.19303486, 0.02670473, 0.04259837, 0.15980282, 0.026649123, 0.05225708]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"bogot" + 0.005*"shourie"
topic #20 (0.242): 0.020*"google" + 0.012*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.380): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.162): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020066, rho=0.143914
bound: at document #0
-13.884 per-word bound, 15122.5 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 45, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.028324183, 0.029712265, 0.033297367, 0.032243256, 0.027710682, 1.1635153, 0.16926531, 0.030258877, 0.055226263, 0.20533836, 0.015897673, 0.06519098, 0.11180136, 0.02590771, 0.018618591, 0.023439221, 0.06080178, 0.20473298, 0.37528637, 0.029985774, 0.24286586, 0.10728242, 0.017192313, 0.05488674, 0.19133821, 0.026722906, 0.042745396, 0.1606186, 0.026694678, 0.05243693]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.027*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.243): 0.019*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.375): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.004*"north"
topic #5 (1.164): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.035796, rho=0.143914
PROGRESS: pass 46, at document #2000/4566
performing inference on a chunk of 2000 documents
1990/2000 documents converged within 50 iterations
optimized alpha [0.028199432, 0.029681647, 0.033139274, 0.032150377, 0.027644755, 1.1457292, 0.16964513, 0.030176036, 0.054877874, 0.20352383, 0.015883613, 0.06464223, 0.11067666, 0.025927648, 0.018562071, 0.023390573, 0.0603402, 0.20324056, 0.37673643, 0.02993008, 0.24018392, 0.106054865, 0.017145876, 0.054479014, 0.19203651, 0.026664332, 0.0425459, 0.1589697, 0.026662348, 0.052084286]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.240): 0.020*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.377): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.146): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.029124, rho=0.142446
PROGRESS: pass 46, at document #4000/4566
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
optimized alpha [0.02833595, 0.02974803, 0.033296645, 0.03224923, 0.027748162, 1.1669302, 0.17023438, 0.030270655, 0.055285458, 0.20518099, 0.01588285, 0.06504699, 0.11161581, 0.025937142, 0.018596524, 0.023413973, 0.06072046, 0.20573719, 0.38247526, 0.030015953, 0.24270189, 0.107292295, 0.017143665, 0.05479523, 0.19365166, 0.02674689, 0.042716853, 0.1602177, 0.026690837, 0.05243083]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.243): 0.020*"google" + 0.013*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.382): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.167): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.019842, rho=0.142446
bound: at document #0
-13.884 per-word bound, 15118.7 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 46, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.028381575, 0.029807085, 0.033378, 0.032310788, 0.027769653, 1.1680149, 0.1698693, 0.030336002, 0.05541427, 0.20604262, 0.015876045, 0.06537249, 0.11210455, 0.025957948, 0.018612677, 0.023463657, 0.06096408, 0.20521276, 0.3775227, 0.030038238, 0.24383315, 0.10777906, 0.017173115, 0.055046782, 0.19195832, 0.026764797, 0.042861715, 0.16102007, 0.026735893, 0.052607533]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.009*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.244): 0.019*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.378): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.004*"north"
topic #5 (1.168): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.035573, rho=0.142446
PROGRESS: pass 47, at document #2000/4566
performing inference on a chunk of 2000 documents
1991/2000 documents converged within 50 iterations
optimized alpha [0.028257634, 0.029776137, 0.03322301, 0.032218393, 0.02770405, 1.1502881, 0.17024745, 0.030253401, 0.055066302, 0.20421426, 0.01586236, 0.06482581, 0.11098627, 0.025977606, 0.018556917, 0.02341712, 0.060504347, 0.20373408, 0.37894025, 0.029978648, 0.24114588, 0.10655099, 0.017127436, 0.05464415, 0.19263326, 0.026706668, 0.04266286, 0.15937795, 0.026703786, 0.052255627]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.241): 0.020*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.379): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.150): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.028926, rho=0.141023
PROGRESS: pass 47, at document #4000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.028392883, 0.029841544, 0.033378806, 0.0323162, 0.027808396, 1.171302, 0.17082316, 0.03034694, 0.055473402, 0.20585224, 0.015861832, 0.065225765, 0.111907646, 0.025986895, 0.018591197, 0.0234387, 0.06087597, 0.20620598, 0.3846647, 0.030063711, 0.24362595, 0.10777373, 0.017125478, 0.05495663, 0.19424175, 0.026788514, 0.042831752, 0.16061182, 0.026730105, 0.05259465]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.244): 0.020*"google" + 0.013*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"web" + 0.008*"android"
topic #18 (0.385): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.171): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.019671, rho=0.141023
bound: at document #0
-13.884 per-word bound, 15115.0 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 47, at document #4566/4566
performing inference on a chunk of 566 documents
563/566 documents converged within 50 iterations
optimized alpha [0.028437883, 0.029899556, 0.033459008, 0.032376893, 0.027829457, 1.1723256, 0.17044754, 0.030411327, 0.055599097, 0.20670877, 0.015855331, 0.06554671, 0.11238776, 0.02600734, 0.01860736, 0.023487935, 0.061116066, 0.20567612, 0.37970993, 0.030085646, 0.24472238, 0.10824788, 0.017154837, 0.0552045, 0.19254833, 0.026806157, 0.04297453, 0.1614013, 0.026774682, 0.052768376]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.245): 0.019*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.380): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.004*"north"
topic #5 (1.172): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.035024, rho=0.141023
PROGRESS: pass 48, at document #2000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.028314734, 0.029868297, 0.03330482, 0.032284968, 0.027766075, 1.1546259, 0.17081526, 0.03032895, 0.05525148, 0.20488867, 0.015842013, 0.065006696, 0.11128097, 0.026026698, 0.018552335, 0.023441887, 0.06065834, 0.20421892, 0.38111028, 0.030028572, 0.24204619, 0.10701759, 0.017109876, 0.054803345, 0.19319734, 0.026748437, 0.042776335, 0.15976633, 0.026742809, 0.05241738]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.242): 0.020*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.381): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.155): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.028393, rho=0.139641
PROGRESS: pass 48, at document #4000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.028450726, 0.02993275, 0.033459075, 0.03238176, 0.027869413, 1.1754733, 0.17137727, 0.030421447, 0.05565429, 0.2065106, 0.015841695, 0.06540198, 0.112191714, 0.02603578, 0.018586444, 0.0234633, 0.06103039, 0.20666647, 0.3867921, 0.03011284, 0.24452047, 0.10822624, 0.017108163, 0.05511221, 0.19478837, 0.026827691, 0.042940255, 0.16098677, 0.02676888, 0.052752774]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"arun" + 0.006*"jaejoongs" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.245): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.387): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"israel" + 0.003*"north"
topic #5 (1.175): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.019514, rho=0.139641
bound: at document #0
-13.883 per-word bound, 15111.6 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 48, at document #4566/4566
performing inference on a chunk of 566 documents
561/566 documents converged within 50 iterations
optimized alpha [0.028495107, 0.029989762, 0.033538163, 0.032441624, 0.027890049, 1.1764553, 0.17099205, 0.030484911, 0.055777047, 0.20738602, 0.015835484, 0.06571851, 0.112663664, 0.026055874, 0.018602619, 0.023512093, 0.061267056, 0.20613235, 0.3818352, 0.030134425, 0.24558812, 0.10868874, 0.017137432, 0.055356577, 0.19309783, 0.026845098, 0.043081064, 0.16176476, 0.026812999, 0.052923672]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.246): 0.019*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.382): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.004*"north"
topic #5 (1.176): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.034653, rho=0.139641
PROGRESS: pass 49, at document #2000/4566
performing inference on a chunk of 2000 documents
1993/2000 documents converged within 50 iterations
optimized alpha [0.02837271, 0.029960232, 0.033384737, 0.032350175, 0.02782694, 1.1588305, 0.17135082, 0.030402772, 0.05542995, 0.20557484, 0.015822511, 0.06517613, 0.11156178, 0.026074974, 0.01854831, 0.023466486, 0.06081132, 0.20467995, 0.38320443, 0.030077683, 0.24295744, 0.107457526, 0.017093167, 0.05495693, 0.19375998, 0.026787823, 0.04288359, 0.16013774, 0.02678136, 0.05257368]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.243): 0.020*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.383): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.159): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.028302, rho=0.138299
PROGRESS: pass 49, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.02850551, 0.030023742, 0.033537477, 0.03244598, 0.02792929, 1.1795053, 0.1719119, 0.030494254, 0.05582859, 0.20716625, 0.015822396, 0.065566964, 0.11246268, 0.026083855, 0.018582257, 0.023487758, 0.061179385, 0.20710406, 0.38887367, 0.030161146, 0.24539141, 0.108652614, 0.017091691, 0.05526228, 0.19533361, 0.026866384, 0.043048576, 0.16134515, 0.026807176, 0.05290553]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.245): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"app" + 0.009*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.389): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.180): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.019312, rho=0.138299
bound: at document #0
-13.883 per-word bound, 15108.4 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 49, at document #4566/4566
performing inference on a chunk of 566 documents
562/566 documents converged within 50 iterations
optimized alpha [0.02854934, 0.030079799, 0.033615533, 0.03250508, 0.027949536, 1.1804769, 0.17151989, 0.03055686, 0.05594867, 0.20808125, 0.015816472, 0.06587951, 0.112927325, 0.026103644, 0.018598448, 0.02353613, 0.061412908, 0.20656921, 0.38390246, 0.03018242, 0.24645585, 0.10912837, 0.017120877, 0.055503402, 0.19367889, 0.026883576, 0.043187518, 0.16211116, 0.026850868, 0.053073823]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.246): 0.019*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.384): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.004*"north"
topic #5 (1.180): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.034263, rho=0.138299
PROGRESS: pass 50, at document #2000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.028427705, 0.03004996, 0.033462845, 0.03241408, 0.027886683, 1.1629313, 0.1718816, 0.030474942, 0.05560213, 0.20627172, 0.015803834, 0.06534387, 0.111830115, 0.026122482, 0.01854483, 0.023490956, 0.060959123, 0.2051097, 0.3852662, 0.030128105, 0.24383307, 0.10789554, 0.017077269, 0.055105224, 0.1943146, 0.026826706, 0.042990703, 0.16049245, 0.026819447, 0.052724827]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.244): 0.020*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.385): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.163): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.028040, rho=0.136995
PROGRESS: pass 50, at document #4000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.028559335, 0.030112557, 0.033614125, 0.03250893, 0.027988054, 1.1834395, 0.17243107, 0.03056544, 0.055996742, 0.20784378, 0.015803918, 0.06573033, 0.11272856, 0.02613118, 0.018578593, 0.02351207, 0.061331, 0.2075107, 0.39088354, 0.030208735, 0.246275, 0.10907752, 0.017076008, 0.055407185, 0.19587508, 0.026904585, 0.043153808, 0.16166493, 0.026844997, 0.053055365]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.246): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.009*"twitter" + 0.009*"app" + 0.009*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.391): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.183): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.018948, rho=0.136995
bound: at document #0
-13.883 per-word bound, 15105.2 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 50, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.028602613, 0.030167684, 0.033691168, 0.032567274, 0.028007908, 1.1844324, 0.1720281, 0.0306272, 0.05611422, 0.20876022, 0.015798263, 0.06603893, 0.11318595, 0.026150657, 0.01859479, 0.023560029, 0.061561335, 0.20697221, 0.38591242, 0.030229693, 0.24735188, 0.10954305, 0.017105103, 0.055645134, 0.1942263, 0.026921568, 0.043290928, 0.16242132, 0.026888268, 0.053221077]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.247): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.386): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.004*"north"
topic #5 (1.184): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.033844, rho=0.136995
PROGRESS: pass 51, at document #2000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.028481718, 0.030133482, 0.0335392, 0.032476727, 0.027945306, 1.166957, 0.17238075, 0.030545518, 0.05576831, 0.20696612, 0.015785934, 0.065505445, 0.11209329, 0.026169242, 0.018541822, 0.023515264, 0.061109357, 0.20553, 0.38726673, 0.030175699, 0.24473132, 0.10830955, 0.017062131, 0.055248458, 0.19484541, 0.026865102, 0.043094788, 0.16082005, 0.026857052, 0.05287311]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.245): 0.020*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.387): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.167): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.027635, rho=0.135728
PROGRESS: pass 51, at document #4000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.028612187, 0.03019523, 0.033689037, 0.03257062, 0.028045734, 1.1872951, 0.17291911, 0.030635042, 0.05615895, 0.2085212, 0.01578619, 0.06588768, 0.112982355, 0.026177738, 0.018575422, 0.023536226, 0.061477516, 0.20790932, 0.39282903, 0.030257626, 0.2471494, 0.10947865, 0.017061071, 0.055547137, 0.19639055, 0.026942307, 0.043256067, 0.16198097, 0.026882356, 0.053205103]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.247): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.393): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.003*"north" + 0.003*"israel"
topic #5 (1.187): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.018821, rho=0.135728
bound: at document #0
-13.882 per-word bound, 15102.0 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 51, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.02865492, 0.030249473, 0.033765078, 0.032628216, 0.028065184, 1.1883099, 0.17246464, 0.03069597, 0.056273907, 0.20945667, 0.015780786, 0.06619241, 0.11343268, 0.026196899, 0.018591616, 0.023583772, 0.06170471, 0.20737155, 0.38785404, 0.030278241, 0.24821472, 0.10993431, 0.017090071, 0.055782005, 0.19474396, 0.026959073, 0.04339139, 0.16272828, 0.0269252, 0.053368244]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.248): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.388): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.004*"north"
topic #5 (1.188): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.033273, rho=0.135728
PROGRESS: pass 52, at document #2000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.028534748, 0.030215062, 0.033613816, 0.032538097, 0.028002834, 1.1709249, 0.17281035, 0.03061455, 0.05592868, 0.20766243, 0.015768765, 0.06566116, 0.11235182, 0.02621523, 0.018539289, 0.023539396, 0.061254587, 0.20592321, 0.3891838, 0.030222485, 0.24560095, 0.10870097, 0.017047722, 0.055386838, 0.19539015, 0.026903, 0.043193027, 0.16114503, 0.026894193, 0.053021204]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.246): 0.020*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.389): 0.012*"news" + 0.007*"wikileaks" + 0.006*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.171): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.027383, rho=0.134494
PROGRESS: pass 52, at document #4000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.028664108, 0.030275984, 0.033762276, 0.032631088, 0.028102346, 1.1911108, 0.17334941, 0.030703152, 0.056319345, 0.20919442, 0.015769197, 0.066043854, 0.11323198, 0.02622355, 0.01857272, 0.023560205, 0.061619077, 0.20828062, 0.3947346, 0.03030166, 0.24800263, 0.109865226, 0.017046848, 0.055678677, 0.19691592, 0.026979567, 0.043352574, 0.16229491, 0.026919248, 0.053346694]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.248): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.395): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.191): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.018639, rho=0.134494
bound: at document #0
-13.882 per-word bound, 15098.9 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 52, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.028706279, 0.030329337, 0.033837304, 0.03268791, 0.02812137, 1.1920606, 0.17284815, 0.030763237, 0.0564317, 0.21011078, 0.015764024, 0.066344626, 0.113702476, 0.026242377, 0.018588893, 0.023607329, 0.061843123, 0.20774077, 0.3897545, 0.030321946, 0.24904053, 0.11031101, 0.017075736, 0.05591051, 0.19527003, 0.026996085, 0.043486122, 0.16303097, 0.026961645, 0.0535073]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.249): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.390): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.004*"north"
topic #5 (1.192): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.033201, rho=0.134494
PROGRESS: pass 53, at document #2000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.028586784, 0.030296737, 0.03368671, 0.032598194, 0.028059237, 1.1747267, 0.17318794, 0.030682037, 0.056087047, 0.20831889, 0.015752276, 0.06581536, 0.11263267, 0.026260445, 0.018537173, 0.023563324, 0.061394714, 0.20630713, 0.3910591, 0.030266544, 0.24643709, 0.109084636, 0.017035082, 0.055516887, 0.19586945, 0.026940374, 0.04329138, 0.16144404, 0.02693082, 0.05316121]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.246): 0.020*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.391): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.175): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.027112, rho=0.133294
PROGRESS: pass 53, at document #4000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.02871505, 0.03035683, 0.033833805, 0.032690287, 0.028157841, 1.1947478, 0.17372145, 0.03076972, 0.05647024, 0.20981267, 0.015752876, 0.066189565, 0.11350331, 0.02626857, 0.018570425, 0.023583986, 0.061755493, 0.20865706, 0.39657566, 0.030347036, 0.24881464, 0.11023688, 0.01703439, 0.055802025, 0.19739415, 0.027016295, 0.04344918, 0.162593, 0.026955634, 0.053487096]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.021*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.249): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.397): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.195): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.018526, rho=0.133294
bound: at document #0
-13.882 per-word bound, 15095.9 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 53, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.02875669, 0.030409323, 0.03390787, 0.03274636, 0.028176466, 1.1956706, 0.1732594, 0.030829005, 0.05658025, 0.21075775, 0.015747927, 0.06648671, 0.11393881, 0.026287086, 0.018586582, 0.023630708, 0.061976593, 0.20811425, 0.39159518, 0.030366996, 0.24982591, 0.1106481, 0.017063167, 0.05603106, 0.195752, 0.02703259, 0.043581016, 0.1633204, 0.026997615, 0.05364527]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.250): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.392): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"israel" + 0.004*"north"
topic #5 (1.196): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.032830, rho=0.133294
PROGRESS: pass 54, at document #2000/4566
performing inference on a chunk of 2000 documents
1993/2000 documents converged within 50 iterations
optimized alpha [0.028637873, 0.030376513, 0.03375796, 0.032657072, 0.028114563, 1.1784278, 0.17359325, 0.030748062, 0.056236405, 0.20900792, 0.015735427, 0.06595972, 0.112866156, 0.02630492, 0.018535456, 0.023587074, 0.06153009, 0.20666417, 0.3928818, 0.030313896, 0.24724217, 0.10942362, 0.017023094, 0.055639155, 0.19637464, 0.026977232, 0.043384083, 0.16174315, 0.026966969, 0.0533002]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.247): 0.020*"google" + 0.013*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.393): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.178): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026923, rho=0.132126
PROGRESS: pass 54, at document #4000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.028765067, 0.030435793, 0.033903725, 0.032750435, 0.02821229, 1.1983079, 0.17412344, 0.030834857, 0.05661601, 0.21047969, 0.015737217, 0.06633452, 0.11372832, 0.026312862, 0.018568534, 0.023607578, 0.06188729, 0.2089699, 0.39836589, 0.030391674, 0.24959992, 0.11056463, 0.017022561, 0.055928744, 0.19789262, 0.027052535, 0.04354022, 0.16288203, 0.026991533, 0.053619437]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.011*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.250): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.398): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.198): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.018216, rho=0.132126
bound: at document #0
-13.882 per-word bound, 15093.1 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 54, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.028806182, 0.030487446, 0.033976853, 0.032805756, 0.02823052, 1.1992028, 0.17365772, 0.030893363, 0.056723747, 0.21143351, 0.015732478, 0.06662807, 0.11415749, 0.026331069, 0.018584667, 0.023653908, 0.062105533, 0.20842877, 0.39338058, 0.030411309, 0.2505824, 0.110967726, 0.01705123, 0.05615494, 0.19625081, 0.027068598, 0.043670423, 0.16359994, 0.027033096, 0.053775296]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.251): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.393): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.199): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.032546, rho=0.132126
PROGRESS: pass 55, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.028688023, 0.030454414, 0.033827595, 0.032716833, 0.028168824, 1.1819905, 0.173986, 0.03081265, 0.056380693, 0.20968385, 0.015721278, 0.06610318, 0.11309678, 0.026348649, 0.018534098, 0.023610607, 0.061660856, 0.20702659, 0.3946481, 0.030358465, 0.24801822, 0.10974516, 0.017011678, 0.05576453, 0.19684757, 0.027013583, 0.04347689, 0.16203168, 0.027002616, 0.053431284]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.248): 0.020*"google" + 0.013*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.395): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.182): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026795, rho=0.130987
PROGRESS: pass 55, at document #4000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.028814165, 0.030512903, 0.03397207, 0.032807168, 0.028265677, 1.201714, 0.1745109, 0.030898564, 0.056753132, 0.21111812, 0.015723191, 0.06646977, 0.1139504, 0.026356403, 0.018567003, 0.023632502, 0.062014535, 0.20931217, 0.40011954, 0.030437555, 0.25035235, 0.1108752, 0.0170113, 0.056051187, 0.1983517, 0.02708825, 0.043631364, 0.16316052, 0.02702693, 0.05375102]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.250): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.400): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.202): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.018074, rho=0.130987
bound: at document #0
-13.881 per-word bound, 15090.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 55, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.028854758, 0.030563727, 0.03404427, 0.032861736, 0.028283512, 1.2025679, 0.17400017, 0.030956294, 0.056858715, 0.21204093, 0.015718643, 0.06675986, 0.11440008, 0.026374297, 0.018583104, 0.023678431, 0.06222997, 0.20876938, 0.39514062, 0.030456841, 0.25131086, 0.11129335, 0.017039847, 0.056274615, 0.19671121, 0.027104083, 0.043759927, 0.16386989, 0.027068079, 0.05390457]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.251): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.395): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.203): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.032330, rho=0.130987
PROGRESS: pass 56, at document #2000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.028739037, 0.030530496, 0.033895656, 0.032773204, 0.028222034, 1.1854275, 0.1743232, 0.030875813, 0.05652024, 0.21029486, 0.015707688, 0.06623722, 0.113349564, 0.026391638, 0.018533075, 0.02363546, 0.06178713, 0.20736293, 0.3963841, 0.030402277, 0.24876338, 0.11007852, 0.0170008, 0.055885714, 0.19730192, 0.0270494, 0.04356719, 0.16231012, 0.027037753, 0.053558033]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.249): 0.020*"google" + 0.013*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.008*"iphone" + 0.008*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.396): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.185): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026500, rho=0.129878
PROGRESS: pass 56, at document #4000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.028864171, 0.030588225, 0.034038886, 0.03286063, 0.02831806, 1.205048, 0.17484413, 0.030960904, 0.05689303, 0.21172541, 0.015709728, 0.06660458, 0.114201546, 0.026399221, 0.018565815, 0.023657193, 0.062137503, 0.20961942, 0.40182626, 0.0304807, 0.2510709, 0.111191586, 0.017000575, 0.056166004, 0.19882849, 0.027123477, 0.043717187, 0.16342951, 0.027061842, 0.053871393]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.251): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"iphone" + 0.009*"web" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.402): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.205): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.017887, rho=0.129878
bound: at document #0
-13.881 per-word bound, 15087.4 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 56, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.028904242, 0.030638248, 0.034110185, 0.03290727, 0.028335512, 1.2058927, 0.17433211, 0.031017886, 0.056996442, 0.21264236, 0.015705366, 0.066891275, 0.11464401, 0.026416814, 0.018581884, 0.023702735, 0.062350236, 0.20907566, 0.39684582, 0.030499658, 0.2520061, 0.11157922, 0.017029006, 0.056386817, 0.19719, 0.027139086, 0.043844197, 0.1641304, 0.027102582, 0.054022815]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.252): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.397): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.206): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.031837, rho=0.129878
PROGRESS: pass 57, at document #2000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.028789157, 0.03060482, 0.033962205, 0.032819234, 0.028274233, 1.188847, 0.17465098, 0.030937644, 0.05665507, 0.21088812, 0.015694646, 0.06637079, 0.11359691, 0.026433913, 0.0185324, 0.023660062, 0.061909296, 0.2076682, 0.39806405, 0.030447306, 0.24946982, 0.11037434, 0.016990451, 0.055999525, 0.19779664, 0.027084723, 0.043652214, 0.16257913, 0.027072413, 0.053680956]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.249): 0.020*"google" + 0.013*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.398): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.189): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026250, rho=0.128796
PROGRESS: pass 57, at document #4000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.028913284, 0.030659923, 0.034104202, 0.03290591, 0.028369438, 1.2083296, 0.17517559, 0.031021912, 0.05702094, 0.21230088, 0.0156968, 0.06673037, 0.11443364, 0.026441332, 0.018564977, 0.023681633, 0.06225641, 0.20992088, 0.4034833, 0.030525053, 0.25178924, 0.11147749, 0.016990373, 0.056280762, 0.19928418, 0.027158204, 0.043800704, 0.1636896, 0.027096279, 0.05399499]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.252): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.403): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.208): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.017698, rho=0.128796
bound: at document #0
-13.881 per-word bound, 15084.8 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 57, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.028952839, 0.030709174, 0.03417461, 0.03295201, 0.028386505, 1.2091244, 0.17466237, 0.031078147, 0.057122335, 0.21320027, 0.01569261, 0.0670138, 0.11486935, 0.02645862, 0.018581005, 0.02372679, 0.062466502, 0.20937915, 0.39849225, 0.030543659, 0.25270233, 0.11185804, 0.017018683, 0.056498956, 0.19764543, 0.027173579, 0.043926183, 0.16438054, 0.027136615, 0.05414423]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.253): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.009*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.398): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.209): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.031510, rho=0.128796
PROGRESS: pass 58, at document #2000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.028838342, 0.030675579, 0.034027252, 0.032864448, 0.02832543, 1.1921552, 0.174988, 0.030998137, 0.05678194, 0.21147463, 0.015682114, 0.0664956, 0.11382597, 0.026473802, 0.018532017, 0.023684423, 0.062027477, 0.20795056, 0.399698, 0.030489609, 0.25017598, 0.11065619, 0.016980615, 0.056113172, 0.19825098, 0.027116131, 0.04373494, 0.16283783, 0.027106598, 0.0538034]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.250): 0.020*"google" + 0.013*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.400): 0.012*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.192): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.025879, rho=0.127741
PROGRESS: pass 58, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.02896147, 0.030731864, 0.034168027, 0.032952446, 0.028419819, 1.2114719, 0.17550582, 0.031081574, 0.05714099, 0.21286798, 0.015684381, 0.066851735, 0.1146544, 0.026481038, 0.018564414, 0.023705812, 0.062371366, 0.21017255, 0.4050816, 0.030566696, 0.25247994, 0.11174936, 0.01698066, 0.05639169, 0.19972312, 0.02718903, 0.043881934, 0.16393863, 0.027130214, 0.054117985]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.252): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.405): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.211): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.017617, rho=0.127741
bound: at document #0
-13.881 per-word bound, 15082.2 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 58, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029000519, 0.030780349, 0.03423757, 0.032998007, 0.028436515, 1.2122389, 0.17499048, 0.031137098, 0.057240512, 0.2137496, 0.015680358, 0.067132026, 0.1150837, 0.02649804, 0.018580401, 0.023750588, 0.06257891, 0.20963097, 0.4000844, 0.030584974, 0.25336832, 0.11212312, 0.017008847, 0.05660735, 0.19808562, 0.0272042, 0.044005938, 0.16462204, 0.027170148, 0.05426509]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.253): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.400): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.212): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.031279, rho=0.127741
PROGRESS: pass 59, at document #2000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.028886585, 0.030746553, 0.034090795, 0.032910883, 0.02837562, 1.195287, 0.17529953, 0.031057306, 0.056901127, 0.21203628, 0.015669072, 0.06661599, 0.11404486, 0.026514668, 0.018531902, 0.023708506, 0.062141664, 0.2082304, 0.40126693, 0.030533066, 0.25084853, 0.11092411, 0.016971216, 0.056223035, 0.19869302, 0.027147101, 0.04381538, 0.16308746, 0.02714194, 0.053925198]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.251): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.401): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.195): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.025721, rho=0.126711
PROGRESS: pass 59, at document #4000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.029010586, 0.030802168, 0.03423041, 0.0329961, 0.028469242, 1.2144978, 0.1758121, 0.03113998, 0.057264406, 0.21341477, 0.015671449, 0.06696478, 0.11486583, 0.026521754, 0.018564139, 0.023729742, 0.06248244, 0.2104625, 0.40663037, 0.03060952, 0.25313723, 0.11201392, 0.016971394, 0.05649904, 0.2001824, 0.027219448, 0.04395823, 0.1641887, 0.027165333, 0.05423025]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.253): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.407): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.214): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.017490, rho=0.126711
bound: at document #0
-13.880 per-word bound, 15079.7 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 59, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029049115, 0.030849895, 0.03430674, 0.03304113, 0.028485565, 1.2152249, 0.17529406, 0.031194791, 0.05736199, 0.21427906, 0.015667582, 0.06724205, 0.115288824, 0.026538458, 0.018580077, 0.023774141, 0.06268747, 0.20992047, 0.40163726, 0.03062743, 0.25400373, 0.11238106, 0.016999459, 0.056712225, 0.19854394, 0.027234415, 0.044080812, 0.16482723, 0.027204858, 0.054375324]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.254): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.402): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.215): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.031071, rho=0.126711
PROGRESS: pass 60, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.028935703, 0.030815922, 0.034160454, 0.032954443, 0.028424857, 1.1983526, 0.17559871, 0.031115215, 0.057023518, 0.21257408, 0.015657503, 0.06672837, 0.11425224, 0.026554856, 0.018532058, 0.023732323, 0.062252037, 0.20852719, 0.40280426, 0.030575747, 0.25148445, 0.111185126, 0.016962273, 0.0563294, 0.19912562, 0.027177649, 0.04389373, 0.163302, 0.027176768, 0.054036513]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.251): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.403): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.198): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.025399, rho=0.125706
PROGRESS: pass 60, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.029058719, 0.030870805, 0.0342988, 0.033040978, 0.028521258, 1.2174019, 0.17610505, 0.031197077, 0.05738353, 0.21393324, 0.015658986, 0.067078054, 0.11506527, 0.026561746, 0.018564112, 0.023751883, 0.06258977, 0.21071519, 0.40809748, 0.030651527, 0.25373927, 0.11226615, 0.016962558, 0.05660277, 0.20061518, 0.027249418, 0.044035144, 0.16438548, 0.027199894, 0.05433883]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.254): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.408): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.217): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.017352, rho=0.125706
bound: at document #0
-13.880 per-word bound, 15077.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 60, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029096762, 0.030917818, 0.03436661, 0.033085503, 0.028537208, 1.2181064, 0.17558672, 0.03125121, 0.057479303, 0.214782, 0.015655275, 0.06735241, 0.115482666, 0.026578177, 0.018580006, 0.02379593, 0.062792465, 0.2101739, 0.40310794, 0.030669067, 0.25458622, 0.11262715, 0.016990503, 0.056813605, 0.19897963, 0.027264196, 0.044156343, 0.16505405, 0.027239028, 0.054482024]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.255): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.403): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.218): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.030828, rho=0.125706
PROGRESS: pass 61, at document #2000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.028983893, 0.030883703, 0.034220956, 0.03299926, 0.028476672, 1.2013183, 0.17589901, 0.031171883, 0.057141878, 0.21309327, 0.015645402, 0.06684109, 0.11445822, 0.026591068, 0.018532455, 0.023754412, 0.062358953, 0.20880148, 0.40427908, 0.030615645, 0.252095, 0.111435, 0.01695375, 0.05643239, 0.19957054, 0.027207792, 0.043967273, 0.16354744, 0.027211068, 0.054144435]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.252): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.404): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.201): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.025071, rho=0.124725
PROGRESS: pass 61, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.029107807, 0.030939769, 0.034355983, 0.033085093, 0.02857231, 1.2202442, 0.17639959, 0.031253006, 0.057491835, 0.21445483, 0.01564698, 0.06719609, 0.11527132, 0.026597818, 0.018564345, 0.023772357, 0.06269365, 0.21098289, 0.40953422, 0.030688923, 0.25434503, 0.11250699, 0.01695415, 0.05669984, 0.20104767, 0.02727903, 0.04410457, 0.16463152, 0.027235672, 0.054450978]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.254): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.410): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.220): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.017084, rho=0.124725
bound: at document #0
-13.880 per-word bound, 15074.7 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 61, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.02914536, 0.030986072, 0.034423035, 0.033129122, 0.028587898, 1.2209673, 0.1758799, 0.031306487, 0.057586, 0.2152866, 0.015643423, 0.067467526, 0.11568303, 0.026614003, 0.018580195, 0.023816075, 0.06289408, 0.21044275, 0.40455014, 0.030699486, 0.25517285, 0.11286226, 0.016981978, 0.05690846, 0.19941573, 0.027293624, 0.0442245, 0.16529235, 0.027274413, 0.054592267]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.014*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.255): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.405): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.221): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.030707, rho=0.124725
PROGRESS: pass 62, at document #2000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.029032955, 0.03095176, 0.034277976, 0.03304326, 0.028527495, 1.2042217, 0.17617603, 0.031227363, 0.05724961, 0.21362367, 0.015633741, 0.06695816, 0.1146553, 0.026629986, 0.01853308, 0.023774823, 0.06246234, 0.20907857, 0.40567517, 0.030646387, 0.25268826, 0.111673236, 0.01694563, 0.05652878, 0.20000204, 0.027237525, 0.04403618, 0.16379268, 0.02724653, 0.054255627]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.253): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.406): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.204): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024824, rho=0.123766
PROGRESS: pass 62, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.029154127, 0.031007146, 0.03441189, 0.033128377, 0.028622333, 1.2230123, 0.17667098, 0.031307716, 0.05760021, 0.21498679, 0.015636384, 0.06730571, 0.11546089, 0.02663656, 0.018564802, 0.023794089, 0.06279409, 0.21123022, 0.41088465, 0.030721, 0.2549227, 0.112736404, 0.01694612, 0.056793846, 0.20144416, 0.027308222, 0.044174924, 0.16486771, 0.027269179, 0.05455618]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.255): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.411): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.223): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.017004, rho=0.123766
bound: at document #0
-13.880 per-word bound, 15072.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 62, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029191203, 0.031052742, 0.034478176, 0.0331719, 0.028637554, 1.2236782, 0.17615065, 0.03136054, 0.05769269, 0.2158021, 0.01563296, 0.067574285, 0.115866974, 0.026652468, 0.0185806, 0.023837458, 0.06299226, 0.21071786, 0.40589705, 0.030731376, 0.25573215, 0.11308603, 0.016973823, 0.057000257, 0.19981138, 0.027322622, 0.044293553, 0.16552082, 0.027307535, 0.054695603]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.013*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.256): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.406): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.224): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.030232, rho=0.123766
PROGRESS: pass 63, at document #2000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.029079298, 0.031020137, 0.034333717, 0.03308644, 0.028577298, 1.2070028, 0.17644343, 0.031281643, 0.05735737, 0.21412992, 0.015623454, 0.067067094, 0.11485023, 0.026668236, 0.01853392, 0.023796473, 0.062566146, 0.20936932, 0.40703604, 0.030676696, 0.2532661, 0.11190077, 0.01693787, 0.056622174, 0.20037867, 0.027266838, 0.044105973, 0.16402844, 0.027279744, 0.05436008]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.253): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.407): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.207): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024702, rho=0.122828
PROGRESS: pass 63, at document #4000/4566
performing inference on a chunk of 2000 documents
1992/2000 documents converged within 50 iterations
optimized alpha [0.029201338, 0.03107484, 0.03446656, 0.033170853, 0.028671382, 1.225662, 0.17693308, 0.031361263, 0.05770514, 0.21546885, 0.015626173, 0.067411594, 0.11564856, 0.02667465, 0.01856548, 0.023815589, 0.06289502, 0.2115046, 0.41221973, 0.030750763, 0.2554873, 0.112955704, 0.016938463, 0.05688495, 0.20181349, 0.027337011, 0.04424075, 0.16509451, 0.02730215, 0.05465814]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.255): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.412): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.226): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.016831, rho=0.122828
bound: at document #0
-13.879 per-word bound, 15070.0 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 63, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029237943, 0.031119747, 0.03453212, 0.033213895, 0.028686255, 1.2263076, 0.17641295, 0.031413462, 0.05779606, 0.21630184, 0.015622882, 0.06767748, 0.11604932, 0.026690299, 0.018581228, 0.02385863, 0.063091, 0.21099402, 0.4072359, 0.030760987, 0.2562782, 0.1133, 0.016966049, 0.057089265, 0.2001841, 0.027351229, 0.044358164, 0.16574067, 0.027340136, 0.054795813]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.256): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.407): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.226): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.030153, rho=0.122828
PROGRESS: pass 64, at document #2000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.0291265, 0.03108695, 0.034388263, 0.03312882, 0.028626138, 1.2096919, 0.17670235, 0.031334773, 0.057461806, 0.21463527, 0.015612601, 0.067172445, 0.115036346, 0.02670585, 0.018536078, 0.023817899, 0.062670596, 0.20964463, 0.40835705, 0.03070847, 0.2538341, 0.11211853, 0.016930483, 0.05671277, 0.20076023, 0.027295748, 0.04417135, 0.1642557, 0.027312435, 0.05446138]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.254): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.408): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.210): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024571, rho=0.121912
PROGRESS: pass 64, at document #4000/4566
performing inference on a chunk of 2000 documents
1992/2000 documents converged within 50 iterations
optimized alpha [0.029245896, 0.031141028, 0.03452009, 0.033212572, 0.028719485, 1.2282382, 0.1771874, 0.031413708, 0.05780338, 0.2159763, 0.015615409, 0.067514084, 0.11583442, 0.026712101, 0.018567467, 0.02383688, 0.06299671, 0.21176538, 0.4135109, 0.030781988, 0.2560388, 0.11317797, 0.016931165, 0.056973368, 0.20219833, 0.027365413, 0.044304945, 0.16531412, 0.027334627, 0.054760363]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.256): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.414): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.228): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.016786, rho=0.121912
bound: at document #0
-13.879 per-word bound, 15067.7 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 64, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029282045, 0.031185249, 0.034584913, 0.03325513, 0.028734002, 1.2288488, 0.17666611, 0.03146528, 0.057892796, 0.21679288, 0.015612245, 0.0677773, 0.11622987, 0.026727479, 0.018583158, 0.023879588, 0.06319045, 0.21125303, 0.40853322, 0.030792031, 0.2568115, 0.113516875, 0.016958624, 0.057175588, 0.20056868, 0.027379444, 0.04442115, 0.16595255, 0.027372245, 0.054896247]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.257): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.409): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.229): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.029946, rho=0.121912
PROGRESS: pass 65, at document #2000/4566
performing inference on a chunk of 2000 documents
1999/2000 documents converged within 50 iterations
optimized alpha [0.029171081, 0.031152276, 0.034441616, 0.03317044, 0.02867403, 1.2123009, 0.17695223, 0.03138681, 0.057559684, 0.21513039, 0.015603086, 0.067274414, 0.115227625, 0.026742818, 0.018538399, 0.023839105, 0.06277184, 0.2099134, 0.4096425, 0.0307379, 0.25440216, 0.11233904, 0.016923428, 0.056800656, 0.20112485, 0.027324256, 0.0442351, 0.16447522, 0.027344633, 0.05456286]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.254): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.410): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.212): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024369, rho=0.121016
PROGRESS: pass 65, at document #4000/4566
performing inference on a chunk of 2000 documents
1993/2000 documents converged within 50 iterations
optimized alpha [0.029289603, 0.031205727, 0.03457241, 0.03325354, 0.028766641, 1.2307218, 0.1774258, 0.03146504, 0.057898633, 0.21644826, 0.015605963, 0.067609146, 0.116018794, 0.026748916, 0.018569622, 0.02385793, 0.06309522, 0.21201904, 0.41475523, 0.030809049, 0.256608, 0.11339146, 0.016924204, 0.0570625, 0.20258236, 0.027393429, 0.044367556, 0.1655255, 0.0273666, 0.054859433]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.257): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.415): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.231): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.016706, rho=0.121016
bound: at document #0
-13.879 per-word bound, 15065.6 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 65, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029325303, 0.031249277, 0.03463652, 0.03329562, 0.028780818, 1.2313018, 0.1769036, 0.031516, 0.057986595, 0.21725248, 0.015602916, 0.067869805, 0.11640888, 0.026764035, 0.01858525, 0.023900306, 0.06328679, 0.21150503, 0.40978074, 0.030818943, 0.25736016, 0.11372489, 0.016951544, 0.057262644, 0.2009535, 0.02740727, 0.04448258, 0.16615723, 0.027403856, 0.05499358]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.257): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.410): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.231): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.029729, rho=0.121016
PROGRESS: pass 66, at document #2000/4566
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
optimized alpha [0.0292148, 0.031216132, 0.034493797, 0.0332113, 0.02872099, 1.2148247, 0.1771864, 0.031437747, 0.057654623, 0.21560168, 0.015593917, 0.067369156, 0.11541034, 0.026779167, 0.018540865, 0.023860063, 0.06287363, 0.21015495, 0.41090736, 0.030761506, 0.25498053, 0.11254406, 0.016916709, 0.056889214, 0.20147952, 0.027352378, 0.04429727, 0.16468686, 0.027376324, 0.05466124]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.255): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.411): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"cont"
topic #5 (1.215): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.007*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024333, rho=0.120140
PROGRESS: pass 66, at document #4000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.029332472, 0.031267125, 0.034623597, 0.03329376, 0.028812893, 1.2331517, 0.1776512, 0.031515308, 0.057994504, 0.21691126, 0.015596865, 0.06770123, 0.11619492, 0.026785111, 0.01857193, 0.02387876, 0.063194335, 0.21224767, 0.41600016, 0.030832179, 0.2571837, 0.11358858, 0.016917577, 0.05714893, 0.20293054, 0.027421061, 0.044428617, 0.1657292, 0.027398085, 0.05495218]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.257): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.416): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.233): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.016530, rho=0.120140
bound: at document #0
-13.879 per-word bound, 15063.6 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 66, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029367734, 0.031310044, 0.034687012, 0.033335377, 0.028826734, 1.2337027, 0.17712934, 0.031565677, 0.05808102, 0.21770126, 0.015593932, 0.06795943, 0.11658, 0.026799975, 0.018587494, 0.023920815, 0.063383766, 0.21173406, 0.4110358, 0.030841963, 0.2579182, 0.113917194, 0.016944794, 0.057347078, 0.20130523, 0.027434722, 0.044542503, 0.16635326, 0.027434984, 0.05508471]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.258): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.411): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.234): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.029605, rho=0.120140
PROGRESS: pass 67, at document #2000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.029257696, 0.03127674, 0.03454484, 0.033251416, 0.028767044, 1.2172912, 0.17740907, 0.03148762, 0.057750117, 0.21606484, 0.015585088, 0.06746101, 0.115578055, 0.026814898, 0.01854348, 0.023880802, 0.06296837, 0.2104045, 0.4121335, 0.0307867, 0.25553402, 0.11274678, 0.016910305, 0.056975134, 0.20183805, 0.027380105, 0.044357914, 0.16489, 0.027407534, 0.054753456]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.256): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.412): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.217): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024175, rho=0.119282
PROGRESS: pass 67, at document #4000/4566
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
optimized alpha [0.029374516, 0.031327136, 0.03467365, 0.03333322, 0.028858222, 1.2354901, 0.17786904, 0.031564508, 0.058090832, 0.21737364, 0.015588089, 0.06779435, 0.11635606, 0.026820682, 0.018574378, 0.023899348, 0.06328642, 0.21248136, 0.41717526, 0.030858718, 0.2577047, 0.113784045, 0.016911246, 0.057229273, 0.20327844, 0.027448298, 0.044488125, 0.16592427, 0.027430674, 0.05503883]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.258): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.417): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.235): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.016482, rho=0.119282
bound: at document #0
-13.879 per-word bound, 15061.5 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 67, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.02940935, 0.031369437, 0.03473638, 0.033374384, 0.028871736, 1.2360134, 0.17734814, 0.031614296, 0.058175895, 0.21814828, 0.015585264, 0.068050094, 0.11673644, 0.0268353, 0.018589877, 0.023941087, 0.06347383, 0.21196893, 0.4122232, 0.030868357, 0.2584228, 0.11410788, 0.01693834, 0.05742551, 0.2016545, 0.027461778, 0.044600893, 0.166542, 0.02746721, 0.05516982]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.258): 0.020*"google" + 0.014*"nasa" + 0.010*"ipad" + 0.010*"social" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.412): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.236): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.029363, rho=0.119282
PROGRESS: pass 68, at document #2000/4566
performing inference on a chunk of 2000 documents
1999/2000 documents converged within 50 iterations
optimized alpha [0.029299758, 0.03133598, 0.03459477, 0.033290762, 0.028812174, 1.2196565, 0.17763233, 0.031536452, 0.057849407, 0.21651511, 0.015576568, 0.06755375, 0.115744285, 0.026850022, 0.018546218, 0.023901293, 0.06306007, 0.21063097, 0.4133211, 0.030813394, 0.25604498, 0.11294039, 0.016904186, 0.057055093, 0.2021853, 0.027407434, 0.044417027, 0.16508594, 0.027439818, 0.05483648]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.256): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.413): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.220): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024129, rho=0.118442
PROGRESS: pass 68, at document #4000/4566
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
optimized alpha [0.029415749, 0.03138758, 0.03472259, 0.033373896, 0.028902654, 1.2377317, 0.17808793, 0.03161268, 0.058190934, 0.21779756, 0.015579626, 0.067880414, 0.11652254, 0.02685565, 0.01857695, 0.023919683, 0.06337557, 0.21268247, 0.41832447, 0.030883083, 0.25821236, 0.11397006, 0.016905194, 0.057307195, 0.20361695, 0.027475145, 0.04454613, 0.16612019, 0.02746111, 0.055119675]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.258): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.418): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.238): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.016256, rho=0.118442
bound: at document #0
-13.878 per-word bound, 15059.5 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 68, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.029450165, 0.031429265, 0.034784656, 0.0334146, 0.02891585, 1.2382442, 0.17756663, 0.031661905, 0.058274515, 0.21855953, 0.015576905, 0.06813383, 0.11689817, 0.026870023, 0.018592387, 0.023961114, 0.063561015, 0.21216944, 0.41338384, 0.030892598, 0.25891435, 0.11428934, 0.016932169, 0.057501577, 0.20199314, 0.02748845, 0.04465781, 0.16673277, 0.027497305, 0.055249218]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.259): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.008*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.413): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.238): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.007*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.029011, rho=0.118442
PROGRESS: pass 69, at document #2000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.029341005, 0.03139565, 0.03464357, 0.033331297, 0.028856419, 1.2219385, 0.17784825, 0.03158425, 0.057945453, 0.21692267, 0.015568348, 0.067639634, 0.11590425, 0.026884535, 0.018549072, 0.023921533, 0.0631488, 0.21083719, 0.41446123, 0.03083976, 0.25654384, 0.11313411, 0.016898343, 0.057132654, 0.20251697, 0.027434355, 0.044471987, 0.16528964, 0.027469978, 0.054920364]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.257): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.414): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.222): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.023836, rho=0.117620
PROGRESS: pass 69, at document #4000/4566
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
optimized alpha [0.029456187, 0.03144668, 0.03477045, 0.033413798, 0.028946215, 1.2399217, 0.17829946, 0.03165984, 0.05827766, 0.2182059, 0.015571461, 0.067963794, 0.11667662, 0.026890013, 0.018579643, 0.023939788, 0.063458204, 0.21288127, 0.41944912, 0.03090716, 0.2586962, 0.11414918, 0.016899424, 0.057386138, 0.20392442, 0.027501598, 0.044600055, 0.16631658, 0.027492639, 0.055204675]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.259): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.419): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.240): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.016169, rho=0.117620
bound: at document #0
-13.878 per-word bound, 15057.6 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 69, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.02949019, 0.03148776, 0.034831867, 0.033454046, 0.0289591, 1.2404048, 0.1777792, 0.031708512, 0.058359925, 0.2189568, 0.015568837, 0.06821493, 0.11704776, 0.026904143, 0.018595016, 0.023980912, 0.06364178, 0.2123706, 0.4145186, 0.03091654, 0.25938335, 0.11446405, 0.016926277, 0.057578657, 0.20230262, 0.02751472, 0.04471069, 0.16692075, 0.027528482, 0.05533271]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.259): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.415): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.240): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.028807, rho=0.117620
PROGRESS: pass 70, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.029381463, 0.031454, 0.034691334, 0.03337107, 0.028899804, 1.2241647, 0.17805816, 0.031631064, 0.05803198, 0.21733567, 0.015560419, 0.067722954, 0.11605779, 0.026918467, 0.018552039, 0.023941547, 0.06323128, 0.21105282, 0.4155929, 0.030862208, 0.25703278, 0.113316976, 0.016892776, 0.057211224, 0.20281902, 0.027460886, 0.044525642, 0.16548511, 0.027501196, 0.055004995]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.257): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.416): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.224): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.023757, rho=0.116815
PROGRESS: pass 70, at document #4000/4566
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
optimized alpha [0.029495845, 0.031506214, 0.03481728, 0.033452928, 0.028987236, 1.2420335, 0.17850575, 0.03170601, 0.058361776, 0.21861851, 0.015563585, 0.06804853, 0.116824195, 0.026923796, 0.018582447, 0.023959653, 0.0635383, 0.21308407, 0.42054215, 0.03093096, 0.25915074, 0.114325106, 0.016893921, 0.057459373, 0.20421766, 0.027527664, 0.044652656, 0.16650422, 0.027522057, 0.055287175]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.259): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.421): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.242): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.016051, rho=0.116815
bound: at document #0
-13.878 per-word bound, 15055.8 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 70, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.029529445, 0.031546697, 0.034878045, 0.033492733, 0.028999826, 1.2424936, 0.17798595, 0.031754136, 0.05844279, 0.21935768, 0.015561054, 0.0682974, 0.11719104, 0.026937693, 0.018597754, 0.024000477, 0.06372008, 0.21257304, 0.41562685, 0.03094022, 0.25982383, 0.11463573, 0.016920656, 0.057650134, 0.20260224, 0.027540615, 0.044762276, 0.16710272, 0.027557572, 0.055413768]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.260): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.416): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.242): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.028573, rho=0.116815
PROGRESS: pass 71, at document #2000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.029421156, 0.031512775, 0.034738027, 0.033410065, 0.028940678, 1.2263305, 0.17826226, 0.031676892, 0.058115937, 0.217741, 0.015552773, 0.067807496, 0.116205, 0.026951823, 0.018555105, 0.023961315, 0.063311316, 0.21125379, 0.41670045, 0.030887963, 0.25749004, 0.11348746, 0.016887456, 0.057284236, 0.2031142, 0.027487038, 0.044577982, 0.16567321, 0.027530383, 0.05508718]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.257): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.417): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.226): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.023658, rho=0.116026
PROGRESS: pass 71, at document #4000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.02953475, 0.03156443, 0.034863044, 0.033491317, 0.029029133, 1.2440888, 0.1787051, 0.03175123, 0.058443364, 0.2189998, 0.015555987, 0.06812668, 0.116965584, 0.026957, 0.018585347, 0.02397928, 0.06361603, 0.21327113, 0.42162204, 0.030956244, 0.2595983, 0.11448828, 0.016889643, 0.0575338, 0.20451455, 0.027553353, 0.044703998, 0.1666846, 0.027551036, 0.055367265]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.260): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.422): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.244): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.015837, rho=0.116026
bound: at document #0
-13.878 per-word bound, 15054.0 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 71, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.029567953, 0.03160432, 0.034923177, 0.033530686, 0.029041428, 1.244523, 0.17818508, 0.03179883, 0.058523152, 0.21972916, 0.015553549, 0.06837338, 0.11732831, 0.026970666, 0.018600587, 0.024019806, 0.063796036, 0.2127603, 0.41672227, 0.030965356, 0.2602554, 0.11479486, 0.016916256, 0.05772279, 0.20290029, 0.027566135, 0.044812623, 0.16727656, 0.027586224, 0.05549244]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.260): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.417): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.245): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.028361, rho=0.116026
PROGRESS: pass 72, at document #2000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.029460095, 0.0315685, 0.034783695, 0.033448346, 0.028982425, 1.2284261, 0.1784589, 0.031723537, 0.058197435, 0.21811405, 0.015545396, 0.06788566, 0.11635271, 0.026984613, 0.01855826, 0.02398085, 0.06338895, 0.21146035, 0.4177841, 0.03091336, 0.2579461, 0.11365126, 0.016883356, 0.057358358, 0.2034146, 0.027512813, 0.044629086, 0.16585428, 0.02755908, 0.05516699]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.258): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.418): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.228): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.023243, rho=0.115253
PROGRESS: pass 72, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.02957294, 0.03161785, 0.03490785, 0.03352899, 0.029070249, 1.2461002, 0.17889854, 0.031797275, 0.05852596, 0.21937372, 0.015548659, 0.0682064, 0.11710757, 0.026989654, 0.018588345, 0.023998683, 0.06369146, 0.21347, 0.4226791, 0.030979428, 0.26006144, 0.11464536, 0.016885603, 0.057602767, 0.20479101, 0.027578702, 0.044754118, 0.16685894, 0.027581107, 0.055441875]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.260): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"android"
topic #18 (0.423): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.246): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.015798, rho=0.115253
bound: at document #0
-13.878 per-word bound, 15052.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 72, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.029605765, 0.03165721, 0.03496738, 0.033567946, 0.029082265, 1.2465216, 0.1783796, 0.031844355, 0.058604572, 0.22009547, 0.015546308, 0.06845101, 0.11746636, 0.027003104, 0.018603524, 0.024038926, 0.06386982, 0.21296273, 0.41779324, 0.030988427, 0.26070565, 0.11496897, 0.016912099, 0.05779013, 0.2031828, 0.027591325, 0.044861805, 0.16744515, 0.027615974, 0.055565756]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.261): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.418): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.247): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.028181, rho=0.115253
PROGRESS: pass 73, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.029498322, 0.031621277, 0.034826487, 0.03348589, 0.029023381, 1.2304851, 0.17865838, 0.031769264, 0.058279876, 0.21849285, 0.015538278, 0.067965284, 0.11649487, 0.027016867, 0.018561505, 0.024000162, 0.06346775, 0.21164517, 0.41883367, 0.030934904, 0.2584117, 0.113835305, 0.01687948, 0.057427175, 0.20368178, 0.027538238, 0.04468133, 0.1660283, 0.027588906, 0.05524147]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.258): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.419): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.230): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.022938, rho=0.114495
PROGRESS: pass 73, at document #4000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.029610408, 0.03167185, 0.03494976, 0.033565942, 0.02911058, 1.2480427, 0.17909366, 0.03184238, 0.05860608, 0.21973693, 0.015541583, 0.06828363, 0.11724389, 0.027021758, 0.018591432, 0.024017852, 0.063768, 0.21364276, 0.42371705, 0.031002305, 0.2605052, 0.11482834, 0.01688177, 0.057669774, 0.20503998, 0.027603673, 0.044804465, 0.16701657, 0.02761071, 0.055514384]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.261): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.424): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.248): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.015719, rho=0.114495
bound: at document #0
-13.878 per-word bound, 15050.5 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 73, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.029642854, 0.03171067, 0.03500869, 0.033604484, 0.029122317, 1.248447, 0.1785752, 0.031888943, 0.058683515, 0.22045252, 0.0155393155, 0.06852617, 0.11759872, 0.027034987, 0.018606544, 0.02405781, 0.06394467, 0.2131363, 0.4188462, 0.031011181, 0.2611341, 0.11514812, 0.016908148, 0.057855517, 0.20343636, 0.02761613, 0.04491119, 0.16759782, 0.027645256, 0.055636972]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.010*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.261): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.419): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.248): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.028086, rho=0.114495
PROGRESS: pass 74, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.029535826, 0.031674635, 0.034868363, 0.033522744, 0.02906357, 1.2324727, 0.17885093, 0.031814054, 0.05835991, 0.21886699, 0.015531403, 0.068042524, 0.11662462, 0.027048575, 0.018564833, 0.024019245, 0.06354429, 0.21185069, 0.41987947, 0.030956194, 0.25885683, 0.114017844, 0.016875818, 0.0574941, 0.20394093, 0.02756328, 0.044726502, 0.16618884, 0.027618231, 0.05531389]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.259): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.420): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.232): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.022817, rho=0.113752
PROGRESS: pass 74, at document #4000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.029647183, 0.031724654, 0.03499076, 0.0336022, 0.029150153, 1.2499323, 0.17927453, 0.031886574, 0.058683876, 0.2200893, 0.015534748, 0.068358555, 0.11736136, 0.02705333, 0.01859461, 0.024036793, 0.06384237, 0.21383855, 0.42473257, 0.031023176, 0.26094592, 0.114991724, 0.016878145, 0.05773492, 0.20530184, 0.027628284, 0.04484701, 0.16717921, 0.027638266, 0.05558488]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.261): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.425): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.250): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.015669, rho=0.113752
bound: at document #0
-13.877 per-word bound, 15048.8 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 74, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.029679261, 0.03176295, 0.0350491, 0.03364034, 0.029161619, 1.2503307, 0.17875649, 0.031932637, 0.05876019, 0.22079958, 0.015532563, 0.06859909, 0.11771275, 0.02706635, 0.018609658, 0.02407647, 0.0640174, 0.21332973, 0.41987988, 0.03103195, 0.2615625, 0.11530786, 0.016904406, 0.0579191, 0.20370224, 0.027640581, 0.04495288, 0.16775541, 0.027672509, 0.055706237]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.262): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.420): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.250): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.027953, rho=0.113752
PROGRESS: pass 75, at document #2000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.029572638, 0.031726815, 0.03490932, 0.033558886, 0.029103005, 1.2344316, 0.17903905, 0.03185792, 0.05843763, 0.21920307, 0.015524767, 0.06811738, 0.116749376, 0.027079754, 0.018568242, 0.02403809, 0.06361861, 0.21202835, 0.4209052, 0.030977247, 0.25930682, 0.1141813, 0.016872346, 0.05755917, 0.20419392, 0.02758796, 0.044771615, 0.16635221, 0.02764557, 0.05538432]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.259): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.421): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.234): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.022684, rho=0.113023
PROGRESS: pass 75, at document #4000/4566
performing inference on a chunk of 2000 documents
1999/2000 documents converged within 50 iterations
optimized alpha [0.029683257, 0.03177633, 0.035028968, 0.033637766, 0.029188976, 1.2517799, 0.17945912, 0.031929858, 0.058756083, 0.22041637, 0.015528155, 0.06843113, 0.117487036, 0.027084362, 0.018597862, 0.024055507, 0.06391453, 0.21400298, 0.42572656, 0.031042065, 0.26139683, 0.11514898, 0.016874721, 0.057798248, 0.20553185, 0.027652534, 0.044891227, 0.16733627, 0.02766695, 0.055656575]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.261): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.426): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.252): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.015565, rho=0.113023
bound: at document #0
-13.877 per-word bound, 15047.1 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 75, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.02971497, 0.031814113, 0.035086706, 0.033675507, 0.029200176, 1.2521591, 0.17894135, 0.03197543, 0.05883135, 0.22112426, 0.015526046, 0.0686697, 0.11783478, 0.027097173, 0.018612843, 0.024094908, 0.064087965, 0.21349779, 0.4208887, 0.031050747, 0.2620006, 0.11546149, 0.016900865, 0.05798089, 0.20393628, 0.027664673, 0.044996217, 0.16790707, 0.027700882, 0.055776674]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.262): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.421): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.252): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.027582, rho=0.113023
PROGRESS: pass 76, at document #2000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.029608758, 0.031777892, 0.0349475, 0.033594362, 0.029141696, 1.2363273, 0.17923944, 0.031900894, 0.05850996, 0.21953468, 0.0155183645, 0.06818994, 0.11687542, 0.027110409, 0.018571716, 0.024056718, 0.063690804, 0.21221364, 0.42190257, 0.030999841, 0.2597625, 0.11433868, 0.016869072, 0.057622474, 0.20442799, 0.027612288, 0.04481573, 0.16651084, 0.027673986, 0.055455912]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.260): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.422): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.236): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.022215, rho=0.112308
PROGRESS: pass 76, at document #4000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.029718671, 0.03182691, 0.035066355, 0.033672687, 0.029227076, 1.2535813, 0.17966208, 0.03197227, 0.058829598, 0.2207363, 0.015521788, 0.06849769, 0.11760789, 0.027114892, 0.018601183, 0.024074007, 0.063984655, 0.21418265, 0.42670393, 0.031065986, 0.26182708, 0.115299836, 0.016871482, 0.057863098, 0.2057582, 0.027676448, 0.044934485, 0.16748828, 0.02769517, 0.055723198]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.262): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.427): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.254): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.015458, rho=0.112308
bound: at document #0
-13.877 per-word bound, 15045.5 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 76, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.029750023, 0.031864192, 0.03511657, 0.033710048, 0.029238021, 1.2539576, 0.17914358, 0.032017365, 0.05890382, 0.22144082, 0.015519754, 0.06873441, 0.117952265, 0.0271275, 0.0186161, 0.02411314, 0.06415654, 0.21367675, 0.42189068, 0.031074539, 0.26241955, 0.11560876, 0.016897513, 0.058044214, 0.20416848, 0.027688436, 0.04503863, 0.16805297, 0.027728803, 0.055842124]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.262): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.422): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.254): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.027481, rho=0.112308
PROGRESS: pass 77, at document #2000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.029644212, 0.03182788, 0.034977976, 0.033629198, 0.02917968, 1.2381985, 0.17943957, 0.031943012, 0.058583513, 0.21985379, 0.015511317, 0.06825672, 0.11699684, 0.027140567, 0.018575259, 0.02407513, 0.06376097, 0.21239136, 0.42290184, 0.03102386, 0.26018846, 0.1144898, 0.016865978, 0.057687208, 0.20467076, 0.027636278, 0.04485633, 0.16666828, 0.02770198, 0.055522542]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.260): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.423): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.238): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.022026, rho=0.111606
PROGRESS: pass 77, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.029753426, 0.031876396, 0.03509608, 0.033706978, 0.029264485, 1.2553582, 0.17985898, 0.03201384, 0.05889782, 0.22104925, 0.015514781, 0.06856628, 0.1177119, 0.027144928, 0.018604577, 0.02409229, 0.06405281, 0.2143656, 0.42768416, 0.031087862, 0.26223806, 0.115445346, 0.016868427, 0.057926163, 0.2060022, 0.027700035, 0.044974267, 0.16763686, 0.027724504, 0.055791166]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.262): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.428): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.255): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.015312, rho=0.111606
bound: at document #0
-13.877 per-word bound, 15043.9 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 77, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.029784428, 0.031913187, 0.035145853, 0.033743948, 0.02927517, 1.2557034, 0.1793404, 0.03205846, 0.05897104, 0.22174968, 0.015512821, 0.06880109, 0.11805307, 0.027157329, 0.018619427, 0.024131155, 0.064223155, 0.21386115, 0.42287895, 0.031096295, 0.2628148, 0.115750715, 0.01689434, 0.058105752, 0.2044149, 0.027711866, 0.045077592, 0.16819777, 0.02775782, 0.055908885]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.263): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.423): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"israel"
topic #5 (1.256): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.027176, rho=0.111606
PROGRESS: pass 78, at document #2000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.029679012, 0.031876788, 0.035005976, 0.033663377, 0.029218605, 1.2399976, 0.17963433, 0.031984285, 0.05865186, 0.22015965, 0.015505355, 0.06832537, 0.11710185, 0.02717023, 0.01857886, 0.02409332, 0.06382915, 0.21259136, 0.423878, 0.031045856, 0.26059523, 0.114641406, 0.016863056, 0.057750154, 0.20491003, 0.027659925, 0.044896096, 0.16682954, 0.027731016, 0.055590417]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.261): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.424): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.240): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.021869, rho=0.110918
PROGRESS: pass 78, at document #4000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.029787537, 0.031924836, 0.035123352, 0.033740617, 0.029302828, 1.2570615, 0.1800496, 0.032054573, 0.05896738, 0.2213341, 0.015508849, 0.068632714, 0.1178248, 0.027174462, 0.018608032, 0.024110349, 0.06411899, 0.21455346, 0.42863607, 0.031111175, 0.2626424, 0.11559213, 0.016865538, 0.05798108, 0.2062131, 0.027723271, 0.04501322, 0.1678006, 0.027751788, 0.05585724]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.263): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.429): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"israel"
topic #5 (1.257): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.015209, rho=0.110918
bound: at document #0
-13.877 per-word bound, 15042.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 78, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029818205, 0.031961147, 0.03517272, 0.03377722, 0.029313257, 1.2574015, 0.17953078, 0.03209873, 0.05903961, 0.22203097, 0.0155069595, 0.0688657, 0.118162766, 0.027186668, 0.018622816, 0.02414895, 0.064287856, 0.21404672, 0.42383572, 0.031119475, 0.26321027, 0.115894, 0.016891338, 0.05815929, 0.20463157, 0.02773495, 0.045115743, 0.16835459, 0.027784813, 0.055973805]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.263): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.424): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.257): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.027006, rho=0.110918
PROGRESS: pass 79, at document #2000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.029713176, 0.03192467, 0.03503351, 0.033696935, 0.02925681, 1.2417682, 0.17982168, 0.03202473, 0.058721498, 0.22044498, 0.015499597, 0.06839196, 0.11721538, 0.027199406, 0.018582515, 0.024111286, 0.0638954, 0.21278208, 0.42482883, 0.03106752, 0.26099214, 0.11479431, 0.016860304, 0.057805214, 0.20511594, 0.027683223, 0.04493506, 0.16700085, 0.02775807, 0.05565646]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.261): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.425): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.242): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.021780, rho=0.110241
PROGRESS: pass 79, at document #4000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.029821036, 0.03197055, 0.035150178, 0.033773657, 0.029340478, 1.2587497, 0.1802248, 0.032094497, 0.05903182, 0.22163063, 0.015503131, 0.068693526, 0.117920905, 0.027203523, 0.018611548, 0.024128195, 0.06418336, 0.21473302, 0.42957383, 0.031132454, 0.26303622, 0.11574326, 0.016862825, 0.05804099, 0.20642656, 0.027746182, 0.045051403, 0.16796601, 0.02778019, 0.055921566]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.263): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.430): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"south"
topic #5 (1.259): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.015149, rho=0.110241
bound: at document #0
-13.877 per-word bound, 15040.9 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 79, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029851375, 0.032006413, 0.03519915, 0.033809893, 0.029350655, 1.2590832, 0.17970628, 0.032138206, 0.05910314, 0.2223212, 0.015501307, 0.0689248, 0.11825598, 0.027215535, 0.018626267, 0.024166536, 0.06435079, 0.21422677, 0.42478433, 0.031140639, 0.26359242, 0.116041556, 0.01688851, 0.058217764, 0.2048486, 0.027757712, 0.04515315, 0.16851458, 0.02781292, 0.056037005]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.016): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.264): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.425): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.259): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026790, rho=0.110241
PROGRESS: pass 80, at document #2000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.029746737, 0.03196988, 0.035060603, 0.033729896, 0.029294329, 1.2435193, 0.17999505, 0.032064382, 0.05878618, 0.22074863, 0.015494045, 0.068453126, 0.11731302, 0.027229091, 0.01858623, 0.02412904, 0.063959904, 0.21296845, 0.42577007, 0.031090643, 0.26138198, 0.114945315, 0.016857715, 0.05786509, 0.20533384, 0.027706198, 0.04497325, 0.16716704, 0.027786214, 0.05572078]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.261): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.426): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.244): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.021652, rho=0.109578
PROGRESS: pass 80, at document #4000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.029853936, 0.032017004, 0.035176557, 0.033806093, 0.029377444, 1.2603959, 0.18039395, 0.032133628, 0.059094522, 0.22192645, 0.015497609, 0.06875646, 0.118026644, 0.027233107, 0.018615115, 0.024145823, 0.064245954, 0.21490727, 0.430477, 0.031155167, 0.26341796, 0.11589433, 0.016860265, 0.058096126, 0.20662709, 0.027768768, 0.04508881, 0.16813187, 0.0278066, 0.05598416]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.263): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.430): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.003*"south"
topic #5 (1.260): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.015120, rho=0.109578
bound: at document #0
-13.876 per-word bound, 15039.5 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 80, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029883951, 0.03205241, 0.03522515, 0.033841975, 0.029387375, 1.2607199, 0.17987661, 0.0321769, 0.05916495, 0.22260924, 0.01549585, 0.068985984, 0.118358694, 0.027244924, 0.018629767, 0.024183908, 0.06441198, 0.21440066, 0.42569318, 0.031163223, 0.26396242, 0.11618915, 0.01688584, 0.058271542, 0.20505513, 0.027780155, 0.045198034, 0.16867478, 0.02783905, 0.056098506]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.264): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.426): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.261): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026738, rho=0.109578
PROGRESS: pass 81, at document #2000/4566
performing inference on a chunk of 2000 documents
1993/2000 documents converged within 50 iterations
optimized alpha [0.029779693, 0.03201581, 0.035087254, 0.03376226, 0.029331163, 1.2452228, 0.18017228, 0.032103267, 0.058849137, 0.22104147, 0.01548868, 0.0685163, 0.11741955, 0.027258663, 0.018589988, 0.024146583, 0.06402265, 0.21314801, 0.4266694, 0.031113442, 0.26176378, 0.1150964, 0.016855277, 0.05792033, 0.20554861, 0.027728852, 0.04501881, 0.16733223, 0.027812399, 0.055783406]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.262): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.427): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.245): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.021571, rho=0.108926
PROGRESS: pass 81, at document #4000/4566
performing inference on a chunk of 2000 documents
1999/2000 documents converged within 50 iterations
optimized alpha [0.029886238, 0.0320608, 0.035202526, 0.03383795, 0.029415295, 1.2620168, 0.18057777, 0.032172, 0.05915881, 0.22221144, 0.015492272, 0.06881765, 0.11812247, 0.027262522, 0.018618736, 0.02416324, 0.06430684, 0.21507727, 0.43135786, 0.031177578, 0.26378897, 0.11604043, 0.016857859, 0.05814672, 0.2068428, 0.027791042, 0.04513353, 0.16827528, 0.027832601, 0.05604512]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.264): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.431): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.262): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.014953, rho=0.108926
bound: at document #0
-13.876 per-word bound, 15038.1 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 81, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029915938, 0.03209577, 0.035250742, 0.033873476, 0.029424975, 1.2623248, 0.18005943, 0.03221484, 0.059228316, 0.22288737, 0.015490571, 0.06904548, 0.11845167, 0.027274145, 0.018633325, 0.024201076, 0.06447149, 0.21457419, 0.4265813, 0.031185508, 0.2643224, 0.116331734, 0.01688332, 0.058320835, 0.20527552, 0.027802283, 0.045242082, 0.16881287, 0.02786477, 0.056158382]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.264): 0.020*"google" + 0.014*"nasa" + 0.010*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.427): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.262): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026689, rho=0.108926
PROGRESS: pass 82, at document #2000/4566
performing inference on a chunk of 2000 documents
1993/2000 documents converged within 50 iterations
optimized alpha [0.02981204, 0.03205738, 0.035113465, 0.03379402, 0.02936885, 1.2468637, 0.18034275, 0.032141365, 0.058913525, 0.22134626, 0.015483495, 0.068577655, 0.11751016, 0.027287833, 0.018593794, 0.0241639, 0.06408363, 0.21332826, 0.42754704, 0.03113593, 0.2621214, 0.11524223, 0.016852982, 0.057971053, 0.20575616, 0.027751178, 0.045063477, 0.16747618, 0.027836673, 0.055844337]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.262): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.428): 0.013*"news" + 0.007*"wikileaks" + 0.007*"police" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.247): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.021461, rho=0.108285
PROGRESS: pass 82, at document #4000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.029917944, 0.03210364, 0.035228048, 0.033869207, 0.029452445, 1.2635608, 0.18074474, 0.032209598, 0.059218112, 0.22251341, 0.015487111, 0.06887706, 0.118202485, 0.027291564, 0.018622397, 0.024180437, 0.06436598, 0.21524562, 0.43220744, 0.03119799, 0.2641517, 0.11618053, 0.016855588, 0.05819912, 0.207039, 0.027812995, 0.04517738, 0.16841309, 0.027858205, 0.05610439]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.264): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.432): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.264): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.014844, rho=0.108285
bound: at document #0
-13.876 per-word bound, 15036.8 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 82, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.029947342, 0.032138202, 0.03527591, 0.033904396, 0.029461887, 1.2639103, 0.18022667, 0.03225202, 0.059286814, 0.22318101, 0.015485472, 0.06910325, 0.11852935, 0.027302999, 0.01863692, 0.024218028, 0.06452931, 0.21474177, 0.4274447, 0.03120581, 0.2646773, 0.11646875, 0.01688094, 0.05837195, 0.20547654, 0.0278241, 0.045285173, 0.16891912, 0.027890109, 0.05621665]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.265): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.427): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.264): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026578, rho=0.108285
PROGRESS: pass 83, at document #2000/4566
performing inference on a chunk of 2000 documents
1993/2000 documents converged within 50 iterations
optimized alpha [0.029843824, 0.032101516, 0.035141073, 0.033823356, 0.029405871, 1.2485335, 0.18050791, 0.032178733, 0.05897318, 0.22161715, 0.015478487, 0.06863741, 0.11759864, 0.02731655, 0.018597636, 0.024181016, 0.06414302, 0.21350099, 0.42840374, 0.031156426, 0.2625174, 0.11538298, 0.016850827, 0.058023617, 0.20596242, 0.027773203, 0.04510723, 0.1675894, 0.027862083, 0.055903733]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.263): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.428): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.249): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.021341, rho=0.107656
PROGRESS: pass 83, at document #4000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.029949086, 0.032147326, 0.035254963, 0.033898037, 0.02949048, 1.2651325, 0.18090634, 0.03224646, 0.059279047, 0.2227575, 0.015482123, 0.06893485, 0.11829249, 0.027321644, 0.018626098, 0.024197428, 0.064423524, 0.21539518, 0.433038, 0.031219779, 0.26451755, 0.11631549, 0.016853455, 0.05825019, 0.20723954, 0.027834628, 0.045220304, 0.16852845, 0.027883409, 0.056159105]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.265): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.433): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.265): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.014747, rho=0.107656
bound: at document #0
-13.876 per-word bound, 15035.4 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 83, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.029978178, 0.03218146, 0.03530245, 0.033932906, 0.02949967, 1.2654775, 0.18038903, 0.03228847, 0.059346884, 0.22341767, 0.01548054, 0.06915941, 0.11861667, 0.02733288, 0.018640555, 0.024234774, 0.06458554, 0.21489239, 0.42828637, 0.031227477, 0.26503038, 0.1166004, 0.016878696, 0.058421746, 0.20568062, 0.027845595, 0.045327306, 0.16903047, 0.02791504, 0.05627038]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.265): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.428): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.265): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026344, rho=0.107656
PROGRESS: pass 84, at document #2000/4566
performing inference on a chunk of 2000 documents
1992/2000 documents converged within 50 iterations
optimized alpha [0.029875038, 0.032144703, 0.03516824, 0.033852175, 0.029443739, 1.2501637, 0.18066792, 0.032215364, 0.059034333, 0.22187258, 0.015473641, 0.0686955, 0.11768374, 0.027346268, 0.018601513, 0.024197921, 0.06420076, 0.21365824, 0.4292368, 0.031176649, 0.26288605, 0.115518175, 0.0168488, 0.058074847, 0.20616177, 0.027794894, 0.045150016, 0.16770764, 0.027887074, 0.055958636]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.263): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.429): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.250): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.021143, rho=0.107037
PROGRESS: pass 84, at document #4000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.029979695, 0.03218844, 0.035281487, 0.03392639, 0.029527826, 1.266701, 0.18106355, 0.03228262, 0.05933841, 0.223023, 0.015477302, 0.06899115, 0.11836732, 0.027351258, 0.018629838, 0.024214221, 0.064479575, 0.21555336, 0.43385062, 0.031239638, 0.26487577, 0.11643904, 0.016851457, 0.058300033, 0.20742452, 0.027855966, 0.04526232, 0.16865091, 0.027908223, 0.05621248]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.265): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.434): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.267): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.014625, rho=0.107037
bound: at document #0
-13.876 per-word bound, 15034.0 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 84, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.030008491, 0.03222217, 0.035328604, 0.033960935, 0.02953677, 1.2670206, 0.18054636, 0.032324225, 0.05940541, 0.22367615, 0.015475771, 0.0692141, 0.118689165, 0.027362298, 0.01864423, 0.024251329, 0.0646403, 0.21505156, 0.4291081, 0.031247225, 0.2653789, 0.116720974, 0.016876586, 0.058470327, 0.20587258, 0.027866794, 0.04536853, 0.1691491, 0.02793959, 0.05632278]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.265): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.429): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.267): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026132, rho=0.107037
PROGRESS: pass 85, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.029905697, 0.032185372, 0.03519496, 0.033880483, 0.029480927, 1.251757, 0.18082312, 0.032251276, 0.059093896, 0.22212587, 0.015468959, 0.06875205, 0.117766716, 0.027375521, 0.018605422, 0.024214623, 0.064256996, 0.21382211, 0.43004894, 0.0311966, 0.2632448, 0.11564234, 0.0168469, 0.058124777, 0.20634834, 0.027816283, 0.045191854, 0.16783172, 0.027911674, 0.056012172]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.263): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.430): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.252): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.021042, rho=0.106429
PROGRESS: pass 85, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.030009732, 0.032228712, 0.03530755, 0.033954225, 0.029564489, 1.2682136, 0.18120535, 0.032318052, 0.059402417, 0.22327003, 0.015472641, 0.06904586, 0.118452355, 0.027380386, 0.01863361, 0.024230804, 0.06453407, 0.21569644, 0.43463677, 0.031259224, 0.26523116, 0.1165641, 0.01684958, 0.058345478, 0.20760353, 0.02787699, 0.04530338, 0.16876093, 0.027932638, 0.056264494]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.265): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.435): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.268): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.014579, rho=0.106429
bound: at document #0
-13.876 per-word bound, 15032.6 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 85, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.030038238, 0.032262046, 0.03535431, 0.033988457, 0.029573193, 1.2685193, 0.18068883, 0.032359257, 0.05946852, 0.22391672, 0.015471162, 0.06926724, 0.118771546, 0.027391234, 0.018647935, 0.024267672, 0.06469353, 0.21519892, 0.42990226, 0.0312667, 0.26572472, 0.116843, 0.0168746, 0.05851458, 0.20605342, 0.02788768, 0.045408804, 0.16925582, 0.027963746, 0.05637385]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.266): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.430): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.269): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.026043, rho=0.106429
PROGRESS: pass 86, at document #2000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.029935816, 0.032225225, 0.035221256, 0.033908304, 0.029517435, 1.2533169, 0.18096332, 0.032286495, 0.059157982, 0.22236986, 0.015464435, 0.06880712, 0.11785319, 0.027402867, 0.018609358, 0.024231125, 0.064311765, 0.21398062, 0.43084905, 0.031216301, 0.2636129, 0.11576815, 0.016845126, 0.058170505, 0.20653415, 0.02783736, 0.04523277, 0.16794483, 0.027935892, 0.05606442]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.264): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.431): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.253): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020969, rho=0.105832
PROGRESS: pass 86, at document #4000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.030039256, 0.032268178, 0.03533318, 0.03398159, 0.029603582, 1.2696884, 0.18133217, 0.032352813, 0.059455328, 0.22350176, 0.015467318, 0.069095515, 0.118534826, 0.027407622, 0.018637417, 0.024247194, 0.06458718, 0.21585406, 0.43543935, 0.03127857, 0.26559064, 0.11668465, 0.016847827, 0.058396008, 0.20777836, 0.027897723, 0.045343537, 0.16886908, 0.02795668, 0.05632122]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"november" + 0.012*"expected" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.266): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.435): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.270): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.014549, rho=0.105832
bound: at document #0
-13.876 per-word bound, 15031.5 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 86, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.030067485, 0.03230113, 0.035379592, 0.034015525, 0.029612035, 1.2700162, 0.18081684, 0.032393638, 0.059520725, 0.224144, 0.015465897, 0.06931545, 0.118851624, 0.027418297, 0.018651681, 0.024283832, 0.06474546, 0.21534301, 0.4307177, 0.031285945, 0.26607478, 0.11696075, 0.016872743, 0.058563903, 0.20623374, 0.027908286, 0.045448206, 0.1693598, 0.027987538, 0.056429617]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.266): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.431): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.270): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.025672, rho=0.105832
PROGRESS: pass 87, at document #2000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.029965406, 0.032264277, 0.0352471, 0.03393564, 0.029556336, 1.2548578, 0.18108971, 0.032321036, 0.059211276, 0.22260343, 0.015459244, 0.06885725, 0.11793701, 0.027431209, 0.018613324, 0.024247421, 0.06436515, 0.21411672, 0.4316361, 0.031235745, 0.26399595, 0.11588934, 0.016843475, 0.058221113, 0.206709, 0.02785815, 0.045272764, 0.16805443, 0.027959732, 0.05612118]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.264): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.432): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.255): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020752, rho=0.105244
PROGRESS: pass 87, at document #4000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.030068247, 0.03230848, 0.035358377, 0.034008473, 0.029641965, 1.2711294, 0.18145582, 0.032386888, 0.05951002, 0.22373421, 0.0154629685, 0.069147505, 0.11862053, 0.02743583, 0.018641246, 0.024263365, 0.0646389, 0.2159668, 0.43618974, 0.03129765, 0.26596087, 0.116800606, 0.016846197, 0.05844218, 0.20796251, 0.027918149, 0.04538277, 0.16897348, 0.027980339, 0.05637345]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.266): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.436): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.271): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.014401, rho=0.105244
bound: at document #0
-13.876 per-word bound, 15030.1 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 87, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.030096196, 0.03234105, 0.035404444, 0.03404211, 0.029650168, 1.2714479, 0.18094236, 0.03242733, 0.059574664, 0.22437035, 0.015461597, 0.06936595, 0.11893482, 0.027446324, 0.018655447, 0.024299772, 0.06479599, 0.21545967, 0.43147808, 0.031304926, 0.26643586, 0.11707393, 0.016871005, 0.058608904, 0.20642342, 0.027928583, 0.045486685, 0.1694601, 0.028010948, 0.056480926]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.012*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.266): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.431): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.271): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.025414, rho=0.105244
PROGRESS: pass 88, at document #2000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.02999447, 0.032304157, 0.03527251, 0.033962507, 0.029594526, 1.2563384, 0.18121326, 0.03235491, 0.059266295, 0.22284037, 0.01545422, 0.068909615, 0.1180294, 0.02745908, 0.018617319, 0.02426351, 0.06441715, 0.21425223, 0.4323941, 0.031256553, 0.26435307, 0.11600616, 0.016841937, 0.05826747, 0.20690434, 0.02787863, 0.04531187, 0.16816096, 0.027983192, 0.05617358]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.264): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.432): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.256): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020667, rho=0.104666
PROGRESS: pass 88, at document #4000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.030096743, 0.03234635, 0.03538317, 0.03403489, 0.029679632, 1.2725449, 0.18157665, 0.032420315, 0.059563354, 0.22396545, 0.0154579645, 0.069198176, 0.118702896, 0.027463581, 0.018645113, 0.024279349, 0.06468929, 0.21611467, 0.43693388, 0.031318117, 0.2663069, 0.11691234, 0.016844679, 0.05848722, 0.20813453, 0.027938297, 0.045421164, 0.16907516, 0.028003631, 0.056424398]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.266): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.437): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.273): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.014209, rho=0.104666
bound: at document #0
-13.875 per-word bound, 15028.8 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 88, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.030124435, 0.032378566, 0.03542892, 0.03406825, 0.029687604, 1.2728643, 0.18106523, 0.032460403, 0.05962731, 0.22459613, 0.015456646, 0.06941523, 0.11901497, 0.027473906, 0.018659255, 0.024315538, 0.06484529, 0.21561746, 0.4322579, 0.031325288, 0.26677322, 0.11718146, 0.016869387, 0.058652844, 0.20660111, 0.02794861, 0.045524362, 0.16955914, 0.028034005, 0.05653102]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.267): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.432): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.273): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.025380, rho=0.104666
PROGRESS: pass 89, at document #2000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.03002305, 0.032341644, 0.035297528, 0.03398892, 0.02963202, 1.257809, 0.18133757, 0.03238815, 0.059319966, 0.22307146, 0.015450151, 0.06896073, 0.11811343, 0.027486507, 0.018621335, 0.024279412, 0.06446789, 0.21441413, 0.4331613, 0.031277124, 0.2647006, 0.11611713, 0.016840512, 0.058312748, 0.20706801, 0.027898835, 0.04535014, 0.16826549, 0.028006306, 0.05622474]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.265): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.433): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.258): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020637, rho=0.104097
PROGRESS: pass 89, at document #4000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.030124744, 0.03238509, 0.03540756, 0.03406086, 0.029716616, 1.2738976, 0.1817058, 0.032453105, 0.05961839, 0.22420019, 0.015453912, 0.06924756, 0.118788846, 0.027490877, 0.018648991, 0.024295123, 0.06474134, 0.21625306, 0.43767065, 0.031336695, 0.2666562, 0.11701827, 0.016843265, 0.058531184, 0.20829813, 0.027958162, 0.045458715, 0.16917498, 0.02802657, 0.056471154]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.267): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.438): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.274): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.014152, rho=0.104097
bound: at document #0
-13.875 per-word bound, 15027.6 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 89, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.030152168, 0.032416932, 0.035452973, 0.034093924, 0.02972434, 1.2742001, 0.18119483, 0.032492828, 0.05968158, 0.22482353, 0.015452637, 0.069463156, 0.119098365, 0.027501026, 0.01866307, 0.024331091, 0.064896144, 0.21575902, 0.43300277, 0.03134376, 0.26711506, 0.117285416, 0.016867867, 0.05869567, 0.20676944, 0.027968349, 0.045561176, 0.16965571, 0.028056702, 0.056576923]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.267): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.433): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.274): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.025244, rho=0.104097
PROGRESS: pass 90, at document #2000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.03005113, 0.032379974, 0.03532213, 0.034014866, 0.029668827, 1.2592049, 0.18147166, 0.03242076, 0.059375238, 0.22330312, 0.01544622, 0.0690105, 0.11820051, 0.02751206, 0.018625364, 0.024295105, 0.06452016, 0.21456015, 0.43391114, 0.031295754, 0.2650507, 0.11622502, 0.016839178, 0.058356915, 0.20723537, 0.027918749, 0.04538758, 0.1683682, 0.028029058, 0.05627178]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.265): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.434): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.259): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020454, rho=0.103538
PROGRESS: pass 90, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.030152267, 0.032423038, 0.03543157, 0.0340864, 0.029752923, 1.2752267, 0.181839, 0.03248529, 0.05967183, 0.22443268, 0.015449998, 0.06929571, 0.11886619, 0.027516324, 0.018652901, 0.024310725, 0.06478905, 0.21639848, 0.43840966, 0.031355012, 0.26699805, 0.11712138, 0.016841952, 0.058573876, 0.20845835, 0.027977735, 0.04549545, 0.16927321, 0.02804915, 0.056519743]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.007*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.267): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.438): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.275): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"people" + 0.008*"time" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.014104, rho=0.103538
bound: at document #0
-13.875 per-word bound, 15026.4 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 90, at document #4566/4566
performing inference on a chunk of 566 documents
565/566 documents converged within 50 iterations
optimized alpha [0.030179432, 0.032454524, 0.035476662, 0.03411919, 0.029760418, 1.2755301, 0.18132874, 0.03252466, 0.05973431, 0.22505066, 0.01544877, 0.06950993, 0.11917345, 0.027526312, 0.018666917, 0.024346475, 0.06494277, 0.21590912, 0.43377218, 0.031361986, 0.2674493, 0.117366284, 0.016866453, 0.058737285, 0.20693438, 0.027987804, 0.0455972, 0.16975111, 0.028079048, 0.05662466]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.267): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.434): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.276): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.025142, rho=0.103538
PROGRESS: pass 91, at document #2000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.030078743, 0.032417536, 0.03534634, 0.03404041, 0.029704958, 1.260584, 0.18160857, 0.032452755, 0.059428975, 0.2235363, 0.0154424235, 0.069059074, 0.11827928, 0.027537208, 0.018629426, 0.024310626, 0.06456824, 0.21471497, 0.43467245, 0.031312574, 0.26539382, 0.11631026, 0.01683795, 0.058399856, 0.20739712, 0.027938385, 0.045424197, 0.16846938, 0.028051455, 0.056320585]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.265): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.435): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.261): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.009*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020317, rho=0.102987
PROGRESS: pass 91, at document #4000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.030179322, 0.032460246, 0.035455197, 0.03411319, 0.029788544, 1.2765312, 0.18197306, 0.032516878, 0.059721068, 0.22466384, 0.015446218, 0.06934265, 0.11894637, 0.027541373, 0.018656831, 0.024326133, 0.0648387, 0.21654172, 0.43914893, 0.031371504, 0.26733083, 0.117202096, 0.016840745, 0.058615826, 0.20861353, 0.027997052, 0.0455314, 0.16936976, 0.028071394, 0.05656716]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.008*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.267): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.439): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.277): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.014044, rho=0.102987
bound: at document #0
-13.875 per-word bound, 15025.2 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 91, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.030206231, 0.032491375, 0.03549996, 0.034145687, 0.029795809, 1.2768191, 0.18146272, 0.032555893, 0.05978287, 0.2252748, 0.015445029, 0.069555484, 0.119251296, 0.027551198, 0.018670782, 0.024361666, 0.06499128, 0.21605447, 0.4345212, 0.031378385, 0.26777166, 0.11744518, 0.016865138, 0.058778152, 0.20709276, 0.028006995, 0.045632437, 0.16984382, 0.028101059, 0.056671232]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.268): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.435): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.277): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024827, rho=0.102987
PROGRESS: pass 92, at document #2000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.03010587, 0.032454357, 0.035370167, 0.034067154, 0.029740414, 1.2619283, 0.18174163, 0.03248417, 0.059478577, 0.22376397, 0.015438753, 0.06910642, 0.118362986, 0.027561959, 0.018633487, 0.024325952, 0.06461811, 0.21486397, 0.43541247, 0.03132917, 0.26572636, 0.11639352, 0.016836822, 0.058442034, 0.20755178, 0.027957752, 0.045460027, 0.16856778, 0.028073518, 0.056368195]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.266): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.435): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.262): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.009*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020241, rho=0.102445
PROGRESS: pass 92, at document #4000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.0302059, 0.032495096, 0.03547842, 0.03413951, 0.029823497, 1.2777969, 0.18210182, 0.032547858, 0.05977511, 0.22487655, 0.015442558, 0.06938834, 0.11902689, 0.02756601, 0.018660769, 0.02434134, 0.06488722, 0.21667342, 0.43986648, 0.03138938, 0.26763818, 0.11728057, 0.016839622, 0.05865377, 0.20876306, 0.028016094, 0.04556652, 0.16946317, 0.028093284, 0.05661046]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.008*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.268): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.440): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.278): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.013944, rho=0.102445
bound: at document #0
-13.875 per-word bound, 15023.2 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 92, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.03023256, 0.032525897, 0.035516467, 0.03417173, 0.029830543, 1.2780777, 0.1815925, 0.032586537, 0.05983619, 0.22548175, 0.015441412, 0.069612324, 0.11932947, 0.02757569, 0.01867466, 0.024376662, 0.06503873, 0.21618903, 0.43524447, 0.031396173, 0.26807457, 0.11753802, 0.016863916, 0.058815096, 0.20724872, 0.028025923, 0.04566688, 0.16993473, 0.028122725, 0.05671376]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.268): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.435): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.278): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024740, rho=0.102445
PROGRESS: pass 93, at document #2000/4566
performing inference on a chunk of 2000 documents
1995/2000 documents converged within 50 iterations
optimized alpha [0.03013254, 0.03248888, 0.035387266, 0.034093443, 0.029775215, 1.2632446, 0.18187058, 0.03251498, 0.059532832, 0.22398499, 0.015435204, 0.069164805, 0.11844225, 0.027586324, 0.01863757, 0.024341078, 0.06466694, 0.21500307, 0.43613124, 0.031348743, 0.26603764, 0.116490014, 0.016835777, 0.05848035, 0.20770672, 0.027976852, 0.045495074, 0.16866434, 0.028095242, 0.05641185]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.266): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.436): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.263): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.009*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020159, rho=0.101912
PROGRESS: pass 93, at document #4000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.030232022, 0.03253087, 0.03549498, 0.034165386, 0.029857809, 1.2790233, 0.18222097, 0.03257826, 0.059821695, 0.22509025, 0.015439021, 0.069445, 0.11910241, 0.02759027, 0.018664721, 0.024356367, 0.064934514, 0.2168014, 0.44057354, 0.03140862, 0.26793838, 0.11737248, 0.016838595, 0.058693867, 0.20892094, 0.02803487, 0.045600887, 0.16955526, 0.028114846, 0.056655675]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.008*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.268): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.441): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.279): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.013878, rho=0.101912
bound: at document #0
-13.875 per-word bound, 15021.9 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 93, at document #4566/4566
performing inference on a chunk of 566 documents
564/566 documents converged within 50 iterations
optimized alpha [0.030258445, 0.032561343, 0.035532802, 0.034197334, 0.029864643, 1.279304, 0.1817128, 0.032616615, 0.059882175, 0.22569071, 0.015437917, 0.06966749, 0.11941398, 0.0275998, 0.018678553, 0.024391484, 0.06508498, 0.2163193, 0.43596628, 0.03141531, 0.26836738, 0.11763231, 0.016862793, 0.05885418, 0.20741136, 0.028044589, 0.04570058, 0.1700243, 0.028144069, 0.0567582]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.268): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.436): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.279): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024550, rho=0.101912
PROGRESS: pass 94, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.030158749, 0.032524295, 0.03540238, 0.034119293, 0.029809386, 1.2645211, 0.18199001, 0.032545224, 0.059579838, 0.22419648, 0.015431771, 0.06922495, 0.11852995, 0.027611686, 0.018641654, 0.024356028, 0.06471452, 0.2151382, 0.43683657, 0.03136803, 0.26633635, 0.11658745, 0.01683483, 0.0585207, 0.20786604, 0.027995681, 0.045529354, 0.16875905, 0.028116632, 0.056457307]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.266): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.437): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.265): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.009*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020044, rho=0.101387
PROGRESS: pass 94, at document #4000/4566
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
optimized alpha [0.030257704, 0.032564368, 0.03550958, 0.034190826, 0.029891504, 1.2802414, 0.18233836, 0.03260811, 0.059867173, 0.22529541, 0.015435602, 0.06950346, 0.11918069, 0.027615512, 0.01866869, 0.02437122, 0.06498064, 0.2169396, 0.44125667, 0.031425994, 0.26824617, 0.11746541, 0.016837658, 0.058733057, 0.2090656, 0.028053388, 0.04563234, 0.16964543, 0.028136088, 0.056699812]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.011*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.008*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.268): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.441): 0.013*"news" + 0.007*"police" + 0.006*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.280): 0.014*"day" + 0.010*"today" + 0.010*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.013819, rho=0.101387
bound: at document #0
-13.875 per-word bound, 15020.6 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 94, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.030283876, 0.03259451, 0.03554718, 0.034222487, 0.029898116, 1.2805059, 0.18183221, 0.032646127, 0.059926987, 0.22588792, 0.015434533, 0.06972435, 0.119498454, 0.02762982, 0.01868246, 0.024406126, 0.06513001, 0.21642049, 0.43665504, 0.03143258, 0.2686701, 0.117724694, 0.016861752, 0.058892317, 0.20755976, 0.028062982, 0.04573136, 0.17011152, 0.028165078, 0.056801517]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.007*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.269): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.437): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.281): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024428, rho=0.101387
PROGRESS: pass 95, at document #2000/4566
performing inference on a chunk of 2000 documents
1993/2000 documents converged within 50 iterations
optimized alpha [0.030184522, 0.032557476, 0.035417374, 0.034144707, 0.029842941, 1.2658024, 0.18211773, 0.03257493, 0.05962575, 0.22440413, 0.015426902, 0.06928333, 0.1186235, 0.027640162, 0.018645758, 0.024370808, 0.06476096, 0.21524617, 0.43751705, 0.031385493, 0.26665828, 0.11668411, 0.016833963, 0.058560163, 0.20801891, 0.028014254, 0.045560777, 0.16885228, 0.028137704, 0.056501728]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.267): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.438): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.266): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.009*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.020011, rho=0.100870
PROGRESS: pass 95, at document #4000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.030282956, 0.032597225, 0.035524055, 0.034215838, 0.029924575, 1.2814468, 0.18246374, 0.032637417, 0.059917584, 0.22549705, 0.015430746, 0.069560155, 0.11927621, 0.027643867, 0.018672667, 0.024385896, 0.0650256, 0.2170287, 0.4419302, 0.03144315, 0.2685568, 0.11755755, 0.016837638, 0.05876842, 0.20921408, 0.028071651, 0.045663156, 0.16973431, 0.028157009, 0.056737274]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.012*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.008*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.269): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.442): 0.013*"news" + 0.007*"police" + 0.006*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.281): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.013772, rho=0.100870
bound: at document #0
-13.875 per-word bound, 15019.4 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 95, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.030308887, 0.03262705, 0.035561442, 0.03424723, 0.029930975, 1.2816993, 0.18195733, 0.03267511, 0.059976704, 0.22608322, 0.01542972, 0.06977954, 0.11959224, 0.027657976, 0.018686375, 0.024420597, 0.06517394, 0.21651009, 0.43734765, 0.031449642, 0.26897278, 0.1178153, 0.016861629, 0.05892671, 0.20771351, 0.028081127, 0.045753513, 0.17019753, 0.028185785, 0.056838267]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.269): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.437): 0.013*"news" + 0.007*"police" + 0.006*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.282): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024327, rho=0.100870
PROGRESS: pass 96, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.030209852, 0.032590006, 0.03543223, 0.03416968, 0.029875873, 1.2670511, 0.18223196, 0.03260408, 0.05967637, 0.22460525, 0.015423707, 0.06933993, 0.118720055, 0.02766817, 0.018649863, 0.024385402, 0.06480622, 0.21532995, 0.4382162, 0.03140431, 0.26697055, 0.11677758, 0.016834002, 0.058595873, 0.20816253, 0.028032558, 0.04558365, 0.16894366, 0.028158462, 0.056539588]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.267): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.438): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.267): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.009*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.019923, rho=0.100360
PROGRESS: pass 96, at document #4000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.030307757, 0.03262942, 0.03553838, 0.034240387, 0.029957034, 1.2826145, 0.1825753, 0.032666165, 0.059966605, 0.22569208, 0.015427557, 0.06961506, 0.11936877, 0.027671734, 0.01867572, 0.024400378, 0.06506938, 0.21710478, 0.44259408, 0.031463213, 0.2688421, 0.11764645, 0.016837684, 0.058802985, 0.20934923, 0.028089637, 0.045685418, 0.16982105, 0.028177593, 0.05677665]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.012*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.008*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.269): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.443): 0.013*"news" + 0.007*"police" + 0.006*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.283): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.013756, rho=0.100360
bound: at document #0
-13.874 per-word bound, 15018.5 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 96, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.030333461, 0.03265894, 0.035575554, 0.034271516, 0.02996323, 1.2828577, 0.18207115, 0.03270354, 0.060025066, 0.22627312, 0.015426569, 0.069832966, 0.11968276, 0.027685648, 0.01868937, 0.024434878, 0.06521671, 0.21658976, 0.43802404, 0.03146959, 0.26925403, 0.11790252, 0.016861577, 0.058960326, 0.20785268, 0.028099004, 0.04577526, 0.1702817, 0.028206155, 0.056876928]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.269): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.438): 0.013*"news" + 0.007*"police" + 0.006*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.283): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.024211, rho=0.100360
PROGRESS: pass 97, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.03023474, 0.032621894, 0.035446916, 0.034194205, 0.02990819, 1.2682562, 0.18234323, 0.03263267, 0.05972862, 0.22480197, 0.015419848, 0.06939477, 0.11881311, 0.02769706, 0.018653044, 0.024399806, 0.06485029, 0.21542665, 0.43886754, 0.031424385, 0.26725113, 0.11686887, 0.016834106, 0.05863076, 0.20829734, 0.028050592, 0.045606088, 0.16903263, 0.028178878, 0.056576457]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.267): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.439): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.268): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.009*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.019875, rho=0.099859
PROGRESS: pass 97, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.030332133, 0.032661017, 0.03555257, 0.03426452, 0.02999038, 1.2837595, 0.18268475, 0.03269438, 0.060020346, 0.22588095, 0.015423712, 0.06966832, 0.11945818, 0.027700495, 0.018678792, 0.024414686, 0.065112054, 0.21719348, 0.44322842, 0.03148141, 0.26912916, 0.11773532, 0.016837796, 0.058836818, 0.2094864, 0.028108768, 0.045705125, 0.16990611, 0.028197875, 0.056814898]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.012*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.008*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.269): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.443): 0.013*"news" + 0.007*"police" + 0.006*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.284): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.013678, rho=0.099859
bound: at document #0
-13.874 per-word bound, 15017.4 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 97, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.030357605, 0.03269024, 0.035589535, 0.034295388, 0.029996365, 1.2839867, 0.18218099, 0.032731447, 0.060078073, 0.22645602, 0.015422759, 0.06988478, 0.11976974, 0.027714206, 0.018692385, 0.024448985, 0.06525839, 0.21668024, 0.4386698, 0.031487685, 0.26953474, 0.11798953, 0.016861586, 0.05899322, 0.20799412, 0.02811801, 0.045794472, 0.17036307, 0.028226225, 0.05691446]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.270): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.439): 0.013*"news" + 0.007*"police" + 0.006*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.284): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.023980, rho=0.099859
PROGRESS: pass 98, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.030259192, 0.032653183, 0.035461456, 0.034218304, 0.029941378, 1.2694366, 0.18245107, 0.032660738, 0.059779435, 0.22498943, 0.015416865, 0.06944797, 0.118896745, 0.02772545, 0.018656245, 0.024414029, 0.06489326, 0.21552277, 0.43950358, 0.03144108, 0.26752868, 0.1169593, 0.016834272, 0.05866492, 0.20843625, 0.028069738, 0.04562829, 0.16911909, 0.028198993, 0.05661787]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.268): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.440): 0.013*"news" + 0.007*"police" + 0.007*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.269): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.009*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.019769, rho=0.099365
PROGRESS: pass 98, at document #4000/4566
performing inference on a chunk of 2000 documents
1996/2000 documents converged within 50 iterations
optimized alpha [0.030354649, 0.032692004, 0.035566613, 0.034288242, 0.030023115, 1.2848843, 0.18279083, 0.032722075, 0.060063794, 0.22606313, 0.015420741, 0.06971997, 0.119543314, 0.027728764, 0.018681884, 0.024428813, 0.06515365, 0.21728075, 0.44384775, 0.031497817, 0.2693984, 0.11782337, 0.01683797, 0.058872826, 0.20962164, 0.02812762, 0.045726813, 0.1699884, 0.028217848, 0.05685799]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.012*"tvxq" + 0.010*"radia" + 0.009*"ezb" + 0.008*"einen" + 0.008*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.269): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.444): 0.013*"news" + 0.007*"police" + 0.006*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.285): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.013597, rho=0.099365
bound: at document #0
-13.874 per-word bound, 15016.3 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 98, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.030379906, 0.032720923, 0.035603374, 0.034318857, 0.030028893, 1.2850971, 0.18228799, 0.032758832, 0.06012093, 0.22663341, 0.01541982, 0.06993502, 0.11985267, 0.02774228, 0.018695418, 0.024462916, 0.06529901, 0.21677005, 0.4393043, 0.031503998, 0.2697996, 0.11807575, 0.01686166, 0.059028275, 0.2081344, 0.028136745, 0.045815665, 0.17044212, 0.02824599, 0.05695679]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"adds" + 0.008*"rate" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.270): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.439): 0.013*"news" + 0.007*"police" + 0.006*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.285): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.023954, rho=0.099365
PROGRESS: pass 99, at document #2000/4566
performing inference on a chunk of 2000 documents
1994/2000 documents converged within 50 iterations
optimized alpha [0.03028183, 0.03268388, 0.035475865, 0.034242015, 0.029973973, 1.2706064, 0.18255697, 0.03268831, 0.059823286, 0.2251843, 0.015413227, 0.06950288, 0.1189828, 0.027753375, 0.018659461, 0.024428086, 0.06493522, 0.21561629, 0.44013098, 0.031457562, 0.26781386, 0.11704901, 0.016834503, 0.058701236, 0.20857441, 0.02808863, 0.045647915, 0.1692036, 0.028218813, 0.0566612]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.006*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.024*"jyj" + 0.012*"tvxq" + 0.010*"ezb" + 0.009*"einen" + 0.008*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.005*"bogot" + 0.005*"tiers"
topic #20 (0.268): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.009*"iphone" + 0.008*"facebook" + 0.008*"media"
topic #18 (0.440): 0.013*"news" + 0.007*"police" + 0.006*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.271): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.009*"dont" + 0.008*"love" + 0.008*"time" + 0.007*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.019508, rho=0.098878
PROGRESS: pass 99, at document #4000/4566
performing inference on a chunk of 2000 documents
1997/2000 documents converged within 50 iterations
optimized alpha [0.030376801, 0.032722402, 0.03558053, 0.034311563, 0.030055257, 1.2859782, 0.18289459, 0.032749273, 0.060109157, 0.22625232, 0.015417111, 0.06976956, 0.11962593, 0.02775656, 0.018684989, 0.024442771, 0.06519423, 0.21736543, 0.44445878, 0.03151556, 0.26967245, 0.11791009, 0.0168382, 0.058905154, 0.20975697, 0.028146211, 0.04574592, 0.17006855, 0.028237518, 0.056900088]
updating topics
merging changes from 2000 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.008*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.022*"jyj" + 0.012*"tvxq" + 0.010*"radia" + 0.010*"ezb" + 0.008*"einen" + 0.008*"pasa" + 0.006*"jaejoongs" + 0.006*"arun" + 0.005*"bogot" + 0.005*"composed"
topic #20 (0.270): 0.020*"google" + 0.013*"nasa" + 0.011*"social" + 0.011*"ipad" + 0.010*"twitter" + 0.009*"web" + 0.009*"app" + 0.009*"iphone" + 0.009*"facebook" + 0.008*"media"
topic #18 (0.444): 0.013*"news" + 0.007*"police" + 0.006*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"south"
topic #5 (1.286): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.013508, rho=0.098878
bound: at document #0
-13.874 per-word bound, 15015.2 perplexity estimate based on a held-out corpus of 566 documents with 88662 words
PROGRESS: pass 99, at document #4566/4566
performing inference on a chunk of 566 documents
566/566 documents converged within 50 iterations
optimized alpha [0.030401846, 0.03275104, 0.035617087, 0.034341928, 0.030060835, 1.2861859, 0.18239278, 0.032785732, 0.060165677, 0.22681712, 0.0154162245, 0.06998323, 0.11993296, 0.027769886, 0.018698469, 0.02447668, 0.06533865, 0.21685578, 0.43992746, 0.031521644, 0.2700682, 0.118160576, 0.016861796, 0.0590597, 0.20827487, 0.028155223, 0.045834295, 0.17051907, 0.028265456, 0.056998152]
updating topics
merging changes from 566 documents into a model of 4566 documents
topic #10 (0.015): 0.016*"fewer" + 0.014*"economy" + 0.014*"jobs" + 0.012*"expected" + 0.012*"november" + 0.008*"rate" + 0.007*"adds" + 0.007*"att" + 0.005*"alert" + 0.005*"aristotle"
topic #22 (0.017): 0.026*"jyj" + 0.013*"tvxq" + 0.011*"ezb" + 0.009*"einen" + 0.009*"radia" + 0.008*"pasa" + 0.007*"jaejoongs" + 0.006*"composed" + 0.006*"bogot" + 0.006*"tiers"
topic #20 (0.270): 0.020*"google" + 0.014*"nasa" + 0.011*"social" + 0.010*"ipad" + 0.010*"twitter" + 0.009*"app" + 0.009*"web" + 0.008*"iphone" + 0.008*"facebook" + 0.008*"android"
topic #18 (0.440): 0.013*"news" + 0.007*"police" + 0.006*"wikileaks" + 0.006*"iran" + 0.005*"bbc" + 0.005*"korea" + 0.005*"state" + 0.004*"man" + 0.004*"north" + 0.004*"cont"
topic #5 (1.286): 0.014*"day" + 0.010*"today" + 0.009*"good" + 0.008*"dont" + 0.008*"love" + 0.008*"time" + 0.008*"people" + 0.006*"aids" + 0.005*"life" + 0.005*"great"
topic diff=0.023898, rho=0.098878
starting a new internal lifecycle event log for LdaModel
LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=64523, num_topics=30, decay=0.5, chunksize=2000> in 419.46s', 'datetime': '2024-01-11T17:07:52.585304', 'gensim': '4.3.2', 'python': '3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}
starting a new internal lifecycle event log for LdaState
LdaState lifecycle event {'fname_or_handle': '../output/19/LDA.RecurrentGCN/tml/gensim_30topics.model.state', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-01-11T17:07:52.588357', 'gensim': '4.3.2', 'python': '3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'}
{'uri': '../output/19/LDA.RecurrentGCN/tml/gensim_30topics.model.state', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
saved ../output/19/LDA.RecurrentGCN/tml/gensim_30topics.model.state
{'uri': '../output/19/LDA.RecurrentGCN/tml/gensim_30topics.model.id2word', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
LdaModel lifecycle event {'fname_or_handle': '../output/19/LDA.RecurrentGCN/tml/gensim_30topics.model', 'separately': "['expElogbeta', 'sstats']", 'sep_limit': 10485760, 'ignore': ['id2word', 'state', 'dispatcher'], 'datetime': '2024-01-11T17:07:52.645618', 'gensim': '4.3.2', 'python': '3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'}
storing np array 'expElogbeta' to ../output/19/LDA.RecurrentGCN/tml/gensim_30topics.model.expElogbeta.npy
not storing attribute id2word
not storing attribute state
not storing attribute dispatcher
{'uri': '../output/19/LDA.RecurrentGCN/tml/gensim_30topics.model', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
saved ../output/19/LDA.RecurrentGCN/tml/gensim_30topics.model
Dictionary lifecycle event {'fname_or_handle': '../output/19/LDA.RecurrentGCN/tml/gensim_30topics_TopicModelingDictionary.mm', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-01-11T17:07:52.728731', 'gensim': '4.3.2', 'python': '3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'}
{'uri': '../output/19/LDA.RecurrentGCN/tml/gensim_30topics_TopicModelingDictionary.mm', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}
saved ../output/19/LDA.RecurrentGCN/tml/gensim_30topics_TopicModelingDictionary.mm
dictionary.shape: 64523
3. Temporal Graph Creation ...
##################################################
Loading users' graph stream ...
Loading users' graph stream failed! Generating the stream ...
UserSimilarity: Number of users per day: [1522, 1522, 1522]
UserSimilarity: Graphs are written in "graphs" directory
4. Temporal Graph Embedding ...
##################################################
Loading embeddings ...
Loading embeddings failed! Training ...
5. Community Prediction ...
##################################################
Loading user clusters ...
Loading user clusters failed! Generating user clusters ...
6. Application: News Recommendation ...
##################################################
Loading news articles ...
Loading news articles' topics ...
Loading news articles' topics failed! Inferring news articles' topics ...
Loading news article recommendations ...
Loading news article recommendations failed! Recommending news articles to future communities ...
Evaluating recommended news articles ...




