'pattern' package not found; tag filters are not available for English
CACHEDIR=C:\Users\sorou\.matplotlib
Using fontManager instance from C:\Users\sorou\.matplotlib\fontlist-v300.json
Loaded backend module://backend_interagg version unknown.
Main: UserSimilarities ...
DataReader: Connection created
DataReader: 63744 rows returned
DataReader: Connection closed
DataPreperation: userModeling=True, timeModeling=True, preProcessing=False, TagME=False
DataPreperation: 100000 sampled from the end of dataset (sorted by creationTime)
DataPreperation: Length of the dataset after applying groupby: 10788 

UserSimilarity: Processed docs shape: (10788,)
UserSimilarity: Topic modeling ...
TopicModeling: num_topics=50,  filterExtremes=True, library=gensim
adding document #0 to Dictionary(0 unique tokens: [])
adding document #10000 to Dictionary(48161 unique tokens: ['Beethoven', "Beethoven's 5th", 'Swan Lake', 'holiday', 'party']...)
built Dictionary(49968 unique tokens: ['Beethoven', "Beethoven's 5th", 'Swan Lake', 'holiday', 'party']...) from 10788 documents (total 234804 corpus positions)
discarding 0 tokens: []...
keeping 49968 tokens which were in no less than 1 and no more than 2157 (=20.0%) documents
rebuilding dictionary, shrinking gaps
resulting dictionary: Dictionary(49968 unique tokens: ['Beethoven', "Beethoven's 5th", 'Swan Lake', 'holiday', 'party']...)
using symmetric alpha at 0.02
using symmetric eta at 0.02
using serial LDA version on this node
running online (multi-pass) LDA training, 50 topics, 5 passes over the supplied corpus of 10788 documents, updating model once every 2000 documents, evaluating perplexity every 10788 documents, iterating 50x with a convergence threshold of 0.001000
PROGRESS: pass 0, at document #2000/10788
performing inference on a chunk of 2000 documents
1787/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #36 (0.020): 0.015*"UOL" + 0.006*"Christmas" + 0.005*"Obama" + 0.005*"bill" + 0.005*"blah" + 0.004*"House" + 0.003*"SP" + 0.003*"Yahoo" + 0.003*"Delicious" + 0.003*"Democrats"
topic #37 (0.020): 0.005*"WikiLeaks" + 0.005*"House" + 0.005*"Pakistan" + 0.004*"Facebook" + 0.004*"you" + 0.004*"USA" + 0.004*"bill" + 0.003*"US" + 0.003*"Twitter" + 0.003*"Google"
topic #14 (0.020): 0.006*"tax" + 0.005*"now" + 0.004*"Christmas" + 0.004*"RHOBH" + 0.004*"via" + 0.004*"tcot" + 0.004*"Democrats" + 0.004*"people" + 0.004*"you" + 0.003*"newstart"
topic #44 (0.020): 0.006*"Senate" + 0.006*"bill" + 0.004*"will" + 0.004*"vote" + 0.004*"Christmas" + 0.004*"Twitter" + 0.004*"Yahoo" + 0.004*"CNN" + 0.004*"DADT" + 0.003*"Obama"
topic #17 (0.020): 0.014*"Follow Friday" + 0.010*"cuba" + 0.009*"GY" + 0.007*"Facebook" + 0.004*"un" + 0.003*"US" + 0.003*"Wikileaks" + 0.003*"Government" + 0.003*"Yahoo" + 0.003*"Larry King"
topic diff=43.699528, rho=1.000000
PROGRESS: pass 0, at document #4000/10788
performing inference on a chunk of 2000 documents
1937/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #10 (0.020): 0.006*"story" + 0.006*"we" + 0.005*"will" + 0.005*"experience" + 0.005*"am" + 0.005*"cars" + 0.004*"DHS" + 0.004*"pray" + 0.004*"Ugh" + 0.004*"hahaha"
topic #22 (0.020): 0.008*"executed" + 0.008*"drug" + 0.006*"inmate" + 0.006*"will" + 0.006*"ozouni" + 0.006*"Okla" + 0.006*"death row" + 0.005*"Boxer" + 0.005*"Morgan Freeman" + 0.005*"alleged"
topic #37 (0.020): 0.007*"WikiLeaks" + 0.007*"you" + 0.006*"USA" + 0.005*"Bond" + 0.005*"Mixed" + 0.004*"oil" + 0.004*"the word" + 0.004*"House" + 0.004*"bill" + 0.004*"church"
topic #4 (0.020): 0.012*"Obama" + 0.005*"Jobs" + 0.005*"para" + 0.005*"Clinton" + 0.004*"House" + 0.004*"Pelosi" + 0.004*"tax" + 0.004*"vacation" + 0.003*"Sec" + 0.003*"vote"
topic #2 (0.020): 0.008*"Opinion" + 0.006*"Delicious" + 0.006*"Tweet" + 0.006*"Walmart" + 0.006*"see" + 0.005*"Christmas" + 0.005*"DJ" + 0.004*"family" + 0.004*"security" + 0.004*"California"
topic diff=3.485500, rho=0.707107
PROGRESS: pass 0, at document #6000/10788
performing inference on a chunk of 2000 documents
1973/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #36 (0.020): 0.021*"request" + 0.008*"Opinion" + 0.007*"UOL" + 0.007*"Roberto Mancini" + 0.007*"FDA" + 0.007*"paper" + 0.006*"football" + 0.006*"Manchester City" + 0.006*"Chelsea" + 0.006*"SP"
topic #23 (0.020): 0.012*"will" + 0.011*"Wikileaks" + 0.007*"India" + 0.007*"US" + 0.006*"lol" + 0.006*"wikileaks" + 0.006*"Morgan Freeman" + 0.005*"Rahul Gandhi" + 0.005*"Thank you" + 0.005*"threat"
topic #49 (0.020): 0.011*"Knicks" + 0.009*"money" + 0.006*"SEC" + 0.005*"tax cuts" + 0.005*"Senator" + 0.005*"wikileaks" + 0.005*"art" + 0.005*"nation" + 0.005*"billion" + 0.004*"Republicans"
topic #19 (0.020): 0.009*"Avastin" + 0.007*"Cancer" + 0.007*"Green" + 0.006*"Breast" + 0.006*"Barcelona" + 0.006*"photography" + 0.006*"iPhone" + 0.006*"Facebook" + 0.005*"Apple" + 0.005*"YouTube"
topic #11 (0.020): 0.020*"God" + 0.008*"musicians" + 0.008*"fuck" + 0.007*"who" + 0.007*"Twitter" + 0.007*"love" + 0.007*"who's" + 0.006*"friends" + 0.005*"word" + 0.005*"news"
topic diff=3.310508, rho=0.577350
PROGRESS: pass 0, at document #8000/10788
performing inference on a chunk of 2000 documents
1977/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #41 (0.020): 0.009*"unemployed" + 0.007*"Colombia" + 0.006*"big" + 0.006*"Europe" + 0.006*"Internet" + 0.006*"NASA" + 0.006*"Love" + 0.005*"energy" + 0.005*"campaign" + 0.005*"WSJ.com"
topic #12 (0.020): 0.017*"tcot" + 0.008*"Women" + 0.008*"teaparty" + 0.007*"Web" + 0.006*"face" + 0.006*"secrets" + 0.005*"gop" + 0.005*"Twitter" + 0.005*"sgp" + 0.005*"success"
topic #13 (0.020): 0.051*"Venezuela" + 0.016*"eu" + 0.009*"WB" + 0.008*"War" + 0.006*"AFP" + 0.006*"model" + 0.005*"women" + 0.005*"working" + 0.005*"Victim" + 0.005*"Glenn Beck"
topic #18 (0.020): 0.009*"NBA" + 0.008*"pandora" + 0.008*"brand" + 0.006*"bet" + 0.006*"amazing" + 0.005*"if" + 0.005*"actor" + 0.005*"close" + 0.005*"Photos" + 0.005*"Remix"
topic #39 (0.020): 0.006*"Women" + 0.005*"mine" + 0.004*"today" + 0.004*"sleep" + 0.004*"hurt" + 0.004*"Freedom" + 0.004*"Christmas" + 0.004*"US" + 0.004*"bit" + 0.004*"via"
topic diff=4.242385, rho=0.500000
PROGRESS: pass 0, at document #10000/10788
performing inference on a chunk of 2000 documents
1988/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #15 (0.020): 0.009*"book" + 0.008*"Hahaha" + 0.006*"Tonight" + 0.006*"hippies" + 0.006*"dans" + 0.005*"you" + 0.005*"CET" + 0.005*"policy" + 0.005*"Gaza" + 0.005*"who"
topic #16 (0.020): 0.014*"album" + 0.009*"soul" + 0.008*"aren" + 0.008*"evil" + 0.007*"Jesus" + 0.007*"history" + 0.006*"feel" + 0.006*"life" + 0.005*"time" + 0.005*"Psa"
topic #33 (0.020): 0.036*"Fundraising" + 0.020*"but not" + 0.015*"Lol" + 0.008*"today" + 0.008*"am" + 0.008*"Biblical" + 0.008*"Presbyterian" + 0.007*"Philly" + 0.007*"good" + 0.007*"Music"
topic #14 (0.020): 0.033*"now" + 0.012*"OMG" + 0.007*"you" + 0.007*"DVD" + 0.007*"real" + 0.007*"Canada" + 0.007*"tax" + 0.007*"jobs" + 0.007*"Christmas" + 0.007*"debt"
topic #49 (0.020): 0.014*"money" + 0.010*"Asia" + 0.008*"pour" + 0.008*"wikileaks" + 0.006*"infrastructure" + 0.006*"BBC" + 0.006*"living" + 0.006*"billion" + 0.006*"Knicks" + 0.005*"Kenya"
topic diff=4.377418, rho=0.447214
bound: at document #0
-18.252 per-word bound, 312284.0 perplexity estimate based on a held-out corpus of 788 documents with 20452 words
PROGRESS: pass 0, at document #10788/10788
performing inference on a chunk of 788 documents
787/788 documents converged within 50 iterations
updating topics
merging changes from 788 documents into a model of 10788 documents
topic #39 (0.020): 0.007*"Love" + 0.006*"hurt" + 0.006*"Women" + 0.006*"bit" + 0.006*"mine" + 0.005*"via" + 0.005*"yo" + 0.005*"Freedom" + 0.005*"singapore" + 0.005*"thx"
topic #48 (0.020): 0.025*"Paris" + 0.013*"Live" + 0.009*"Un" + 0.009*"Perú" + 0.008*"al" + 0.008*"Dealer Auction" + 0.008*"del" + 0.007*"London" + 0.007*"snow" + 0.007*"más"
topic #42 (0.020): 0.076*"video" + 0.025*"YouTube" + 0.024*"Home" + 0.011*"FOX" + 0.006*"tweet" + 0.006*"retweet" + 0.005*"ser" + 0.005*"Bar" + 0.005*"Michael Jackson" + 0.005*"Thx"
topic #12 (0.020): 0.013*"tcot" + 0.013*"gop" + 0.012*"Nexus S" + 0.009*"Web" + 0.008*"face" + 0.008*"rich" + 0.007*"más" + 0.007*"sgp" + 0.006*"Oracle" + 0.006*"Google"
topic #7 (0.020): 0.061*"Peace" + 0.027*"VE" + 0.025*"GOP" + 0.019*"Earmark" + 0.019*"youcut" + 0.007*"Happy Holidays" + 0.006*"pledge" + 0.006*"local" + 0.006*"Barinas" + 0.005*"Sudan"
topic diff=2.498631, rho=0.408248
PROGRESS: pass 1, at document #2000/10788
performing inference on a chunk of 2000 documents
1999/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #42 (0.020): 0.069*"video" + 0.026*"YouTube" + 0.018*"Home" + 0.009*"FOX" + 0.005*"ser" + 0.005*"tweet" + 0.005*"retweet" + 0.005*"Michael Jackson" + 0.005*"Thx" + 0.004*"SB Line"
topic #36 (0.020): 0.010*"cancer" + 0.007*"UOL" + 0.007*"blah" + 0.006*"Stargate Universe" + 0.006*"EUA" + 0.006*"Bush Tax Cuts" + 0.006*"SP" + 0.005*"para" + 0.005*"request" + 0.005*"FDA"
topic #45 (0.020): 0.017*"Wall Street" + 0.011*"Art" + 0.008*"China" + 0.008*"White House" + 0.007*"Congress" + 0.007*"U.S" + 0.007*"Grim Sleeper" + 0.006*"CBS" + 0.006*"Republicans" + 0.006*"Money"
topic #34 (0.020): 0.019*"como" + 0.014*"un" + 0.012*"poco" + 0.012*"eso" + 0.010*"para" + 0.008*"ya" + 0.008*"se" + 0.008*"ay" + 0.008*"jajaja" + 0.007*"hoy"
topic #22 (0.020): 0.019*"Morgan Freeman" + 0.018*"drug" + 0.014*"death" + 0.013*"will" + 0.013*"inmate" + 0.012*"executed" + 0.012*"death row" + 0.012*"CNN" + 0.011*"hoax" + 0.011*"Rumor"
topic diff=1.538025, rho=0.367756
PROGRESS: pass 1, at document #4000/10788
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #8 (0.020): 0.068*"lol" + 0.017*"ur" + 0.014*"LOL" + 0.012*"tweet" + 0.010*"think" + 0.009*"haha" + 0.009*"you" + 0.008*"time" + 0.008*"people" + 0.007*"me"
topic #6 (0.020): 0.020*"CNN" + 0.015*"NFL" + 0.010*"Tony Romo" + 0.010*"EST" + 0.009*"Chargers" + 0.007*"check" + 0.007*"QB" + 0.007*"click to" + 0.007*"flight" + 0.007*"CNN News"
topic #18 (0.020): 0.007*"brand" + 0.007*"NBA" + 0.006*"Chicago" + 0.005*"bet" + 0.005*"Filibuster" + 0.005*"in us" + 0.005*"Time" + 0.005*"bed" + 0.005*"month" + 0.005*"prototypes"
topic #25 (0.020): 0.011*"Chavez" + 0.011*"time" + 0.009*"Reuters" + 0.009*"website" + 0.009*"business" + 0.008*"kids" + 0.008*"who" + 0.008*"mind" + 0.007*"children" + 0.006*"school"
topic #24 (0.020): 0.042*"Sudan" + 0.010*"Check it" + 0.010*"social media" + 0.009*"Check it out" + 0.009*"ma" + 0.007*"Japan" + 0.006*"Blake Edwards" + 0.006*"Spain" + 0.005*"Reuters" + 0.005*"nasa"
topic diff=1.430063, rho=0.367756
PROGRESS: pass 1, at document #6000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #17 (0.020): 0.044*"Follow Friday" + 0.015*"FF" + 0.012*"ppl" + 0.007*"Berlin" + 0.007*"xmas" + 0.006*"WTF" + 0.006*"HIV" + 0.005*"game" + 0.005*"AIDS" + 0.005*"Buy"
topic #6 (0.020): 0.018*"CNN" + 0.015*"NFL" + 0.010*"Tony Romo" + 0.009*"check" + 0.008*"QB" + 0.008*"Chargers" + 0.007*"flight" + 0.007*"EST" + 0.006*"sou" + 0.006*"AM"
topic #47 (0.020): 0.036*"Larry King" + 0.017*"CNN" + 0.015*"show" + 0.014*"tonight" + 0.012*"you" + 0.010*"will" + 0.010*"Video" + 0.010*"Christmas" + 0.009*"Larry King Live" + 0.008*"today"
topic #25 (0.020): 0.010*"website" + 0.009*"children" + 0.009*"time" + 0.009*"Chavez" + 0.009*"business" + 0.008*"who" + 0.008*"Sinatra" + 0.007*"poor" + 0.007*"mind" + 0.007*"kids"
topic #7 (0.020): 0.027*"GOP" + 0.021*"Peace" + 0.017*"Earmark" + 0.017*"youcut" + 0.013*"pledge" + 0.011*"VE" + 0.008*"Happy Holidays" + 0.007*"local" + 0.006*"green" + 0.006*"wrong again"
topic diff=1.265369, rho=0.367756
PROGRESS: pass 1, at document #8000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #21 (0.020): 0.027*"tcot" + 0.017*"Obama" + 0.013*"Bush" + 0.010*"Afterlife" + 0.009*"Reid" + 0.008*"WORLD" + 0.007*"via        s" + 0.007*"GOP" + 0.007*"Senator" + 0.007*"will"
topic #44 (0.020): 0.021*"bill" + 0.021*"Senate" + 0.017*"House" + 0.016*"Obama" + 0.015*"vote" + 0.013*"GOP" + 0.013*"DADT" + 0.009*"will" + 0.007*"Reid" + 0.007*"Democrats"
topic #46 (0.020): 0.019*"to win" + 0.010*"Hey" + 0.009*"Indonesia" + 0.008*"person" + 0.007*"via" + 0.006*"GM" + 0.006*"understand" + 0.006*"Signs Off" + 0.005*"rock" + 0.005*"Chef"
topic #48 (0.020): 0.011*"Paris" + 0.009*"snow" + 0.007*"Live" + 0.006*"Un" + 0.006*"del" + 0.006*"season" + 0.005*"al" + 0.005*"son" + 0.005*"Economist" + 0.005*"airport"
topic #41 (0.020): 0.009*"unemployed" + 0.008*"Colombia" + 0.008*"big" + 0.007*"NASA" + 0.007*"fly" + 0.007*"Europe" + 0.006*"Love" + 0.006*"OK" + 0.006*"energy" + 0.006*"U.N"
topic diff=1.125394, rho=0.367756
PROGRESS: pass 1, at document #10000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #30 (0.020): 0.029*"Facebook" + 0.025*"AP" + 0.011*"photography" + 0.011*"Brasil" + 0.009*"Free" + 0.008*"pode" + 0.007*"Julian Assange" + 0.007*"Online" + 0.006*"via" + 0.006*"WikiLeaks"
topic #49 (0.020): 0.018*"money" + 0.011*"Asia" + 0.008*"wikileaks" + 0.007*"Knicks" + 0.007*"infrastructure" + 0.006*"living" + 0.006*"billion" + 0.006*"Gadget" + 0.006*"Kenya" + 0.006*"BBC"
topic #36 (0.020): 0.008*"para" + 0.008*"request" + 0.007*"cancer" + 0.007*"EUA" + 0.007*"Chelsea" + 0.006*"EPL" + 0.006*"football" + 0.006*"livestream" + 0.006*"Taliban" + 0.005*"Arsenal"
topic #47 (0.020): 0.037*"Larry King" + 0.019*"CNN" + 0.014*"show" + 0.014*"tonight" + 0.012*"you" + 0.011*"Larry King Live" + 0.011*"Christmas" + 0.009*"Video" + 0.009*"will" + 0.009*"today"
topic #27 (0.020): 0.016*"NYT" + 0.009*"Muslim" + 0.009*"Haiti" + 0.008*"Tax Cut" + 0.008*"Congress" + 0.006*"Billion" + 0.006*"North Korea" + 0.005*"VIDEO" + 0.005*"California" + 0.005*"Legislation"
topic diff=0.984538, rho=0.367756
bound: at document #0
-11.344 per-word bound, 2599.7 perplexity estimate based on a held-out corpus of 788 documents with 20452 words
PROGRESS: pass 1, at document #10788/10788
performing inference on a chunk of 788 documents
788/788 documents converged within 50 iterations
updating topics
merging changes from 788 documents into a model of 10788 documents
topic #12 (0.020): 0.015*"gop" + 0.013*"Nexus S" + 0.012*"tcot" + 0.011*"Web" + 0.009*"rich" + 0.008*"face" + 0.007*"sgp" + 0.007*"Oracle" + 0.006*"Google" + 0.006*"Engadget"
topic #2 (0.020): 0.024*"Jane Austen" + 0.017*"Israel" + 0.012*"Delicious" + 0.011*"see" + 0.009*"Toronto" + 0.009*"Christmas" + 0.008*"bookmarks" + 0.007*"appeals" + 0.007*"check it" + 0.007*"come"
topic #0 (0.020): 0.022*"London" + 0.021*"Freedom of Speech" + 0.021*"Manhattan" + 0.011*"travel" + 0.008*"students" + 0.007*"Redskins" + 0.006*"talking" + 0.006*"Funding" + 0.006*"planning" + 0.005*"N.J"
topic #18 (0.020): 0.008*"Music Channel" + 0.007*"bed" + 0.007*"Chicago" + 0.006*"NBA" + 0.006*"screenwriting" + 0.005*"digg" + 0.005*"month" + 0.005*"filmmaking" + 0.005*"Busta Rhymes" + 0.005*"brand"
topic #39 (0.020): 0.008*"Love" + 0.008*"bit" + 0.007*"hurt" + 0.007*"Women" + 0.007*"mine" + 0.006*"Haiti" + 0.006*"via" + 0.006*"thx" + 0.006*"Freedom" + 0.005*"yo"
topic diff=0.715077, rho=0.367756
PROGRESS: pass 2, at document #2000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #33 (0.020): 0.018*"Fundraising" + 0.018*"but not" + 0.012*"Lol" + 0.010*"Moscow" + 0.008*"am" + 0.008*"Oh" + 0.007*"good" + 0.007*"tweets" + 0.006*"today" + 0.006*"movie"
topic #10 (0.020): 0.012*"radio" + 0.010*"la libertad" + 0.007*"Boston" + 0.007*"Sos" + 0.007*"we" + 0.007*"Hell" + 0.006*"Hoy" + 0.006*"cute" + 0.006*"skin" + 0.005*"us"
topic #43 (0.020): 0.037*"un" + 0.024*"es" + 0.019*"para" + 0.014*"si" + 0.012*"en" + 0.009*"Gracias" + 0.009*"la" + 0.008*"mi" + 0.007*"este" + 0.007*"sin"
topic #40 (0.020): 0.032*"NYC" + 0.010*"New York" + 0.009*"people" + 0.009*"Sale" + 0.007*"RADIO" + 0.007*"People" + 0.007*"Star Trek" + 0.007*"Friends" + 0.006*"life" + 0.006*"Nice"
topic #14 (0.020): 0.030*"now" + 0.011*"people" + 0.011*"Canada" + 0.010*"you" + 0.010*"Mark Zuckerberg" + 0.008*"OMG" + 0.007*"Christmas" + 0.007*"twitter" + 0.007*"real" + 0.007*"LTTP"
topic diff=0.517666, rho=0.345156
PROGRESS: pass 2, at document #4000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #29 (0.020): 0.007*"VAW" + 0.007*"frm" + 0.006*"christmas" + 0.006*"fb" + 0.005*"Domestic Violence" + 0.005*"yesterday" + 0.004*"np" + 0.004*"mayor" + 0.004*"legislation" + 0.004*"White"
topic #4 (0.020): 0.019*"Cuba" + 0.018*"para" + 0.009*"Clinton" + 0.008*"laws" + 0.008*"Sec" + 0.008*"dos" + 0.007*"Iran" + 0.006*"La" + 0.006*"action" + 0.005*"ao"
topic #33 (0.020): 0.014*"but not" + 0.012*"Fundraising" + 0.012*"Lol" + 0.008*"bitch" + 0.008*"am" + 0.008*"good" + 0.007*"Moscow" + 0.007*"Oh" + 0.006*"movie" + 0.006*"tweets"
topic #5 (0.020): 0.058*"Como" + 0.012*"Social Media" + 0.010*"a man" + 0.007*"Here" + 0.007*"WSPA" + 0.006*"Apps" + 0.006*"Facebook Features" + 0.006*"always" + 0.005*"win" + 0.005*"today"
topic #23 (0.020): 0.021*"Wikileaks" + 0.016*"wikileaks" + 0.016*"US" + 0.015*"India" + 0.013*"will" + 0.010*"Assange" + 0.010*"Breaking News" + 0.007*"Pakistan" + 0.006*"US embassy cables" + 0.005*"Thank you"
topic diff=0.423569, rho=0.345156
PROGRESS: pass 2, at document #6000/10788
performing inference on a chunk of 2000 documents
1999/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #26 (0.020): 0.013*"blog" + 0.011*"wordpress.com" + 0.011*"UR" + 0.009*"coffee" + 0.009*"LGBT" + 0.007*"Thailand" + 0.007*"Tibet" + 0.006*"economist" + 0.006*"post" + 0.006*"Dalai Lama"
topic #33 (0.020): 0.013*"Lol" + 0.013*"good" + 0.011*"but not" + 0.009*"am" + 0.009*"bitch" + 0.008*"Fundraising" + 0.007*"ad" + 0.006*"tweets" + 0.006*"today" + 0.006*"Oh"
topic #15 (0.020): 0.010*"hindi" + 0.007*"idk" + 0.007*"yan" + 0.007*"book" + 0.007*"Tonight" + 0.006*"dans" + 0.005*"Carine Roitfeld" + 0.005*"sya" + 0.005*"Hahaha" + 0.004*"sila"
topic #17 (0.020): 0.045*"Follow Friday" + 0.017*"FF" + 0.012*"ppl" + 0.008*"game" + 0.008*"Berlin" + 0.007*"xmas" + 0.006*"Buy" + 0.005*"WTF" + 0.005*"HIV" + 0.005*"maty"
topic #4 (0.020): 0.016*"dos" + 0.015*"Cuba" + 0.014*"para" + 0.012*"wordpress" + 0.009*"LP" + 0.008*"Sec" + 0.008*"Clinton" + 0.008*"último" + 0.007*"Iran" + 0.007*"ler"
topic diff=0.324283, rho=0.345156
PROGRESS: pass 2, at document #8000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #30 (0.020): 0.032*"Facebook" + 0.031*"AP" + 0.016*"photography" + 0.010*"Brasil" + 0.009*"foto" + 0.008*"Free" + 0.008*"Online" + 0.008*"live" + 0.007*"Julian Assange" + 0.006*"via"
topic #29 (0.020): 0.007*"VAW" + 0.007*"Marisela" + 0.006*"np" + 0.006*"christmas" + 0.005*"frm" + 0.005*"Escobedo" + 0.005*"yg" + 0.005*"Domestic Violence" + 0.005*"vaw" + 0.005*"fb"
topic #8 (0.020): 0.069*"lol" + 0.017*"ur" + 0.013*"LOL" + 0.011*"you" + 0.011*"lmao" + 0.010*"haha" + 0.010*"time" + 0.010*"think" + 0.008*"me" + 0.008*"people"
topic #37 (0.020): 0.021*"Iran" + 0.015*"Mc" + 0.011*"USA" + 0.007*"the word" + 0.007*"tomorrow" + 0.007*"If" + 0.006*"France" + 0.006*"this Christmas" + 0.006*"can" + 0.006*"Cann"
topic #31 (0.020): 0.014*"food" + 0.013*"holiday" + 0.013*"via" + 0.009*"TV" + 0.007*"gift" + 0.006*"FYI" + 0.005*"Christmas tree" + 0.005*"Mobile" + 0.005*"app" + 0.005*"t.co"
topic diff=0.287633, rho=0.345156
PROGRESS: pass 2, at document #10000/10788
performing inference on a chunk of 2000 documents
1999/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #1 (0.020): 0.052*"Family" + 0.049*"Concert" + 0.046*"Presbyterian" + 0.046*"Biblical" + 0.006*"first" + 0.006*"Football" + 0.006*"Teacher" + 0.006*"Happy Birthday" + 0.006*"Deal" + 0.005*"tax Free"
topic #2 (0.020): 0.015*"Israel" + 0.011*"see" + 0.011*"Delicious" + 0.008*"Christmas" + 0.008*"Brooklyn" + 0.008*"Jane Austen" + 0.008*"Yahoo" + 0.007*"Toronto" + 0.007*"back" + 0.006*"come"
topic #30 (0.020): 0.036*"Facebook" + 0.027*"AP" + 0.013*"photography" + 0.011*"Brasil" + 0.008*"Free" + 0.008*"pode" + 0.008*"Online" + 0.007*"via" + 0.007*"live" + 0.006*"Julian Assange"
topic #28 (0.020): 0.018*"pf" + 0.013*"pour" + 0.013*"yoy" + 0.012*"Christmas .. Love" + 0.009*"Carpe Diem" + 0.009*"VENEZUELA" + 0.008*"times" + 0.007*"LULA" + 0.007*"Xmas" + 0.006*"Life"
topic #20 (0.020): 0.117*"Twitter" + 0.067*"tweet" + 0.013*"Facebook" + 0.009*"women" + 0.007*"Tea Party" + 0.006*"Palestine" + 0.006*"iPad" + 0.006*"President" + 0.005*"Social Media" + 0.005*"Google"
topic diff=0.279484, rho=0.345156
bound: at document #0
-10.501 per-word bound, 1448.8 perplexity estimate based on a held-out corpus of 788 documents with 20452 words
PROGRESS: pass 2, at document #10788/10788
performing inference on a chunk of 788 documents
788/788 documents converged within 50 iterations
updating topics
merging changes from 788 documents into a model of 10788 documents
topic #45 (0.020): 0.028*"Wall Street" + 0.015*"Art" + 0.010*"U.S" + 0.009*"CBS" + 0.008*"Grim Sleeper" + 0.008*"Money" + 0.008*"Sarah Palin" + 0.008*"health" + 0.008*"China" + 0.007*"suspect"
topic #21 (0.020): 0.044*"WORLD" + 0.042*"via        s" + 0.039*"LE" + 0.024*"tcot" + 0.010*"Obama" + 0.008*"Earmarks" + 0.007*"Bush" + 0.006*"your songs" + 0.006*"Tea Party" + 0.006*"research"
topic #7 (0.020): 0.062*"Peace" + 0.031*"GOP" + 0.028*"VE" + 0.020*"Earmark" + 0.019*"youcut" + 0.016*"pledge" + 0.010*"p2" + 0.008*"Clooney" + 0.008*"Happy Holidays" + 0.007*"Barinas"
topic #4 (0.020): 0.025*"Cuba" + 0.018*"para" + 0.013*"laws" + 0.011*"dos" + 0.010*"Sec" + 0.009*"La" + 0.009*"Iran" + 0.008*"ao" + 0.008*"Clinton" + 0.007*"LP"
topic #35 (0.020): 0.012*"BBC News" + 0.012*"London" + 0.011*"Blog" + 0.010*"Japan" + 0.008*"Post" + 0.007*"British" + 0.006*"dead" + 0.006*"Artist" + 0.006*"Mexico drug war" + 0.006*"North Korea"
topic diff=0.183543, rho=0.345156
PROGRESS: pass 3, at document #2000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #34 (0.020): 0.021*"como" + 0.015*"un" + 0.014*"para" + 0.012*"poco" + 0.012*"eso" + 0.009*"lentamente" + 0.009*"poco a poco" + 0.009*"pasion" + 0.009*"ya" + 0.008*"al"
topic #42 (0.020): 0.089*"video" + 0.035*"YouTube" + 0.018*"Home" + 0.008*"FOX" + 0.006*"my family" + 0.005*"ser" + 0.005*"Michael Jackson" + 0.005*"retweet" + 0.004*"Hawks" + 0.004*"HD"
topic #33 (0.020): 0.018*"but not" + 0.018*"Fundraising" + 0.012*"Lol" + 0.010*"Moscow" + 0.009*"good" + 0.007*"Oh" + 0.007*"am" + 0.007*"tweets" + 0.006*"Can" + 0.006*"will"
topic #49 (0.020): 0.016*"money" + 0.009*"WGCL" + 0.009*"Asia" + 0.009*"Knicks" + 0.007*"wikileaks" + 0.006*"rise" + 0.006*"Kenya" + 0.006*"Human Rights" + 0.006*"billion" + 0.005*"Gadget"
topic #27 (0.020): 0.019*"NYT" + 0.010*"North Korea" + 0.009*"Congress" + 0.008*"Muslim" + 0.008*"Jobless" + 0.007*"Haiti" + 0.007*"Tax Cut" + 0.007*"Billion" + 0.007*"Benefits" + 0.006*"NEWS"
topic diff=0.160842, rho=0.326268
PROGRESS: pass 3, at document #4000/10788
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #35 (0.020): 0.012*"Blog" + 0.010*"London" + 0.010*"BBC News" + 0.009*"Japan" + 0.009*"Post" + 0.007*"British" + 0.007*"dead" + 0.006*"Russia" + 0.006*"charges" + 0.006*"US"
topic #11 (0.020): 0.026*"friends" + 0.024*"God" + 0.011*"fuck" + 0.009*"who's" + 0.009*"na" + 0.008*"We" + 0.008*"who" + 0.007*"do" + 0.007*"news" + 0.007*"em"
topic #12 (0.020): 0.014*"tcot" + 0.013*"gop" + 0.010*"Nexus S" + 0.009*"rich" + 0.009*"Web" + 0.008*"sgp" + 0.008*"face" + 0.008*"Oracle" + 0.006*"teaparty" + 0.005*"ORCL"
topic #29 (0.020): 0.007*"VAW" + 0.007*"christmas" + 0.007*"frm" + 0.006*"fb" + 0.005*"Domestic Violence" + 0.004*"yesterday" + 0.004*"np" + 0.004*"GOD" + 0.004*"mayor" + 0.004*"legislation"
topic #42 (0.020): 0.094*"video" + 0.069*"YouTube" + 0.012*"Home" + 0.005*"my family" + 0.005*"FOX" + 0.005*"Queen" + 0.004*"retweet" + 0.004*"Hawks" + 0.004*"Bar" + 0.003*"HD"
topic diff=0.147430, rho=0.326268
PROGRESS: pass 3, at document #6000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #46 (0.020): 0.025*"to win" + 0.009*"Indonesia" + 0.007*"GM" + 0.006*"water" + 0.006*"NYC" + 0.005*"understand" + 0.005*"person" + 0.005*"Christmas" + 0.005*"fire" + 0.005*"Chef"
topic #41 (0.020): 0.010*"U.N" + 0.008*"Colombia" + 0.008*"Fox" + 0.008*"OK" + 0.007*"rights" + 0.007*"big" + 0.007*"fly" + 0.007*"NASA" + 0.006*"Tweets" + 0.006*"Christmas"
topic #35 (0.020): 0.010*"Blog" + 0.009*"Japan" + 0.008*"London" + 0.008*"Post" + 0.007*"BBC News" + 0.007*"charges" + 0.006*"dead" + 0.006*"British" + 0.006*"Nigeria" + 0.005*"US"
topic #9 (0.020): 0.043*"WikiLeaks" + 0.030*"Julian Assange" + 0.020*"US" + 0.016*"Pakistan" + 0.014*"Assange" + 0.011*"Wiki Leaks" + 0.010*"India" + 0.010*"Wikileaks" + 0.010*"accused" + 0.010*"torture"
topic #19 (0.020): 0.026*"iPhone" + 0.024*"Apple" + 0.020*"Android" + 0.018*"Google" + 0.018*"iPad" + 0.016*"Yahoo" + 0.012*"Word Lens" + 0.011*"app" + 0.007*"Avastin" + 0.007*"Video"
topic diff=0.111666, rho=0.326268
PROGRESS: pass 3, at document #8000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #0 (0.020): 0.017*"London" + 0.012*"Freedom of Speech" + 0.011*"travel" + 0.008*"BAND" + 0.008*"students" + 0.006*"Funding" + 0.006*"Manhattan" + 0.005*"Seattle" + 0.005*"San Francisco" + 0.005*"lp"
topic #28 (0.020): 0.032*"pf" + 0.015*"Carpe Diem" + 0.014*"pour" + 0.013*"LULA" + 0.012*"VENEZUELA" + 0.011*"fez" + 0.011*"prometeu" + 0.008*"times" + 0.007*"Xmas" + 0.006*"CARPE DIEM"
topic #26 (0.020): 0.014*"blog" + 0.013*"LGBT" + 0.011*"Share" + 0.010*"coffee" + 0.009*"UR" + 0.008*"post" + 0.007*"Thailand" + 0.007*"wordpress.com" + 0.007*"Tibet" + 0.006*"economist"
topic #40 (0.020): 0.024*"NYC" + 0.010*"Roll Call" + 0.010*"people" + 0.008*"RADIO" + 0.008*"People" + 0.008*"Friends" + 0.007*"Nice" + 0.007*"New York" + 0.007*"Spurs" + 0.006*"smile"
topic #45 (0.020): 0.013*"Wall Street" + 0.011*"U.S" + 0.009*"China" + 0.008*"Grim Sleeper" + 0.007*"health" + 0.006*"CBS" + 0.006*"Money" + 0.006*"Sarah Palin" + 0.006*"California" + 0.006*"White House"
topic diff=0.115830, rho=0.326268
PROGRESS: pass 3, at document #10000/10788
performing inference on a chunk of 2000 documents
1998/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #33 (0.020): 0.034*"Fundraising" + 0.023*"but not" + 0.017*"Lol" + 0.013*"good" + 0.008*"Music" + 0.008*"bitch" + 0.007*"Philly" + 0.007*"ad" + 0.006*"tweeting" + 0.006*"tweets"
topic #2 (0.020): 0.016*"Israel" + 0.011*"Delicious" + 0.010*"see" + 0.008*"Jane Austen" + 0.008*"Brooklyn" + 0.008*"Christmas" + 0.007*"Yahoo" + 0.007*"Toronto" + 0.006*"back" + 0.006*"come"
topic #14 (0.020): 0.048*"now" + 0.011*"OMG" + 0.011*"DVD" + 0.011*"Canada" + 0.009*"people" + 0.009*"twitter" + 0.009*"you" + 0.008*"LTTP" + 0.008*"go" + 0.008*"Mark Zuckerberg"
topic #49 (0.020): 0.019*"money" + 0.011*"Asia" + 0.008*"Knicks" + 0.008*"wikileaks" + 0.007*"infrastructure" + 0.007*"living" + 0.006*"Kenya" + 0.006*"billion" + 0.006*"Gadget" + 0.006*"assange"
topic #34 (0.020): 0.020*"poco" + 0.019*"lentamente" + 0.018*"pasion" + 0.018*"poco a poco" + 0.018*"como" + 0.014*"un" + 0.012*"para" + 0.009*"jajaja" + 0.009*"eso" + 0.009*"las"
topic diff=0.148289, rho=0.326268
bound: at document #0
-10.388 per-word bound, 1339.8 perplexity estimate based on a held-out corpus of 788 documents with 20452 words
PROGRESS: pass 3, at document #10788/10788
performing inference on a chunk of 788 documents
788/788 documents converged within 50 iterations
updating topics
merging changes from 788 documents into a model of 10788 documents
topic #49 (0.020): 0.019*"money" + 0.014*"WGCL" + 0.013*"Asia" + 0.013*"Knicks" + 0.008*"Kenya" + 0.007*"Human Rights" + 0.007*"wikileaks" + 0.006*"rise" + 0.006*"living" + 0.006*"Gadget"
topic #37 (0.020): 0.022*"Iran" + 0.013*"Mc" + 0.013*"If" + 0.012*"USA" + 0.009*"tomorrow" + 0.007*"reason" + 0.007*"the word" + 0.006*"Marine" + 0.006*"gold" + 0.006*"wall"
topic #0 (0.020): 0.035*"London" + 0.020*"Manhattan" + 0.020*"Freedom of Speech" + 0.011*"travel" + 0.008*"NYC" + 0.007*"students" + 0.007*"Redskins" + 0.006*"Funding" + 0.006*"Seattle" + 0.006*"N.J"
topic #35 (0.020): 0.012*"BBC News" + 0.011*"Blog" + 0.011*"Japan" + 0.010*"London" + 0.008*"Post" + 0.007*"dead" + 0.006*"British" + 0.006*"North Korea" + 0.006*"Mexico drug war" + 0.006*"Artist"
topic #24 (0.020): 0.072*"Sudan" + 0.028*"Clooney" + 0.017*"Reuters" + 0.014*"ma" + 0.010*"Check it" + 0.009*"Check it out" + 0.008*"nasa" + 0.007*"Yahoo! News" + 0.007*"Japan" + 0.007*"social media"
topic diff=0.097171, rho=0.326268
PROGRESS: pass 4, at document #2000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #5 (0.020): 0.073*"Como" + 0.013*"Social Media" + 0.011*"a man" + 0.009*"WSPA" + 0.007*"Facebook Features" + 0.006*"Here" + 0.005*"Apps" + 0.005*"Fan" + 0.005*"via" + 0.005*"always"
topic #35 (0.020): 0.011*"Blog" + 0.011*"BBC News" + 0.011*"Japan" + 0.010*"London" + 0.007*"Post" + 0.007*"dead" + 0.007*"US" + 0.006*"British" + 0.006*"man" + 0.006*"China"
topic #17 (0.020): 0.043*"Follow Friday" + 0.021*"FF" + 0.017*"Berlin" + 0.011*"game" + 0.009*"cuba" + 0.009*"ppl" + 0.009*"GY" + 0.008*"avatar" + 0.008*"TRES HOMBRES" + 0.007*"hotmail"
topic #36 (0.020): 0.011*"cancer" + 0.008*"para" + 0.007*"Taliban" + 0.007*"request" + 0.007*"UOL" + 0.007*"blah" + 0.007*"Bush Tax Cuts" + 0.006*"Stargate Universe" + 0.006*"football" + 0.006*"SP"
topic #12 (0.020): 0.012*"gop" + 0.012*"Nexus S" + 0.011*"tcot" + 0.010*"Web" + 0.009*"Oracle" + 0.008*"rich" + 0.008*"sgp" + 0.007*"face" + 0.006*"teaparty" + 0.005*"NASA"
topic diff=0.118570, rho=0.310176
PROGRESS: pass 4, at document #4000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #34 (0.020): 0.019*"como" + 0.013*"para" + 0.013*"un" + 0.011*"poco" + 0.010*"eso" + 0.009*"ya" + 0.008*"lentamente" + 0.008*"internet" + 0.008*"poco a poco" + 0.008*"pasion"
topic #49 (0.020): 0.018*"money" + 0.012*"Knicks" + 0.008*"Asia" + 0.008*"wikileaks" + 0.007*"WGCL" + 0.007*"infrastructure" + 0.006*"Kenya" + 0.006*"Human Rights" + 0.006*"billion" + 0.006*"assange"
topic #46 (0.020): 0.025*"to win" + 0.010*"Indonesia" + 0.007*"Chef" + 0.006*"Hey" + 0.005*"water" + 0.005*"fire" + 0.005*"Christmas" + 0.005*"understand" + 0.005*"GM" + 0.005*"person"
topic #24 (0.020): 0.049*"Sudan" + 0.017*"Clooney" + 0.014*"Reuters" + 0.012*"Check it" + 0.011*"Check it out" + 0.009*"ma" + 0.008*"Japan" + 0.007*"social media" + 0.007*"Spain" + 0.006*"Yahoo! News"
topic #14 (0.020): 0.033*"now" + 0.014*"LTTP" + 0.011*"people" + 0.011*"you" + 0.010*"Mark Zuckerberg" + 0.009*"Canada" + 0.008*"OMG" + 0.008*"DVD" + 0.008*"twitter" + 0.008*"Christmas"
topic diff=0.111850, rho=0.310176
PROGRESS: pass 4, at document #6000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #6 (0.020): 0.015*"NFL" + 0.011*"CNN" + 0.010*"Tony Romo" + 0.008*"snow" + 0.008*"check" + 0.008*"QB" + 0.008*"Chargers" + 0.007*"EST" + 0.007*"flight" + 0.006*"Snow"
topic #21 (0.020): 0.026*"tcot" + 0.018*"WORLD" + 0.016*"via        s" + 0.015*"LE" + 0.010*"Obama" + 0.008*"Bush" + 0.006*"Senator" + 0.006*"ocra" + 0.005*"will" + 0.005*"Earmarks"
topic #37 (0.020): 0.015*"Iran" + 0.009*"If" + 0.009*"the word" + 0.008*"USA" + 0.008*"Mc" + 0.007*"reason" + 0.007*"France" + 0.006*"tomorrow" + 0.006*"bad" + 0.006*"church"
topic #10 (0.020): 0.010*"we" + 0.009*"radio" + 0.007*"Boston" + 0.007*"experience" + 0.006*"Hoy" + 0.006*"us" + 0.006*"Happy" + 0.006*"air" + 0.005*"Santa" + 0.005*"la libertad"
topic #16 (0.020): 0.016*"Jesus" + 0.014*"God" + 0.012*"album" + 0.010*"aren" + 0.008*"history" + 0.007*"evil" + 0.007*"pray" + 0.007*"work" + 0.006*"willing" + 0.006*"life"
topic diff=0.082710, rho=0.310176
PROGRESS: pass 4, at document #8000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #36 (0.020): 0.014*"request" + 0.013*"livestream" + 0.012*"chat room" + 0.009*"football" + 0.009*"cancer" + 0.007*"para" + 0.007*"SP" + 0.007*"Chelsea" + 0.006*"Taliban" + 0.006*"UOL"
topic #30 (0.020): 0.044*"Facebook" + 0.032*"AP" + 0.016*"photography" + 0.010*"foto" + 0.010*"Brasil" + 0.009*"Mashable" + 0.009*"Online" + 0.008*"live" + 0.008*"Free" + 0.007*"via"
topic #22 (0.020): 0.024*"Morgan Freeman" + 0.018*"death" + 0.016*"will" + 0.015*"CNN" + 0.014*"drug" + 0.013*"Las Vegas" + 0.012*"hoax" + 0.011*"false" + 0.011*"Rumor" + 0.010*"inmate"
topic #19 (0.020): 0.026*"iPhone" + 0.026*"Apple" + 0.020*"Google" + 0.019*"Android" + 0.018*"iPad" + 0.017*"Yahoo" + 0.011*"Word Lens" + 0.010*"app" + 0.009*"via" + 0.007*"Study"
topic #5 (0.020): 0.031*"Como" + 0.012*"Social Media" + 0.012*"a man" + 0.007*"Here" + 0.006*"Facebook Features" + 0.006*"win" + 0.006*"Fan" + 0.006*"Apps" + 0.005*"net" + 0.005*"via"
topic diff=0.085670, rho=0.310176
PROGRESS: pass 4, at document #10000/10788
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 10788 documents
topic #47 (0.020): 0.035*"Larry King" + 0.022*"CNN" + 0.016*"tonight" + 0.015*"show" + 0.015*"today" + 0.014*"Christmas" + 0.011*"you" + 0.011*"will" + 0.010*"Larry King Live" + 0.009*"out"
topic #38 (0.020): 0.021*"UK" + 0.013*"Check" + 0.009*"weather" + 0.006*"banks" + 0.005*"envoy" + 0.005*"Ireland" + 0.005*"won" + 0.005*"Countdown" + 0.005*"Holidays" + 0.005*"N. Korea"
topic #12 (0.020): 0.010*"Nexus S" + 0.010*"rich" + 0.009*"tcot" + 0.008*"gop" + 0.007*"face" + 0.007*"amtrak" + 0.007*"Web" + 0.007*"teaparty" + 0.006*"policy" + 0.006*"success"
topic #17 (0.020): 0.043*"Follow Friday" + 0.022*"FF" + 0.012*"ppl" + 0.010*"game" + 0.009*"GY" + 0.009*"xmas" + 0.008*"Berlin" + 0.007*"cuba" + 0.007*"WTF" + 0.007*"avatar"
topic #10 (0.020): 0.011*"Boston" + 0.010*"radio" + 0.010*"Hoy" + 0.009*"we" + 0.007*"goals" + 0.007*"Happy" + 0.006*"End" + 0.006*"air" + 0.006*"Santa" + 0.006*"us"
topic diff=0.121224, rho=0.310176
bound: at document #0
-10.336 per-word bound, 1292.6 perplexity estimate based on a held-out corpus of 788 documents with 20452 words
PROGRESS: pass 4, at document #10788/10788
performing inference on a chunk of 788 documents
788/788 documents converged within 50 iterations
updating topics
merging changes from 788 documents into a model of 10788 documents
topic #36 (0.020): 0.011*"cancer" + 0.009*"para" + 0.008*"Bush Tax Cuts" + 0.008*"request" + 0.007*"Lyrics" + 0.007*"EUA" + 0.007*"blah" + 0.007*"football" + 0.007*"Taliban" + 0.006*"Stargate Universe"
topic #20 (0.020): 0.113*"Twitter" + 0.062*"tweet" + 0.016*"Facebook" + 0.009*"women" + 0.009*"staff" + 0.007*"Palestine" + 0.007*"Tea Party" + 0.006*"Google" + 0.005*"end" + 0.005*"sales"
topic #1 (0.020): 0.040*"Family" + 0.036*"Concert" + 0.035*"Presbyterian" + 0.035*"Biblical" + 0.008*"liberal" + 0.007*"Teacher" + 0.006*"Right" + 0.006*"Bogotá" + 0.005*"Happy Birthday" + 0.005*"charity"
topic #14 (0.020): 0.040*"now" + 0.015*"people" + 0.012*"Mark Zuckerberg" + 0.011*"you" + 0.011*"DVD" + 0.011*"LTTP" + 0.009*"Canada" + 0.009*"go" + 0.009*"believe" + 0.009*"next"
topic #15 (0.020): 0.030*"hindi" + 0.015*"yan" + 0.015*"sya" + 0.014*"idk" + 0.014*"sila" + 0.008*"salita" + 0.007*"lng" + 0.007*"Ferengi" + 0.007*"Rule Of Acquisition" + 0.006*"book"
topic diff=0.080836, rho=0.310176
saving LdaState object under ../output/55/tml/gensim_50topics.model.state, separately None
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'wb', 'uri': '../output/55/tml/gensim_50topics.model.state'}
saved ../output/55/tml/gensim_50topics.model.state
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'wb', 'uri': '../output/55/tml/gensim_50topics.model.id2word'}
saving LdaModel object under ../output/55/tml/gensim_50topics.model, separately ['expElogbeta', 'sstats']
storing np array 'expElogbeta' to ../output/55/tml/gensim_50topics.model.expElogbeta.npy
not storing attribute dispatcher
not storing attribute state
not storing attribute id2word
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'wb', 'uri': '../output/55/tml/gensim_50topics.model'}
saved ../output/55/tml/gensim_50topics.model
topic #0 (0.020): 0.038*"London" + 0.019*"Manhattan" + 0.019*"Freedom of Speech" + 0.011*"travel" + 0.010*"NYC" + 0.007*"students" + 0.007*"Redskins" + 0.007*"Paris Berlin" + 0.007*"Seattle" + 0.006*"Funding"
topic #1 (0.020): 0.040*"Family" + 0.036*"Concert" + 0.035*"Presbyterian" + 0.035*"Biblical" + 0.008*"liberal" + 0.007*"Teacher" + 0.006*"Right" + 0.006*"Bogotá" + 0.005*"Happy Birthday" + 0.005*"charity"
topic #2 (0.020): 0.023*"Jane Austen" + 0.022*"Israel" + 0.012*"Delicious" + 0.009*"Toronto" + 0.009*"bookmarks" + 0.008*"see" + 0.007*"check it" + 0.007*"come" + 0.007*"Christmas" + 0.007*"appeals"
topic #3 (0.020): 0.019*"Dubai" + 0.014*"auspol" + 0.014*"Blake Edwards" + 0.012*"media" + 0.011*"director" + 0.009*"AFP" + 0.009*"Australia" + 0.009*"Pink Panther" + 0.009*"free" + 0.009*"Australian"
topic #4 (0.020): 0.025*"Cuba" + 0.013*"laws" + 0.013*"para" + 0.011*"dos" + 0.010*"Sec" + 0.009*"La" + 0.009*"ao" + 0.009*"Iran" + 0.007*"LP" + 0.007*"Clinton"
topic #5 (0.020): 0.091*"Como" + 0.013*"a man" + 0.012*"Social Media" + 0.011*"WSPA" + 0.007*"Here" + 0.006*"Facebook Features" + 0.006*"Fim" + 0.006*"Roupa Nova" + 0.006*"ENCANTO" + 0.006*"Lagoa"
topic #6 (0.020): 0.017*"NFL" + 0.012*"Chargers" + 0.009*"snow" + 0.009*"play" + 0.008*"start" + 0.007*"Tony Romo" + 0.007*"Christmas" + 0.007*"Snow" + 0.007*"CNN" + 0.006*"49ers"
topic #7 (0.020): 0.061*"Peace" + 0.031*"GOP" + 0.028*"VE" + 0.020*"Earmark" + 0.020*"youcut" + 0.017*"pledge" + 0.008*"Happy Holidays" + 0.008*"p2" + 0.008*"Barinas" + 0.007*"Vla"
topic #8 (0.020): 0.059*"lol" + 0.022*"ur" + 0.014*"LOL" + 0.013*"you" + 0.011*"haha" + 0.010*"time" + 0.010*"me" + 0.010*"think" + 0.009*"people" + 0.009*"am"
topic #9 (0.020): 0.042*"WikiLeaks" + 0.032*"Julian Assange" + 0.026*"US" + 0.018*"Pakistan" + 0.016*"Assange" + 0.014*"India" + 0.014*"Wikileaks" + 0.013*"cablegate" + 0.011*"Wiki Leaks" + 0.011*"accused"
topic #10 (0.020): 0.015*"radio" + 0.011*"la libertad" + 0.009*"we" + 0.009*"Boston" + 0.009*"Sos" + 0.008*"Hoy" + 0.007*"goals" + 0.007*"skin" + 0.006*"Hell" + 0.006*"End"
topic #11 (0.020): 0.042*"friends" + 0.032*"God" + 0.014*"na" + 0.010*"who's" + 0.010*"We" + 0.008*"fuck" + 0.008*"do" + 0.008*"who" + 0.008*"news" + 0.008*"da"
topic #12 (0.020): 0.015*"gop" + 0.013*"Nexus S" + 0.011*"rich" + 0.010*"Web" + 0.010*"tcot" + 0.009*"face" + 0.007*"Oracle" + 0.007*"sgp" + 0.006*"policy" + 0.006*"teaparty"
topic #13 (0.020): 0.075*"Venezuela" + 0.012*"eu" + 0.012*"Save Internet" + 0.012*"Internet Freedom" + 0.011*"libertad" + 0.010*"Amy Winehouse" + 0.008*"women" + 0.008*"tao" + 0.007*"vc" + 0.006*"New York"
topic #14 (0.020): 0.040*"now" + 0.015*"people" + 0.012*"Mark Zuckerberg" + 0.011*"you" + 0.011*"DVD" + 0.011*"LTTP" + 0.009*"Canada" + 0.009*"go" + 0.009*"believe" + 0.009*"next"
topic #15 (0.020): 0.030*"hindi" + 0.015*"yan" + 0.015*"sya" + 0.014*"idk" + 0.014*"sila" + 0.008*"salita" + 0.007*"lng" + 0.007*"Ferengi" + 0.007*"Rule Of Acquisition" + 0.006*"book"
topic #16 (0.020): 0.018*"God" + 0.018*"Jesus" + 0.013*"album" + 0.010*"history" + 0.010*"aren" + 0.008*"soul" + 0.008*"work" + 0.007*"who" + 0.007*"pray" + 0.007*"life"
topic #17 (0.020): 0.039*"Follow Friday" + 0.023*"FF" + 0.020*"Berlin" + 0.013*"game" + 0.009*"TRES HOMBRES" + 0.009*"ppl" + 0.009*"avatar" + 0.009*"hotmail" + 0.009*"hotmail.com" + 0.008*"SAILING"
topic #18 (0.020): 0.009*"Music Channel" + 0.008*"Chicago" + 0.007*"bed" + 0.007*"NBA" + 0.006*"month" + 0.005*"screenwriting" + 0.005*"Video" + 0.005*"digg" + 0.005*"ppl" + 0.005*"week"
topic #19 (0.020): 0.029*"iPhone" + 0.024*"Apple" + 0.020*"Android" + 0.018*"Google" + 0.017*"app" + 0.017*"iPad" + 0.015*"Yahoo" + 0.013*"Word Lens" + 0.010*"via" + 0.010*"Video"
topic #20 (0.020): 0.113*"Twitter" + 0.062*"tweet" + 0.016*"Facebook" + 0.009*"women" + 0.009*"staff" + 0.007*"Palestine" + 0.007*"Tea Party" + 0.006*"Google" + 0.005*"end" + 0.005*"sales"
topic #21 (0.020): 0.044*"WORLD" + 0.041*"via        s" + 0.039*"LE" + 0.024*"tcot" + 0.008*"Earmarks" + 0.008*"Bush" + 0.008*"Obama" + 0.007*"Tea Party" + 0.006*"your songs" + 0.006*"Afterlife"
topic #22 (0.020): 0.022*"Morgan Freeman" + 0.018*"will" + 0.017*"death" + 0.016*"drug" + 0.013*"CNN" + 0.012*"inmate" + 0.012*"hoax" + 0.011*"false" + 0.011*"Rumor" + 0.011*"executed"
topic #23 (0.020): 0.019*"Breaking News" + 0.018*"India" + 0.016*"US" + 0.016*"Wikileaks" + 0.014*"will" + 0.013*"wikileaks" + 0.009*"Assange" + 0.008*"single" + 0.008*"ve" + 0.008*"Pakistan"
topic #24 (0.020): 0.072*"Sudan" + 0.029*"Clooney" + 0.019*"Reuters" + 0.014*"ma" + 0.010*"Check it" + 0.009*"Check it out" + 0.008*"nasa" + 0.007*"Japan" + 0.007*"Yahoo! News" + 0.006*"social media"
topic #25 (0.020): 0.020*"time" + 0.014*"business" + 0.012*"website" + 0.010*"woman" + 0.009*"children" + 0.009*"Yao Ming" + 0.009*"mind" + 0.008*"who" + 0.008*"poor" + 0.007*"sex"
topic #26 (0.020): 0.025*"UR" + 0.018*"blog" + 0.014*"LGBT" + 0.013*"post" + 0.010*"economist" + 0.009*"coffee" + 0.009*"Share" + 0.008*"Thailand" + 0.007*"crisis" + 0.007*"derecho"
topic #27 (0.020): 0.020*"NYT" + 0.009*"North Korea" + 0.009*"Muslim" + 0.007*"Jobless" + 0.007*"Congress" + 0.007*"Lie To Me" + 0.007*"Tax Cut" + 0.007*"Billion" + 0.007*"Haiti" + 0.007*"Seoul"
topic #28 (0.020): 0.017*"VENEZUELA" + 0.016*"pf" + 0.013*"nós" + 0.012*"pour" + 0.010*"Voltaire" + 0.009*"yoy" + 0.009*"Xmas" + 0.008*"Christmas .. Love" + 0.008*"Carpe Diem" + 0.007*"positive"
topic #29 (0.020): 0.011*"fb" + 0.008*"christmas" + 0.008*"np" + 0.007*"UNICEF" + 0.007*"VAW" + 0.007*"frm" + 0.006*"Domestic Violence" + 0.006*"mayor" + 0.006*"choice" + 0.005*"RT           : One"
topic #30 (0.020): 0.046*"Facebook" + 0.030*"AP" + 0.017*"Brasil" + 0.010*"photography" + 0.008*"prime minister" + 0.008*"via" + 0.008*"Mashable" + 0.007*"crime in Australia" + 0.007*"Online" + 0.007*"live"
topic #31 (0.020): 0.021*"JESUS" + 0.019*"food" + 0.015*"TV" + 0.015*"NEPHILIM" + 0.015*"google.com" + 0.014*"holiday" + 0.012*"t.co" + 0.010*"via" + 0.007*"app" + 0.007*"info"
topic #32 (0.020): 0.010*"peace" + 0.007*"thoughts" + 0.007*"Read" + 0.006*"Afghanistan" + 0.006*"team" + 0.005*"uploaded" + 0.005*"parents" + 0.005*"AK" + 0.005*"Changmin" + 0.005*"Me"
topic #33 (0.020): 0.023*"Fundraising" + 0.022*"but not" + 0.014*"Lol" + 0.012*"Moscow" + 0.012*"good" + 0.008*"fun" + 0.008*"will" + 0.007*"Can" + 0.007*"Oh" + 0.007*"up"
topic #34 (0.020): 0.018*"como" + 0.015*"poco" + 0.014*"para" + 0.013*"un" + 0.013*"lentamente" + 0.012*"pasion" + 0.012*"poco a poco" + 0.011*"al" + 0.010*"ay" + 0.010*"las"
topic #35 (0.020): 0.012*"BBC News" + 0.012*"Blog" + 0.011*"Japan" + 0.010*"London" + 0.008*"Post" + 0.007*"dead" + 0.006*"British" + 0.006*"North Korea" + 0.006*"Mexico drug war" + 0.006*"Artist"
topic #36 (0.020): 0.011*"cancer" + 0.009*"para" + 0.008*"Bush Tax Cuts" + 0.008*"request" + 0.007*"Lyrics" + 0.007*"EUA" + 0.007*"blah" + 0.007*"football" + 0.007*"Taliban" + 0.006*"Stargate Universe"
topic #37 (0.020): 0.023*"Iran" + 0.013*"Mc" + 0.013*"If" + 0.012*"USA" + 0.009*"tomorrow" + 0.007*"reason" + 0.007*"the word" + 0.006*"Marine" + 0.006*"gold" + 0.006*"wall"
topic #38 (0.020): 0.019*"UK" + 0.018*"Check" + 0.011*"envoy" + 0.009*"won" + 0.008*"sale" + 0.008*"weather" + 0.007*"via" + 0.006*"vodka" + 0.006*"Arrest" + 0.006*"Audio"
topic #39 (0.020): 0.011*"Haiti" + 0.008*"Love" + 0.008*"bit" + 0.008*"Women" + 0.007*"hurt" + 0.007*"mine" + 0.006*"jailed" + 0.006*"thx" + 0.006*"lunch" + 0.006*"Freedom"
topic #40 (0.020): 0.034*"NYC" + 0.010*"New York" + 0.010*"Sale" + 0.010*"people" + 0.009*"RADIO" + 0.009*"Friends" + 0.008*"Star Trek" + 0.008*"People" + 0.008*"Nice" + 0.007*"Proverb"
topic #41 (0.020): 0.016*"INN" + 0.014*"U.N" + 0.012*"mcot" + 0.011*"big" + 0.010*"Colombia" + 0.010*"rights" + 0.009*"11 Alive" + 0.008*"Christmas" + 0.007*"fly" + 0.007*"NASA"
topic #42 (0.020): 0.094*"video" + 0.035*"YouTube" + 0.024*"Home" + 0.010*"FOX" + 0.007*"my family" + 0.006*"retweet" + 0.005*"ser" + 0.005*"Bar" + 0.005*"recipe" + 0.004*"Austen's"
topic #43 (0.020): 0.041*"un" + 0.027*"para" + 0.023*"es" + 0.017*"Chavez" + 0.015*"la" + 0.014*"si" + 0.012*"en" + 0.010*"Gracias" + 0.008*"este" + 0.007*"sin"
topic #44 (0.020): 0.024*"bill" + 0.022*"Senate" + 0.019*"Obama" + 0.018*"House" + 0.017*"GOP" + 0.013*"tax" + 0.012*"vote" + 0.011*"Congress" + 0.011*"Republicans" + 0.010*"will"
topic #45 (0.020): 0.028*"Wall Street" + 0.015*"Art" + 0.012*"U.S" + 0.009*"health" + 0.009*"Grim Sleeper" + 0.008*"Money" + 0.008*"China" + 0.008*"CBS" + 0.008*"Sarah Palin" + 0.007*"EU"
topic #46 (0.020): 0.022*"to win" + 0.012*"Indonesia" + 0.008*"Chef" + 0.008*"Hey" + 0.006*"person" + 0.006*"understand" + 0.005*"Christmas" + 0.005*"Oscars" + 0.005*"Food Truck" + 0.005*"water"
topic #47 (0.020): 0.028*"Larry King" + 0.022*"CNN" + 0.016*"today" + 0.015*"tonight" + 0.014*"Christmas" + 0.014*"will" + 0.013*"you" + 0.013*"show" + 0.009*"Lol" + 0.009*"Larry King Live"
topic #48 (0.020): 0.024*"Paris" + 0.015*"Dealer Auction" + 0.014*"Live" + 0.010*"Un" + 0.010*"más" + 0.008*"Perú" + 0.008*"Sunroof" + 0.008*"del" + 0.007*"6cyl" + 0.007*"season"
topic #49 (0.020): 0.019*"money" + 0.014*"WGCL" + 0.013*"Knicks" + 0.013*"Asia" + 0.008*"Kenya" + 0.008*"Human Rights" + 0.007*"wikileaks" + 0.006*"rise" + 0.006*"living" + 0.006*"assange"
TopicModeling: GENSIM Topic: 0 
Words: 0.038*"London" + 0.019*"Manhattan" + 0.019*"Freedom of Speech" + 0.011*"travel" + 0.010*"NYC" + 0.007*"students" + 0.007*"Redskins" + 0.007*"Paris Berlin" + 0.007*"Seattle" + 0.006*"Funding"
TopicModeling: GENSIM Topic: 1 
Words: 0.040*"Family" + 0.036*"Concert" + 0.035*"Presbyterian" + 0.035*"Biblical" + 0.008*"liberal" + 0.007*"Teacher" + 0.006*"Right" + 0.006*"Bogotá" + 0.005*"Happy Birthday" + 0.005*"charity"
TopicModeling: GENSIM Topic: 2 
Words: 0.023*"Jane Austen" + 0.022*"Israel" + 0.012*"Delicious" + 0.009*"Toronto" + 0.009*"bookmarks" + 0.008*"see" + 0.007*"check it" + 0.007*"come" + 0.007*"Christmas" + 0.007*"appeals"
TopicModeling: GENSIM Topic: 3 
Words: 0.019*"Dubai" + 0.014*"auspol" + 0.014*"Blake Edwards" + 0.012*"media" + 0.011*"director" + 0.009*"AFP" + 0.009*"Australia" + 0.009*"Pink Panther" + 0.009*"free" + 0.009*"Australian"
TopicModeling: GENSIM Topic: 4 
Words: 0.025*"Cuba" + 0.013*"laws" + 0.013*"para" + 0.011*"dos" + 0.010*"Sec" + 0.009*"La" + 0.009*"ao" + 0.009*"Iran" + 0.007*"LP" + 0.007*"Clinton"
TopicModeling: GENSIM Topic: 5 
Words: 0.091*"Como" + 0.013*"a man" + 0.012*"Social Media" + 0.011*"WSPA" + 0.007*"Here" + 0.006*"Facebook Features" + 0.006*"Fim" + 0.006*"Roupa Nova" + 0.006*"ENCANTO" + 0.006*"Lagoa"
TopicModeling: GENSIM Topic: 6 
Words: 0.017*"NFL" + 0.012*"Chargers" + 0.009*"snow" + 0.009*"play" + 0.008*"start" + 0.007*"Tony Romo" + 0.007*"Christmas" + 0.007*"Snow" + 0.007*"CNN" + 0.006*"49ers"
TopicModeling: GENSIM Topic: 7 
Words: 0.061*"Peace" + 0.031*"GOP" + 0.028*"VE" + 0.020*"Earmark" + 0.020*"youcut" + 0.017*"pledge" + 0.008*"Happy Holidays" + 0.008*"p2" + 0.008*"Barinas" + 0.007*"Vla"
TopicModeling: GENSIM Topic: 8 
Words: 0.059*"lol" + 0.022*"ur" + 0.014*"LOL" + 0.013*"you" + 0.011*"haha" + 0.010*"time" + 0.010*"me" + 0.010*"think" + 0.009*"people" + 0.009*"am"
TopicModeling: GENSIM Topic: 9 
Words: 0.042*"WikiLeaks" + 0.032*"Julian Assange" + 0.026*"US" + 0.018*"Pakistan" + 0.016*"Assange" + 0.014*"India" + 0.014*"Wikileaks" + 0.013*"cablegate" + 0.011*"Wiki Leaks" + 0.011*"accused"
TopicModeling: GENSIM Topic: 10 
Words: 0.015*"radio" + 0.011*"la libertad" + 0.009*"we" + 0.009*"Boston" + 0.009*"Sos" + 0.008*"Hoy" + 0.007*"goals" + 0.007*"skin" + 0.006*"Hell" + 0.006*"End"
TopicModeling: GENSIM Topic: 11 
Words: 0.042*"friends" + 0.032*"God" + 0.014*"na" + 0.010*"who's" + 0.010*"We" + 0.008*"fuck" + 0.008*"do" + 0.008*"who" + 0.008*"news" + 0.008*"da"
TopicModeling: GENSIM Topic: 12 
Words: 0.015*"gop" + 0.013*"Nexus S" + 0.011*"rich" + 0.010*"Web" + 0.010*"tcot" + 0.009*"face" + 0.007*"Oracle" + 0.007*"sgp" + 0.006*"policy" + 0.006*"teaparty"
TopicModeling: GENSIM Topic: 13 
Words: 0.075*"Venezuela" + 0.012*"eu" + 0.012*"Save Internet" + 0.012*"Internet Freedom" + 0.011*"libertad" + 0.010*"Amy Winehouse" + 0.008*"women" + 0.008*"tao" + 0.007*"vc" + 0.006*"New York"
TopicModeling: GENSIM Topic: 14 
Words: 0.040*"now" + 0.015*"people" + 0.012*"Mark Zuckerberg" + 0.011*"you" + 0.011*"DVD" + 0.011*"LTTP" + 0.009*"Canada" + 0.009*"go" + 0.009*"believe" + 0.009*"next"
TopicModeling: GENSIM Topic: 15 
Words: 0.030*"hindi" + 0.015*"yan" + 0.015*"sya" + 0.014*"idk" + 0.014*"sila" + 0.008*"salita" + 0.007*"lng" + 0.007*"Ferengi" + 0.007*"Rule Of Acquisition" + 0.006*"book"
TopicModeling: GENSIM Topic: 16 
Words: 0.018*"God" + 0.018*"Jesus" + 0.013*"album" + 0.010*"history" + 0.010*"aren" + 0.008*"soul" + 0.008*"work" + 0.007*"who" + 0.007*"pray" + 0.007*"life"
TopicModeling: GENSIM Topic: 17 
Words: 0.039*"Follow Friday" + 0.023*"FF" + 0.020*"Berlin" + 0.013*"game" + 0.009*"TRES HOMBRES" + 0.009*"ppl" + 0.009*"avatar" + 0.009*"hotmail" + 0.009*"hotmail.com" + 0.008*"SAILING"
TopicModeling: GENSIM Topic: 18 
Words: 0.009*"Music Channel" + 0.008*"Chicago" + 0.007*"bed" + 0.007*"NBA" + 0.006*"month" + 0.005*"screenwriting" + 0.005*"Video" + 0.005*"digg" + 0.005*"ppl" + 0.005*"week"
TopicModeling: GENSIM Topic: 19 
Words: 0.029*"iPhone" + 0.024*"Apple" + 0.020*"Android" + 0.018*"Google" + 0.017*"app" + 0.017*"iPad" + 0.015*"Yahoo" + 0.013*"Word Lens" + 0.010*"via" + 0.010*"Video"
TopicModeling: GENSIM Topic: 20 
Words: 0.113*"Twitter" + 0.062*"tweet" + 0.016*"Facebook" + 0.009*"women" + 0.009*"staff" + 0.007*"Palestine" + 0.007*"Tea Party" + 0.006*"Google" + 0.005*"end" + 0.005*"sales"
TopicModeling: GENSIM Topic: 21 
Words: 0.044*"WORLD" + 0.041*"via        s" + 0.039*"LE" + 0.024*"tcot" + 0.008*"Earmarks" + 0.008*"Bush" + 0.008*"Obama" + 0.007*"Tea Party" + 0.006*"your songs" + 0.006*"Afterlife"
TopicModeling: GENSIM Topic: 22 
Words: 0.022*"Morgan Freeman" + 0.018*"will" + 0.017*"death" + 0.016*"drug" + 0.013*"CNN" + 0.012*"inmate" + 0.012*"hoax" + 0.011*"false" + 0.011*"Rumor" + 0.011*"executed"
TopicModeling: GENSIM Topic: 23 
Words: 0.019*"Breaking News" + 0.018*"India" + 0.016*"US" + 0.016*"Wikileaks" + 0.014*"will" + 0.013*"wikileaks" + 0.009*"Assange" + 0.008*"single" + 0.008*"ve" + 0.008*"Pakistan"
TopicModeling: GENSIM Topic: 24 
Words: 0.072*"Sudan" + 0.029*"Clooney" + 0.019*"Reuters" + 0.014*"ma" + 0.010*"Check it" + 0.009*"Check it out" + 0.008*"nasa" + 0.007*"Japan" + 0.007*"Yahoo! News" + 0.006*"social media"
TopicModeling: GENSIM Topic: 25 
Words: 0.020*"time" + 0.014*"business" + 0.012*"website" + 0.010*"woman" + 0.009*"children" + 0.009*"Yao Ming" + 0.009*"mind" + 0.008*"who" + 0.008*"poor" + 0.007*"sex"
TopicModeling: GENSIM Topic: 26 
Words: 0.025*"UR" + 0.018*"blog" + 0.014*"LGBT" + 0.013*"post" + 0.010*"economist" + 0.009*"coffee" + 0.009*"Share" + 0.008*"Thailand" + 0.007*"crisis" + 0.007*"derecho"
TopicModeling: GENSIM Topic: 27 
Words: 0.020*"NYT" + 0.009*"North Korea" + 0.009*"Muslim" + 0.007*"Jobless" + 0.007*"Congress" + 0.007*"Lie To Me" + 0.007*"Tax Cut" + 0.007*"Billion" + 0.007*"Haiti" + 0.007*"Seoul"
TopicModeling: GENSIM Topic: 28 
Words: 0.017*"VENEZUELA" + 0.016*"pf" + 0.013*"nós" + 0.012*"pour" + 0.010*"Voltaire" + 0.009*"yoy" + 0.009*"Xmas" + 0.008*"Christmas .. Love" + 0.008*"Carpe Diem" + 0.007*"positive"
TopicModeling: GENSIM Topic: 29 
Words: 0.011*"fb" + 0.008*"christmas" + 0.008*"np" + 0.007*"UNICEF" + 0.007*"VAW" + 0.007*"frm" + 0.006*"Domestic Violence" + 0.006*"mayor" + 0.006*"choice" + 0.005*"RT           : One"
TopicModeling: GENSIM Topic: 30 
Words: 0.046*"Facebook" + 0.030*"AP" + 0.017*"Brasil" + 0.010*"photography" + 0.008*"prime minister" + 0.008*"via" + 0.008*"Mashable" + 0.007*"crime in Australia" + 0.007*"Online" + 0.007*"live"
TopicModeling: GENSIM Topic: 31 
Words: 0.021*"JESUS" + 0.019*"food" + 0.015*"TV" + 0.015*"NEPHILIM" + 0.015*"google.com" + 0.014*"holiday" + 0.012*"t.co" + 0.010*"via" + 0.007*"app" + 0.007*"info"
TopicModeling: GENSIM Topic: 32 
Words: 0.010*"peace" + 0.007*"thoughts" + 0.007*"Read" + 0.006*"Afghanistan" + 0.006*"team" + 0.005*"uploaded" + 0.005*"parents" + 0.005*"AK" + 0.005*"Changmin" + 0.005*"Me"
TopicModeling: GENSIM Topic: 33 
Words: 0.023*"Fundraising" + 0.022*"but not" + 0.014*"Lol" + 0.012*"Moscow" + 0.012*"good" + 0.008*"fun" + 0.008*"will" + 0.007*"Can" + 0.007*"Oh" + 0.007*"up"
TopicModeling: GENSIM Topic: 34 
Words: 0.018*"como" + 0.015*"poco" + 0.014*"para" + 0.013*"un" + 0.013*"lentamente" + 0.012*"pasion" + 0.012*"poco a poco" + 0.011*"al" + 0.010*"ay" + 0.010*"las"
TopicModeling: GENSIM Topic: 35 
Words: 0.012*"BBC News" + 0.012*"Blog" + 0.011*"Japan" + 0.010*"London" + 0.008*"Post" + 0.007*"dead" + 0.006*"British" + 0.006*"North Korea" + 0.006*"Mexico drug war" + 0.006*"Artist"
TopicModeling: GENSIM Topic: 36 
Words: 0.011*"cancer" + 0.009*"para" + 0.008*"Bush Tax Cuts" + 0.008*"request" + 0.007*"Lyrics" + 0.007*"EUA" + 0.007*"blah" + 0.007*"football" + 0.007*"Taliban" + 0.006*"Stargate Universe"
TopicModeling: GENSIM Topic: 37 
Words: 0.023*"Iran" + 0.013*"Mc" + 0.013*"If" + 0.012*"USA" + 0.009*"tomorrow" + 0.007*"reason" + 0.007*"the word" + 0.006*"Marine" + 0.006*"gold" + 0.006*"wall"
TopicModeling: GENSIM Topic: 38 
Words: 0.019*"UK" + 0.018*"Check" + 0.011*"envoy" + 0.009*"won" + 0.008*"sale" + 0.008*"weather" + 0.007*"via" + 0.006*"vodka" + 0.006*"Arrest" + 0.006*"Audio"
TopicModeling: GENSIM Topic: 39 
Words: 0.011*"Haiti" + 0.008*"Love" + 0.008*"bit" + 0.008*"Women" + 0.007*"hurt" + 0.007*"mine" + 0.006*"jailed" + 0.006*"thx" + 0.006*"lunch" + 0.006*"Freedom"
TopicModeling: GENSIM Topic: 40 
Words: 0.034*"NYC" + 0.010*"New York" + 0.010*"Sale" + 0.010*"people" + 0.009*"RADIO" + 0.009*"Friends" + 0.008*"Star Trek" + 0.008*"People" + 0.008*"Nice" + 0.007*"Proverb"
TopicModeling: GENSIM Topic: 41 
Words: 0.016*"INN" + 0.014*"U.N" + 0.012*"mcot" + 0.011*"big" + 0.010*"Colombia" + 0.010*"rights" + 0.009*"11 Alive" + 0.008*"Christmas" + 0.007*"fly" + 0.007*"NASA"
TopicModeling: GENSIM Topic: 42 
Words: 0.094*"video" + 0.035*"YouTube" + 0.024*"Home" + 0.010*"FOX" + 0.007*"my family" + 0.006*"retweet" + 0.005*"ser" + 0.005*"Bar" + 0.005*"recipe" + 0.004*"Austen's"
TopicModeling: GENSIM Topic: 43 
Words: 0.041*"un" + 0.027*"para" + 0.023*"es" + 0.017*"Chavez" + 0.015*"la" + 0.014*"si" + 0.012*"en" + 0.010*"Gracias" + 0.008*"este" + 0.007*"sin"
TopicModeling: GENSIM Topic: 44 
Words: 0.024*"bill" + 0.022*"Senate" + 0.019*"Obama" + 0.018*"House" + 0.017*"GOP" + 0.013*"tax" + 0.012*"vote" + 0.011*"Congress" + 0.011*"Republicans" + 0.010*"will"
TopicModeling: GENSIM Topic: 45 
Words: 0.028*"Wall Street" + 0.015*"Art" + 0.012*"U.S" + 0.009*"health" + 0.009*"Grim Sleeper" + 0.008*"Money" + 0.008*"China" + 0.008*"CBS" + 0.008*"Sarah Palin" + 0.007*"EU"
TopicModeling: GENSIM Topic: 46 
Words: 0.022*"to win" + 0.012*"Indonesia" + 0.008*"Chef" + 0.008*"Hey" + 0.006*"person" + 0.006*"understand" + 0.005*"Christmas" + 0.005*"Oscars" + 0.005*"Food Truck" + 0.005*"water"
TopicModeling: GENSIM Topic: 47 
Words: 0.028*"Larry King" + 0.022*"CNN" + 0.016*"today" + 0.015*"tonight" + 0.014*"Christmas" + 0.014*"will" + 0.013*"you" + 0.013*"show" + 0.009*"Lol" + 0.009*"Larry King Live"
TopicModeling: GENSIM Topic: 48 
Words: 0.024*"Paris" + 0.015*"Dealer Auction" + 0.014*"Live" + 0.010*"Un" + 0.010*"más" + 0.008*"Perú" + 0.008*"Sunroof" + 0.008*"del" + 0.007*"6cyl" + 0.007*"season"
TopicModeling: GENSIM Topic: 49 
Words: 0.019*"money" + 0.014*"WGCL" + 0.013*"Knicks" + 0.013*"Asia" + 0.008*"Kenya" + 0.008*"Human Rights" + 0.007*"wikileaks" + 0.006*"rise" + 0.006*"living" + 0.006*"assange"
TopicModeling: Coherences:

TopicModeling: Calculating model coherence:

Setting topics to those of the model: LdaModel(num_terms=49968, num_topics=50, decay=0.5, chunksize=2000)
CorpusAccumulator accumulated stats from 1000 documents
CorpusAccumulator accumulated stats from 2000 documents
CorpusAccumulator accumulated stats from 3000 documents
CorpusAccumulator accumulated stats from 4000 documents
CorpusAccumulator accumulated stats from 5000 documents
CorpusAccumulator accumulated stats from 6000 documents
CorpusAccumulator accumulated stats from 7000 documents
CorpusAccumulator accumulated stats from 8000 documents
CorpusAccumulator accumulated stats from 9000 documents
CorpusAccumulator accumulated stats from 10000 documents
CorpusAccumulator accumulated stats from 1000 documents
CorpusAccumulator accumulated stats from 2000 documents
CorpusAccumulator accumulated stats from 3000 documents
CorpusAccumulator accumulated stats from 4000 documents
CorpusAccumulator accumulated stats from 5000 documents
CorpusAccumulator accumulated stats from 6000 documents
CorpusAccumulator accumulated stats from 7000 documents
CorpusAccumulator accumulated stats from 8000 documents
CorpusAccumulator accumulated stats from 9000 documents
CorpusAccumulator accumulated stats from 10000 documents
TopicModeling: Coherence value is: -8.700144791142089
TopicModeling: Topic coherences are: [-8.773644712191501, -13.474367302402518, -7.104174360426038, -4.845388447029049, -7.003579618040485, -9.82117059457706, -4.038089150928853, -10.815569203240798, -1.4499539473254917, -1.6337525077307073, -13.222307910093544, -4.583365560280061, -8.248740276606535, -14.120333737282946, -4.233918543151326, -11.201442835721805, -2.0950326418831002, -14.799851137096145, -8.106323193481192, -1.6606830234362377, -5.12343083140164, -12.847792187884647, -1.2685168401592293, -2.2307542193383814, -10.927115686660235, -3.2006416364587222, -9.191767412839821, -6.360261576018113, -16.663115083604595, -11.366612179221587, -6.046765979466879, -11.990771144227242, -13.403539890479662, -6.582660819656626, -8.225833169543732, -3.0727756097427275, -13.94956644453787, -7.647339316922227, -11.480413401299824, -6.931271985481792, -8.98103376362331, -9.332300422215079, -13.459553927628836, -1.736091961905076, -1.2484770638463052, -3.6925364533597183, -9.603377664011665, -1.9405207613734117, -13.535157998049463, -11.323567820116768]
saving Dictionary object under ../output/55/tml/gensim_50topics_TopicModelingDictionary.mm, separately None
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'wb', 'uri': '../output/55/tml/gensim_50topics_TopicModelingDictionary.mm'}
saved ../output/55/tml/gensim_50topics_TopicModelingDictionary.mm
UserSimilarity: Topic modeling done
UserSimilarity: All users size 10788
UserSimilarity: All distinct users:10788
UserSimilarity: users_topic_interests=(10788, 50)
UserSimilarity: Just one topic? False, Binary topic? True, Threshold: 0.2
10788 users has twitted in 2010-12-17 00:00:00
UserSimilarity: 0 / 1
UserSimilarity: UsersTopicInterests.npy is saved for day:0 with shape: (10788, 50)
UsersGraph: There are 10788 users on 0
UserSimilarity: A graph is being created for 0 with 10788 users
UserSimilarity: Number of users per day: [10788]
UserSimilarity: Graphs created!
UserSimilarity: Graphs are written in "graphs" directory
Graph Clustering: Louvain clustering for ../output/55/uml/graphs\01.net
nodes: 10788 / edges: 2631833 / isolates: 147
Graph Clustering: Louvain clustering output: 184 clusters. 38 of them are multi-user clusters and rest of them (146) are singleton clusters.

Graph Clustering: Length of multi-user clusters: [995, 733, 656, 634, 535, 394, 384, 375, 370, 345, 343, 306, 273, 256, 246, 246, 222, 221, 217, 205, 205, 197, 192, 184, 182, 178, 173, 173, 154, 129, 127, 124, 124, 114, 110, 108, 108, 103]

Graph Clustering: UserClusters.npy saved.

Cluster 0 has 995 users. Topic 44 is the favorite topic for 32.562814070351756% of users.
Cluster 1 has 733 users. Topic 34 is the favorite topic for 24.965893587994543% of users.
Cluster 2 has 656 users. Topic 8 is the favorite topic for 70.57926829268293% of users.
Cluster 3 has 634 users. Topic 9 is the favorite topic for 55.99369085173501% of users.
Cluster 4 has 535 users. Topic 47 is the favorite topic for 39.626168224299064% of users.
Cluster 5 has 394 users. Topic 19 is the favorite topic for 75.88832487309645% of users.
Cluster 6 has 384 users. Topic 29 is the favorite topic for 63.541666666666664% of users.
Cluster 7 has 375 users. Topic 6 is the favorite topic for 47.199999999999996% of users.
Cluster 8 has 370 users. Topic 20 is the favorite topic for 44.32432432432433% of users.
Cluster 9 has 345 users. Topic 2 is the favorite topic for 70.43478260869566% of users.
Cluster 10 has 343 users. Topic 5 is the favorite topic for 52.1865889212828% of users.
Cluster 11 has 306 users. Topic 22 is the favorite topic for 80.06535947712419% of users.
Cluster 12 has 273 users. Topic 35 is the favorite topic for 63.73626373626373% of users.
Cluster 13 has 256 users. Topic 25 is the favorite topic for 71.875% of users.
Cluster 14 has 246 users. Topic 17 is the favorite topic for 84.14634146341463% of users.
Cluster 15 has 246 users. Topic 33 is the favorite topic for 65.85365853658537% of users.
Cluster 16 has 222 users. Topic 37 is the favorite topic for 53.6036036036036% of users.
Cluster 17 has 221 users. Topic 28 is the favorite topic for 79.63800904977376% of users.
Cluster 18 has 217 users. Topic 18 is the favorite topic for 88.0184331797235% of users.
Cluster 19 has 205 users. Topic 11 is the favorite topic for 93.17073170731707% of users.
Cluster 20 has 205 users. Topic 4 is the favorite topic for 58.536585365853654% of users.
Cluster 21 has 197 users. Topic 24 is the favorite topic for 86.80203045685279% of users.
Cluster 22 has 192 users. Topic 30 is the favorite topic for 74.47916666666666% of users.
Cluster 23 has 184 users. Topic 31 is the favorite topic for 84.23913043478261% of users.
Cluster 24 has 182 users. Topic 10 is the favorite topic for 95.05494505494505% of users.
Cluster 25 has 178 users. Topic 27 is the favorite topic for 83.14606741573034% of users.
Cluster 26 has 173 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 27 has 173 users. Topic 48 is the favorite topic for 79.1907514450867% of users.
Cluster 28 has 154 users. Topic 46 is the favorite topic for 87.01298701298701% of users.
Cluster 29 has 129 users. Topic 26 is the favorite topic for 94.57364341085271% of users.
Cluster 30 has 127 users. Topic 12 is the favorite topic for 95.2755905511811% of users.
Cluster 31 has 124 users. Topic 14 is the favorite topic for 92.74193548387096% of users.
Cluster 32 has 124 users. Topic 1 is the favorite topic for 100.0% of users.
Cluster 33 has 114 users. Topic 45 is the favorite topic for 91.22807017543859% of users.
Cluster 34 has 110 users. Topic 42 is the favorite topic for 97.27272727272728% of users.
Cluster 35 has 108 users. Topic 16 is the favorite topic for 96.29629629629629% of users.
Cluster 36 has 108 users. Topic 3 is the favorite topic for 100.0% of users.
Cluster 37 has 103 users. Topic 41 is the favorite topic for 95.14563106796116% of users.
Cluster 38 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 39 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 40 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 41 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 42 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 43 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 44 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 45 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 46 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 47 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 48 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 49 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 50 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 51 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 52 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 53 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 54 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 55 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 56 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 57 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 58 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 59 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 60 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 61 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 62 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 63 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 64 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 65 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 66 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 67 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 68 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 69 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 70 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 71 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 72 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 73 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 74 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 75 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 76 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 77 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 78 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 79 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 80 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 81 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 82 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 83 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 84 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 85 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 86 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 87 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 88 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 89 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 90 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 91 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 92 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 93 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 94 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 95 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 96 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 97 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 98 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 99 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 100 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 101 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 102 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 103 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 104 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 105 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 106 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 107 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 108 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 109 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 110 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 111 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 112 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 113 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 114 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 115 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 116 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 117 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 118 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 119 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 120 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 121 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 122 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 123 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 124 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 125 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 126 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 127 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 128 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 129 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 130 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 131 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 132 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 133 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 134 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 135 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 136 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 137 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 138 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 139 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 140 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 141 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 142 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 143 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 144 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 145 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 146 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 147 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 148 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 149 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 150 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 151 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 152 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 153 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 154 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 155 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 156 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 157 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 158 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 159 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 160 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 161 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 162 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 163 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 164 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 165 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 166 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 167 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 168 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 169 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 170 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 171 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 172 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 173 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 174 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 175 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 176 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 177 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 178 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 179 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 180 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 181 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 182 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 183 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
Cluster 184 has 1 users. Topic 0 is the favorite topic for 100.0% of users.
update_title_pos
update_title_pos

NewsTopicExtraction.py:

len(data) for news extraction query: 3446

loading Dictionary object from ../output/55/tml\gensim_50topics_TopicModelingDictionary.mm
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'rb', 'uri': '../output/55/tml\\gensim_50topics_TopicModelingDictionary.mm'}
loaded ../output/55/tml\gensim_50topics_TopicModelingDictionary.mm
model ../output/55/tml\gensim_50topics.model is loaded.
loading LdaModel object from ../output/55/tml\gensim_50topics.model
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'rb', 'uri': '../output/55/tml\\gensim_50topics.model'}
loading expElogbeta from ../output/55/tml\gensim_50topics.model.expElogbeta.npy with mmap=None
setting ignored attribute dispatcher to None
setting ignored attribute state to None
setting ignored attribute id2word to None
loaded ../output/55/tml\gensim_50topics.model
loading LdaState object from ../output/55/tml\gensim_50topics.model.state
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'rb', 'uri': '../output/55/tml\\gensim_50topics.model.state'}
loaded ../output/55/tml\gensim_50topics.model.state
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'rb', 'uri': '../output/55/tml\\gensim_50topics.model.id2word'}
Topics are extracted for news dataset based on the tweets extracted topics.


NewsRecommendation2.py:

loading LdaModel object from ../output/55/tml/gensim_50topics.model
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'rb', 'uri': '../output/55/tml/gensim_50topics.model'}
loading expElogbeta from ../output/55/tml/gensim_50topics.model.expElogbeta.npy with mmap=None
setting ignored attribute dispatcher to None
setting ignored attribute state to None
setting ignored attribute id2word to None
loaded ../output/55/tml/gensim_50topics.model
loading LdaState object from ../output/55/tml/gensim_50topics.model.state
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'rb', 'uri': '../output/55/tml/gensim_50topics.model.state'}
loaded ../output/55/tml/gensim_50topics.model.state
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'rb', 'uri': '../output/55/tml/gensim_50topics.model.id2word'}
update_title_pos
findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('C:\\Users\\sorou\\AppData\\Roaming\\Python\\Python36\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf\\DejaVuSans.ttf') with score of 0.050000.
update_title_pos
update_title_pos
update_title_pos
Shape of TopRecommendations: (38, 20)

ModelEvaluation.py:

Selected date for evaluation: 2010-12-17

User: Mentions:21225 / Missed Users:4863 / Mentioners:1446 / All Users:10788
User: total:26088 / sum:26088
update_title_pos
update_title_pos


Evaluation:

Evaluation: hits: 73
Evaluation: percentage: 0.050484094052558784
Evaluation: topK recommendations: 20
Evaluation: users: 10788
