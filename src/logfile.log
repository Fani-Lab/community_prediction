CACHEDIR=C:\Users\sorou\.matplotlib
Using fontManager instance from C:\Users\sorou\.matplotlib\fontlist-v330.json
Loaded backend module://backend_interagg version unknown.
Main: UserSimilarities ...
DataReader: Connection created
DataReader: 39968 rows returned
DataReader: Connection closed
DataPreperation: userModeling=True, timeModeling=True, preProcessing=False, TagME=False
DataPreperation: 10000 sampled from the end of dataset (sorted by creationTime)
DataPreperation: Length of the dataset after applying groupby: 2605 

UserSimilarity: Processed docs shape: (2605,)
UserSimilarity: Topic modeling ...
TopicModeling: num_topics=25,  filterExtremes=True, library=gensim
adding document #0 to Dictionary(0 unique tokens: [])
built Dictionary(13546 unique tokens: ['Assange', 'Guardian', 'Wikileaks', 'allegations', 'leaked']...) from 2605 documents (total 36941 corpus positions)
discarding 0 tokens: []...
keeping 13546 tokens which were in no less than 1 and no more than 521 (=20.0%) documents
rebuilding dictionary, shrinking gaps
resulting dictionary: Dictionary(13546 unique tokens: ['Assange', 'Guardian', 'Wikileaks', 'allegations', 'leaked']...)
using symmetric alpha at 0.04
using symmetric eta at 0.04
using serial LDA version on this node
running online (multi-pass) LDA training, 25 topics, 5 passes over the supplied corpus of 2605 documents, updating model once every 2000 documents, evaluating perplexity every 2605 documents, iterating 50x with a convergence threshold of 0.001000
too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy
PROGRESS: pass 0, at document #2000/2605
performing inference on a chunk of 2000 documents
1835/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 2605 documents
topic #4 (0.040): 0.008*"Escobedo" + 0.006*"Tibet" + 0.006*"center" + 0.006*"Marisela" + 0.006*"socialists" + 0.004*"leftist" + 0.004*"will" + 0.004*"US" + 0.003*"arrested" + 0.003*"Angelina Jolie"
topic #13 (0.040): 0.036*"BBC" + 0.004*"UK" + 0.003*"US" + 0.003*"Retweet" + 0.003*"Apple MacBook Air" + 0.003*"to win" + 0.003*"MacBook Air" + 0.003*"CNN" + 0.003*"China" + 0.003*"coffee"
topic #14 (0.040): 0.005*"skinny jeans" + 0.004*"tax" + 0.003*"Obama" + 0.003*"Marisela" + 0.003*"US" + 0.003*"Facebook" + 0.003*"time" + 0.003*"Christmas" + 0.003*"Escobedo" + 0.003*"will"
topic #21 (0.040): 0.003*"Care2" + 0.003*"work" + 0.003*"Obama" + 0.003*"starwars" + 0.002*"Michele Bachmann" + 0.002*"blog" + 0.002*"China" + 0.002*"Feds" + 0.002*"lifetime" + 0.002*"will"
topic #16 (0.040): 0.004*"gens" + 0.004*"will" + 0.004*"Senators" + 0.004*"Immigration" + 0.004*"Latino" + 0.003*"Immigration Bill" + 0.003*"out" + 0.003*"Press" + 0.003*"show" + 0.003*"Senate"
topic diff=18.631201, rho=1.000000
bound: at document #0
-19.359 per-word bound, 672495.9 perplexity estimate based on a held-out corpus of 605 documents with 11590 words
PROGRESS: pass 0, at document #2605/2605
performing inference on a chunk of 605 documents
596/605 documents converged within 50 iterations
updating topics
merging changes from 605 documents into a model of 2605 documents
topic #15 (0.040): 0.010*"Pakistan" + 0.010*"China" + 0.007*"U.S" + 0.007*"mom" + 0.007*"official" + 0.007*"made in China" + 0.007*"Leader" + 0.007*"Mexican" + 0.006*"will" + 0.005*"US"
topic #16 (0.040): 0.020*"Deal" + 0.010*"Hindu" + 0.008*"New York" + 0.008*"tax" + 0.007*"State" + 0.006*"Lady Gaga" + 0.005*"Today" + 0.004*"Dynamite!! 2010" + 0.004*"Sengoku" + 0.004*"Soul"
topic #13 (0.040): 0.025*"BBC" + 0.018*"to win" + 0.008*"China" + 0.007*"Media" + 0.007*"deal" + 0.006*"brand" + 0.006*"made in China" + 0.006*"US" + 0.005*"USA" + 0.005*"Retweet"
topic #1 (0.040): 0.012*"Dubai" + 0.010*"Palin" + 0.010*"McNabb" + 0.008*"Grossman" + 0.007*"Mike Shanahan" + 0.006*"obesity" + 0.006*"bench" + 0.006*"knw" + 0.006*"Talk" + 0.006*"Yes"
topic #24 (0.040): 0.014*"WikiLeaks" + 0.009*"US" + 0.008*"Pakistan" + 0.008*"Chavez" + 0.008*"CIA" + 0.007*"decree" + 0.007*"Venezuela" + 0.006*"time" + 0.006*"power" + 0.006*"lawmakers"
topic diff=1.429987, rho=0.707107
PROGRESS: pass 1, at document #2000/2605
performing inference on a chunk of 2000 documents
1993/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 2605 documents
topic #24 (0.040): 0.014*"WikiLeaks" + 0.010*"US" + 0.008*"Chavez" + 0.008*"Pakistan" + 0.007*"Venezuela" + 0.006*"decree" + 0.006*"power" + 0.006*"Assange" + 0.005*"lawmakers" + 0.005*"CIA"
topic #10 (0.040): 0.010*"NYC" + 0.009*"London" + 0.008*"out" + 0.007*"CIA" + 0.007*"Lol" + 0.006*"U.S" + 0.005*"Berlin" + 0.005*"today" + 0.004*"world" + 0.004*"FF"
topic #11 (0.040): 0.096*"Fundraising" + 0.095*"friends" + 0.012*"Music" + 0.009*"Las Vegas" + 0.006*"Captain Beefheart" + 0.004*"Blog" + 0.004*"Casino" + 0.004*"Money" + 0.004*"video" + 0.004*"will"
topic #18 (0.040): 0.071*"Family" + 0.009*"Christmas" + 0.006*"will" + 0.006*"tax" + 0.005*"LOL" + 0.005*"you" + 0.005*"video" + 0.004*"Knicks" + 0.004*"twitter" + 0.004*"friends"
topic #5 (0.040): 0.014*"ur" + 0.013*"lol" + 0.009*"God" + 0.008*"time" + 0.006*"LOL" + 0.006*"love" + 0.006*"photos" + 0.006*"think" + 0.006*"tweet" + 0.006*"President Obama"
topic diff=0.817265, rho=0.550273
bound: at document #0
-17.958 per-word bound, 254677.8 perplexity estimate based on a held-out corpus of 605 documents with 11590 words
PROGRESS: pass 1, at document #2605/2605
performing inference on a chunk of 605 documents
604/605 documents converged within 50 iterations
updating topics
merging changes from 605 documents into a model of 2605 documents
topic #6 (0.040): 0.033*"lol" + 0.016*"pf" + 0.012*"Captain Beefheart" + 0.011*"Government" + 0.009*"CARPE DIEM" + 0.009*"TV" + 0.009*"lmao" + 0.008*"dies" + 0.008*"SB" + 0.007*"Republicans"
topic #7 (0.040): 0.036*"Marisela" + 0.031*"Escobedo" + 0.021*"para" + 0.015*"un" + 0.011*"en" + 0.011*"hoy" + 0.010*"es" + 0.010*"la" + 0.009*"como" + 0.007*"al"
topic #21 (0.040): 0.023*"lifetime" + 0.008*"Business" + 0.007*"week" + 0.007*"tcot" + 0.007*"Michele Bachmann" + 0.006*"People" + 0.006*"Obama" + 0.005*"care" + 0.005*"practice" + 0.005*"canx"
topic #14 (0.040): 0.015*"Facebook" + 0.011*"sex" + 0.009*"Jesus" + 0.008*"missing" + 0.007*"lie" + 0.006*"fat" + 0.006*"servicing" + 0.006*"Bank of America" + 0.006*"Congressman" + 0.006*"mortgage"
topic #13 (0.040): 0.037*"BBC" + 0.021*"to win" + 0.008*"Wikileaks" + 0.008*"deal" + 0.008*"China" + 0.007*"Media" + 0.007*"US" + 0.007*"Madoff" + 0.006*"right" + 0.006*"Retweet"
topic diff=0.634514, rho=0.550273
PROGRESS: pass 2, at document #2000/2605
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 2605 documents
topic #22 (0.040): 0.014*"video" + 0.014*"YouTube" + 0.012*"prison" + 0.010*"Mexico" + 0.009*"GOP" + 0.009*"escape" + 0.009*"inmates" + 0.006*"support" + 0.005*"donate" + 0.005*"Haiti"
topic #3 (0.040): 0.014*"U.S" + 0.013*"terror" + 0.012*"threats" + 0.012*"Pakistan" + 0.012*"spy" + 0.008*"official" + 0.008*"recalls" + 0.008*"U.S. intelligence" + 0.008*"intelligence" + 0.008*"CIA"
topic #24 (0.040): 0.019*"WikiLeaks" + 0.013*"US" + 0.009*"Chavez" + 0.008*"Assange" + 0.008*"Venezuela" + 0.008*"Pakistan" + 0.008*"power" + 0.008*"decree" + 0.006*"lawmakers" + 0.006*"CIA"
topic #2 (0.040): 0.007*"Iran" + 0.007*"Christmas" + 0.007*"gens" + 0.005*"Android" + 0.004*"FF" + 0.004*"sanctions" + 0.004*"TV" + 0.004*"FarmVille" + 0.004*"for Dummies" + 0.004*"Oui"
topic #9 (0.040): 0.008*"lol" + 0.008*"Twitter" + 0.007*"weather" + 0.007*"Congress" + 0.005*"Knicks" + 0.005*"good" + 0.005*"re" + 0.005*"Heat" + 0.005*"charity" + 0.005*"who"
topic diff=0.403341, rho=0.482103
bound: at document #0
-17.749 per-word bound, 220226.2 perplexity estimate based on a held-out corpus of 605 documents with 11590 words
PROGRESS: pass 2, at document #2605/2605
performing inference on a chunk of 605 documents
604/605 documents converged within 50 iterations
updating topics
merging changes from 605 documents into a model of 2605 documents
topic #18 (0.040): 0.134*"Family" + 0.017*"Christmas" + 0.015*"Deal" + 0.010*"tax" + 0.007*"will" + 0.007*"LOL" + 0.007*"video" + 0.007*"you" + 0.005*"Photos" + 0.005*"if"
topic #21 (0.040): 0.023*"lifetime" + 0.010*"tcot" + 0.008*"Business" + 0.008*"Michele Bachmann" + 0.008*"week" + 0.008*"People" + 0.006*"Obama" + 0.006*"care" + 0.005*"practice" + 0.005*"Intelligence"
topic #5 (0.040): 0.028*"ur" + 0.015*"lol" + 0.015*"God" + 0.014*"time" + 0.014*"love" + 0.010*"tweet" + 0.008*"President Obama" + 0.007*"think" + 0.007*"photos" + 0.007*"water"
topic #12 (0.040): 0.026*"ONE LOVE" + 0.018*"UR" + 0.013*"Senate" + 0.010*"Obama" + 0.008*"Earth" + 0.007*"US" + 0.007*"Tron" + 0.006*"deal" + 0.006*"tax" + 0.006*"signs"
topic #11 (0.040): 0.176*"friends" + 0.167*"Fundraising" + 0.022*"Music" + 0.017*"Las Vegas" + 0.011*"tax" + 0.010*"Captain Beefheart" + 0.008*"Money" + 0.007*"Casino" + 0.006*"Don Van Vliet" + 0.006*"Blog"
topic diff=0.296564, rho=0.482103
PROGRESS: pass 3, at document #2000/2605
performing inference on a chunk of 2000 documents
1999/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 2605 documents
topic #9 (0.040): 0.008*"lol" + 0.008*"weather" + 0.008*"Twitter" + 0.007*"Congress" + 0.006*"re" + 0.006*"charity" + 0.006*"Knicks" + 0.006*"good" + 0.005*"me" + 0.005*"Heat"
topic #1 (0.040): 0.007*"Dubai" + 0.007*"Palin" + 0.006*"Mike Shanahan" + 0.006*"feed" + 0.006*"McNabb" + 0.006*"tweets" + 0.006*"swamp" + 0.005*"Eric Braeden" + 0.005*"Grossman" + 0.005*"diet"
topic #22 (0.040): 0.018*"YouTube" + 0.018*"video" + 0.012*"prison" + 0.011*"GOP" + 0.010*"Mexico" + 0.009*"escape" + 0.009*"inmates" + 0.007*"support" + 0.006*"donate" + 0.006*"today"
topic #4 (0.040): 0.017*"arrested" + 0.013*"security guard" + 0.013*"Boxer" + 0.013*"Floyd  Mayweather" + 0.013*"assault" + 0.012*"alleged" + 0.011*"Las Vegas" + 0.009*"este" + 0.009*"Tibet" + 0.008*"will"
topic #21 (0.040): 0.014*"lifetime" + 0.010*"tcot" + 0.009*"starwars" + 0.007*"Michele Bachmann" + 0.006*"People" + 0.006*"Obama" + 0.005*"blog" + 0.005*"British" + 0.005*"Business" + 0.005*"week"
topic diff=0.205575, rho=0.434270
bound: at document #0
-17.669 per-word bound, 208363.1 perplexity estimate based on a held-out corpus of 605 documents with 11590 words
PROGRESS: pass 3, at document #2605/2605
performing inference on a chunk of 605 documents
604/605 documents converged within 50 iterations
updating topics
merging changes from 605 documents into a model of 2605 documents
topic #12 (0.040): 0.025*"ONE LOVE" + 0.018*"UR" + 0.014*"Senate" + 0.011*"Obama" + 0.008*"Earth" + 0.007*"Tron" + 0.007*"US" + 0.006*"signs" + 0.006*"deal" + 0.006*"tax"
topic #15 (0.040): 0.023*"China" + 0.020*"Pakistan" + 0.015*"made in China" + 0.015*"USA" + 0.013*"U.S" + 0.012*"US" + 0.011*"official" + 0.011*"Mexican" + 0.009*"Mexico" + 0.009*"CIA"
topic #10 (0.040): 0.023*"NYC" + 0.023*"London" + 0.014*"Lol" + 0.010*"Berlin" + 0.010*"out" + 0.008*"world" + 0.007*"Thx" + 0.007*"money" + 0.007*"Lil Kim" + 0.007*"FF"
topic #8 (0.040): 0.036*"LP" + 0.032*"Haiti" + 0.010*"BP" + 0.009*"anger" + 0.009*"free" + 0.007*"now" + 0.007*"Onion" + 0.007*"tinderbox" + 0.006*"Korea" + 0.006*"billions"
topic #24 (0.040): 0.023*"WikiLeaks" + 0.015*"US" + 0.011*"Chavez" + 0.010*"Venezuela" + 0.009*"decree" + 0.009*"power" + 0.008*"torture" + 0.008*"lawmakers" + 0.008*"CIA" + 0.008*"govern"
topic diff=0.160231, rho=0.434270
PROGRESS: pass 4, at document #2000/2605
performing inference on a chunk of 2000 documents
2000/2000 documents converged within 50 iterations
updating topics
merging changes from 2000 documents into a model of 2605 documents
topic #23 (0.040): 0.015*"lol" + 0.010*"you" + 0.006*"who" + 0.005*"we" + 0.005*"American" + 0.005*"MUSIC" + 0.005*"will" + 0.005*"haha" + 0.005*"today" + 0.004*"ur"
topic #9 (0.040): 0.009*"Twitter" + 0.008*"lol" + 0.008*"weather" + 0.007*"Congress" + 0.007*"re" + 0.007*"charity" + 0.006*"Knicks" + 0.006*"me" + 0.006*"I'm" + 0.006*"Heat"
topic #11 (0.040): 0.129*"friends" + 0.117*"Fundraising" + 0.017*"Las Vegas" + 0.017*"Music" + 0.012*"Captain Beefheart" + 0.009*"tax" + 0.007*"Don Van Vliet" + 0.007*"Money" + 0.006*"Casino" + 0.005*"Dies"
topic #15 (0.040): 0.021*"China" + 0.019*"Pakistan" + 0.013*"U.S" + 0.013*"USA" + 0.013*"made in China" + 0.011*"US" + 0.010*"official" + 0.010*"Mexico" + 0.010*"Mexican" + 0.008*"inmates"
topic #16 (0.040): 0.007*"New York" + 0.006*"Yes" + 0.006*"State" + 0.006*"Hindu" + 0.006*"Today" + 0.006*"Senators" + 0.005*"United States" + 0.005*"Latino" + 0.005*"Press" + 0.005*"Top"
topic diff=0.124352, rho=0.398331
bound: at document #0
-17.626 per-word bound, 202335.9 perplexity estimate based on a held-out corpus of 605 documents with 11590 words
PROGRESS: pass 4, at document #2605/2605
performing inference on a chunk of 605 documents
605/605 documents converged within 50 iterations
updating topics
merging changes from 605 documents into a model of 2605 documents
topic #12 (0.040): 0.025*"ONE LOVE" + 0.017*"UR" + 0.014*"Senate" + 0.012*"Obama" + 0.008*"Earth" + 0.007*"Tron" + 0.006*"signs" + 0.006*"GOP" + 0.006*"tax" + 0.006*"deal"
topic #22 (0.040): 0.026*"video" + 0.025*"YouTube" + 0.012*"prison" + 0.012*"GOP" + 0.010*"Mexico" + 0.009*"escape" + 0.009*"inmates" + 0.009*"today" + 0.008*"donate" + 0.007*"support"
topic #13 (0.040): 0.046*"BBC" + 0.025*"to win" + 0.011*"Wikileaks" + 0.009*"deal" + 0.009*"Madoff" + 0.008*"US" + 0.008*"India" + 0.007*"Kashmir" + 0.006*"Media" + 0.006*"right"
topic #17 (0.040): 0.020*"Paris" + 0.018*"Wall Street" + 0.016*"Manhattan" + 0.011*"Art" + 0.010*"living" + 0.009*"Donovan McNabb" + 0.009*"Redskins" + 0.007*"today" + 0.007*"read" + 0.007*"Christmas"
topic #23 (0.040): 0.018*"lol" + 0.014*"you" + 0.009*"we" + 0.008*"MUSIC" + 0.007*"will" + 0.007*"who" + 0.006*"American" + 0.006*"blah" + 0.005*"things" + 0.005*"ur"
topic diff=0.104555, rho=0.398331
saving LdaState object under ../output/60/tml/gensim_25topics.model.state, separately None
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'wb', 'uri': '../output/60/tml/gensim_25topics.model.state'}
saved ../output/60/tml/gensim_25topics.model.state
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'wb', 'uri': '../output/60/tml/gensim_25topics.model.id2word'}
saving LdaModel object under ../output/60/tml/gensim_25topics.model, separately ['expElogbeta', 'sstats']
storing np array 'expElogbeta' to ../output/60/tml/gensim_25topics.model.expElogbeta.npy
not storing attribute id2word
not storing attribute dispatcher
not storing attribute state
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'wb', 'uri': '../output/60/tml/gensim_25topics.model'}
saved ../output/60/tml/gensim_25topics.model
topic #0 (0.040): 0.013*"TV" + 0.012*"Blog" + 0.010*"Christmas" + 0.008*"good" + 0.007*"day" + 0.007*"Merry Christmas" + 0.006*"will" + 0.006*"single" + 0.006*"person" + 0.006*"Santa"
topic #1 (0.040): 0.012*"Dubai" + 0.010*"Palin" + 0.010*"Mike Shanahan" + 0.009*"McNabb" + 0.008*"Grossman" + 0.006*"obesity" + 0.006*"Rex Grossman" + 0.006*"Talk" + 0.006*"bench" + 0.006*"knw"
topic #2 (0.040): 0.007*"sanctions" + 0.007*"Christmas" + 0.007*"Android" + 0.006*"pour" + 0.006*"French" + 0.006*"resignation" + 0.006*"FF" + 0.006*"Journalist" + 0.006*"Kiss" + 0.006*"TV"
topic #3 (0.040): 0.017*"terror" + 0.017*"Pakistan" + 0.017*"U.S" + 0.016*"threats" + 0.016*"spy" + 0.011*"CIA" + 0.011*"official" + 0.011*"If" + 0.011*"recalls" + 0.011*"U.S. intelligence"
topic #4 (0.040): 0.018*"arrested" + 0.016*"Boxer" + 0.016*"Floyd  Mayweather" + 0.016*"assault" + 0.015*"este" + 0.015*"security guard" + 0.014*"Las Vegas" + 0.014*"alleged" + 0.010*"will" + 0.008*"mean"
topic #5 (0.040): 0.030*"ur" + 0.018*"time" + 0.016*"God" + 0.015*"love" + 0.012*"lol" + 0.011*"tweet" + 0.008*"President Obama" + 0.007*"photos" + 0.007*"children" + 0.007*"water"
topic #6 (0.040): 0.034*"lol" + 0.020*"pf" + 0.013*"Captain Beefheart" + 0.012*"CARPE DIEM" + 0.011*"Government" + 0.010*"dies" + 0.009*"lmao" + 0.008*"SB" + 0.008*"aged" + 0.008*"Republicans"
topic #7 (0.040): 0.040*"Marisela" + 0.036*"Escobedo" + 0.025*"para" + 0.019*"un" + 0.012*"como" + 0.011*"la" + 0.011*"en" + 0.010*"hoy" + 0.009*"es" + 0.008*"Venezuela"
topic #8 (0.040): 0.037*"LP" + 0.033*"Haiti" + 0.010*"BP" + 0.009*"free" + 0.009*"anger" + 0.008*"now" + 0.007*"tinderbox" + 0.007*"Korea" + 0.007*"Onion" + 0.006*"Sudan"
topic #9 (0.040): 0.011*"Twitter" + 0.011*"weather" + 0.011*"re" + 0.010*"lol" + 0.010*"charity" + 0.008*"me" + 0.008*"Congress" + 0.007*"I'm" + 0.007*"pretty" + 0.007*"good"
topic #10 (0.040): 0.023*"NYC" + 0.022*"London" + 0.014*"Lol" + 0.010*"Berlin" + 0.010*"out" + 0.008*"world" + 0.008*"money" + 0.007*"Thx" + 0.007*"Lil Kim" + 0.007*"UK"
topic #11 (0.040): 0.174*"friends" + 0.161*"Fundraising" + 0.022*"Music" + 0.020*"Las Vegas" + 0.014*"tax" + 0.013*"Captain Beefheart" + 0.008*"Money" + 0.007*"Don Van Vliet" + 0.006*"Casino" + 0.006*"Cosmopolitan"
topic #12 (0.040): 0.025*"ONE LOVE" + 0.017*"UR" + 0.014*"Senate" + 0.012*"Obama" + 0.008*"Earth" + 0.007*"Tron" + 0.006*"signs" + 0.006*"GOP" + 0.006*"tax" + 0.006*"deal"
topic #13 (0.040): 0.046*"BBC" + 0.025*"to win" + 0.011*"Wikileaks" + 0.009*"deal" + 0.009*"Madoff" + 0.008*"US" + 0.008*"India" + 0.007*"Kashmir" + 0.006*"Media" + 0.006*"right"
topic #14 (0.040): 0.020*"Facebook" + 0.011*"sex" + 0.011*"first" + 0.011*"Jesus" + 0.007*"missing" + 0.007*"Bank of America" + 0.007*"mortgage" + 0.006*"video" + 0.006*"servicing" + 0.006*"Congressman"
topic #15 (0.040): 0.024*"China" + 0.021*"Pakistan" + 0.016*"made in China" + 0.015*"USA" + 0.014*"U.S" + 0.012*"US" + 0.011*"Mexican" + 0.011*"official" + 0.010*"CIA" + 0.010*"Mexico"
topic #16 (0.040): 0.010*"State" + 0.010*"Hindu" + 0.009*"New York" + 0.009*"Yes" + 0.007*"Today" + 0.007*"United States" + 0.006*"Lady Gaga" + 0.005*"Ur" + 0.005*"gay" + 0.005*"Computer"
topic #17 (0.040): 0.020*"Paris" + 0.018*"Wall Street" + 0.016*"Manhattan" + 0.011*"Art" + 0.010*"living" + 0.009*"Donovan McNabb" + 0.009*"Redskins" + 0.007*"today" + 0.007*"read" + 0.007*"Christmas"
topic #18 (0.040): 0.131*"Family" + 0.019*"Christmas" + 0.016*"Deal" + 0.008*"tax" + 0.008*"LOL" + 0.007*"will" + 0.006*"you" + 0.006*"video" + 0.006*"love" + 0.005*"Photos"
topic #19 (0.040): 0.009*"bill" + 0.008*"Tax" + 0.008*"working" + 0.007*"dies" + 0.006*"asap" + 0.006*"NBC" + 0.006*"Live" + 0.006*"South Korea" + 0.006*"Christmas" + 0.006*"Africa"
topic #20 (0.040): 0.019*"Vegas" + 0.009*"Artist" + 0.008*"NFL" + 0.007*"tienen" + 0.007*"play" + 0.007*"Rome" + 0.006*"who" + 0.006*"One" + 0.005*"actor" + 0.005*"Holiday"
topic #21 (0.040): 0.022*"lifetime" + 0.014*"tcot" + 0.009*"People" + 0.008*"Michele Bachmann" + 0.008*"Business" + 0.008*"week" + 0.007*"Obama" + 0.006*"Company" + 0.006*"Intelligence" + 0.006*"blog"
topic #22 (0.040): 0.026*"video" + 0.025*"YouTube" + 0.012*"prison" + 0.012*"GOP" + 0.010*"Mexico" + 0.009*"escape" + 0.009*"inmates" + 0.009*"today" + 0.008*"donate" + 0.007*"support"
topic #23 (0.040): 0.018*"lol" + 0.014*"you" + 0.009*"we" + 0.008*"MUSIC" + 0.007*"will" + 0.007*"who" + 0.006*"American" + 0.006*"blah" + 0.005*"things" + 0.005*"ur"
topic #24 (0.040): 0.024*"WikiLeaks" + 0.016*"US" + 0.010*"Chavez" + 0.009*"Venezuela" + 0.009*"decree" + 0.009*"power" + 0.009*"Assange" + 0.008*"torture" + 0.008*"lawmakers" + 0.008*"govern"
TopicModeling: GENSIM Topic: 0 
Words: 0.013*"TV" + 0.012*"Blog" + 0.010*"Christmas" + 0.008*"good" + 0.007*"day" + 0.007*"Merry Christmas" + 0.006*"will" + 0.006*"single" + 0.006*"person" + 0.006*"Santa"
TopicModeling: GENSIM Topic: 1 
Words: 0.012*"Dubai" + 0.010*"Palin" + 0.010*"Mike Shanahan" + 0.009*"McNabb" + 0.008*"Grossman" + 0.006*"obesity" + 0.006*"Rex Grossman" + 0.006*"Talk" + 0.006*"bench" + 0.006*"knw"
TopicModeling: GENSIM Topic: 2 
Words: 0.007*"sanctions" + 0.007*"Christmas" + 0.007*"Android" + 0.006*"pour" + 0.006*"French" + 0.006*"resignation" + 0.006*"FF" + 0.006*"Journalist" + 0.006*"Kiss" + 0.006*"TV"
TopicModeling: GENSIM Topic: 3 
Words: 0.017*"terror" + 0.017*"Pakistan" + 0.017*"U.S" + 0.016*"threats" + 0.016*"spy" + 0.011*"CIA" + 0.011*"official" + 0.011*"If" + 0.011*"recalls" + 0.011*"U.S. intelligence"
TopicModeling: GENSIM Topic: 4 
Words: 0.018*"arrested" + 0.016*"Boxer" + 0.016*"Floyd  Mayweather" + 0.016*"assault" + 0.015*"este" + 0.015*"security guard" + 0.014*"Las Vegas" + 0.014*"alleged" + 0.010*"will" + 0.008*"mean"
TopicModeling: GENSIM Topic: 5 
Words: 0.030*"ur" + 0.018*"time" + 0.016*"God" + 0.015*"love" + 0.012*"lol" + 0.011*"tweet" + 0.008*"President Obama" + 0.007*"photos" + 0.007*"children" + 0.007*"water"
TopicModeling: GENSIM Topic: 6 
Words: 0.034*"lol" + 0.020*"pf" + 0.013*"Captain Beefheart" + 0.012*"CARPE DIEM" + 0.011*"Government" + 0.010*"dies" + 0.009*"lmao" + 0.008*"SB" + 0.008*"aged" + 0.008*"Republicans"
TopicModeling: GENSIM Topic: 7 
Words: 0.040*"Marisela" + 0.036*"Escobedo" + 0.025*"para" + 0.019*"un" + 0.012*"como" + 0.011*"la" + 0.011*"en" + 0.010*"hoy" + 0.009*"es" + 0.008*"Venezuela"
TopicModeling: GENSIM Topic: 8 
Words: 0.037*"LP" + 0.033*"Haiti" + 0.010*"BP" + 0.009*"free" + 0.009*"anger" + 0.008*"now" + 0.007*"tinderbox" + 0.007*"Korea" + 0.007*"Onion" + 0.006*"Sudan"
TopicModeling: GENSIM Topic: 9 
Words: 0.011*"Twitter" + 0.011*"weather" + 0.011*"re" + 0.010*"lol" + 0.010*"charity" + 0.008*"me" + 0.008*"Congress" + 0.007*"I'm" + 0.007*"pretty" + 0.007*"good"
TopicModeling: GENSIM Topic: 10 
Words: 0.023*"NYC" + 0.022*"London" + 0.014*"Lol" + 0.010*"Berlin" + 0.010*"out" + 0.008*"world" + 0.008*"money" + 0.007*"Thx" + 0.007*"Lil Kim" + 0.007*"UK"
TopicModeling: GENSIM Topic: 11 
Words: 0.174*"friends" + 0.161*"Fundraising" + 0.022*"Music" + 0.020*"Las Vegas" + 0.014*"tax" + 0.013*"Captain Beefheart" + 0.008*"Money" + 0.007*"Don Van Vliet" + 0.006*"Casino" + 0.006*"Cosmopolitan"
TopicModeling: GENSIM Topic: 12 
Words: 0.025*"ONE LOVE" + 0.017*"UR" + 0.014*"Senate" + 0.012*"Obama" + 0.008*"Earth" + 0.007*"Tron" + 0.006*"signs" + 0.006*"GOP" + 0.006*"tax" + 0.006*"deal"
TopicModeling: GENSIM Topic: 13 
Words: 0.046*"BBC" + 0.025*"to win" + 0.011*"Wikileaks" + 0.009*"deal" + 0.009*"Madoff" + 0.008*"US" + 0.008*"India" + 0.007*"Kashmir" + 0.006*"Media" + 0.006*"right"
TopicModeling: GENSIM Topic: 14 
Words: 0.020*"Facebook" + 0.011*"sex" + 0.011*"first" + 0.011*"Jesus" + 0.007*"missing" + 0.007*"Bank of America" + 0.007*"mortgage" + 0.006*"video" + 0.006*"servicing" + 0.006*"Congressman"
TopicModeling: GENSIM Topic: 15 
Words: 0.024*"China" + 0.021*"Pakistan" + 0.016*"made in China" + 0.015*"USA" + 0.014*"U.S" + 0.012*"US" + 0.011*"Mexican" + 0.011*"official" + 0.010*"CIA" + 0.010*"Mexico"
TopicModeling: GENSIM Topic: 16 
Words: 0.010*"State" + 0.010*"Hindu" + 0.009*"New York" + 0.009*"Yes" + 0.007*"Today" + 0.007*"United States" + 0.006*"Lady Gaga" + 0.005*"Ur" + 0.005*"gay" + 0.005*"Computer"
TopicModeling: GENSIM Topic: 17 
Words: 0.020*"Paris" + 0.018*"Wall Street" + 0.016*"Manhattan" + 0.011*"Art" + 0.010*"living" + 0.009*"Donovan McNabb" + 0.009*"Redskins" + 0.007*"today" + 0.007*"read" + 0.007*"Christmas"
TopicModeling: GENSIM Topic: 18 
Words: 0.131*"Family" + 0.019*"Christmas" + 0.016*"Deal" + 0.008*"tax" + 0.008*"LOL" + 0.007*"will" + 0.006*"you" + 0.006*"video" + 0.006*"love" + 0.005*"Photos"
TopicModeling: GENSIM Topic: 19 
Words: 0.009*"bill" + 0.008*"Tax" + 0.008*"working" + 0.007*"dies" + 0.006*"asap" + 0.006*"NBC" + 0.006*"Live" + 0.006*"South Korea" + 0.006*"Christmas" + 0.006*"Africa"
TopicModeling: GENSIM Topic: 20 
Words: 0.019*"Vegas" + 0.009*"Artist" + 0.008*"NFL" + 0.007*"tienen" + 0.007*"play" + 0.007*"Rome" + 0.006*"who" + 0.006*"One" + 0.005*"actor" + 0.005*"Holiday"
TopicModeling: GENSIM Topic: 21 
Words: 0.022*"lifetime" + 0.014*"tcot" + 0.009*"People" + 0.008*"Michele Bachmann" + 0.008*"Business" + 0.008*"week" + 0.007*"Obama" + 0.006*"Company" + 0.006*"Intelligence" + 0.006*"blog"
TopicModeling: GENSIM Topic: 22 
Words: 0.026*"video" + 0.025*"YouTube" + 0.012*"prison" + 0.012*"GOP" + 0.010*"Mexico" + 0.009*"escape" + 0.009*"inmates" + 0.009*"today" + 0.008*"donate" + 0.007*"support"
TopicModeling: GENSIM Topic: 23 
Words: 0.018*"lol" + 0.014*"you" + 0.009*"we" + 0.008*"MUSIC" + 0.007*"will" + 0.007*"who" + 0.006*"American" + 0.006*"blah" + 0.005*"things" + 0.005*"ur"
TopicModeling: GENSIM Topic: 24 
Words: 0.024*"WikiLeaks" + 0.016*"US" + 0.010*"Chavez" + 0.009*"Venezuela" + 0.009*"decree" + 0.009*"power" + 0.009*"Assange" + 0.008*"torture" + 0.008*"lawmakers" + 0.008*"govern"
TopicModeling: Coherences:

TopicModeling: Calculating model coherence:

Setting topics to those of the model: LdaModel(num_terms=13546, num_topics=25, decay=0.5, chunksize=2000)
CorpusAccumulator accumulated stats from 1000 documents
CorpusAccumulator accumulated stats from 2000 documents
CorpusAccumulator accumulated stats from 1000 documents
CorpusAccumulator accumulated stats from 2000 documents
TopicModeling: Coherence value is: -11.53286562528365
TopicModeling: Topic coherences are: [-4.048858538058094, -16.373132319392937, -16.888451015562673, -1.198925192926024, -8.015586638460958, -4.403885819432217, -13.695913409814658, -2.645501529400944, -12.556463916400718, -7.815047293128805, -13.290526681314306, -5.57561317304738, -7.157348391001662, -7.022236486523594, -12.998295717407713, -1.4267019925649953, -16.018043422226473, -13.214851934316119, -3.591576916935841, -12.956272797905305, -17.2899516596571, -12.591491211044657, -9.739321940778849, -6.224064510059029, -3.3367087940573072]
saving Dictionary object under ../output/60/tml/gensim_25topics_TopicModelingDictionary.mm, separately None
{'transport_params': None, 'ignore_ext': False, 'opener': None, 'closefd': True, 'newline': None, 'errors': None, 'encoding': None, 'buffering': -1, 'mode': 'wb', 'uri': '../output/60/tml/gensim_25topics_TopicModelingDictionary.mm'}
saved ../output/60/tml/gensim_25topics_TopicModelingDictionary.mm
UserSimilarity: Topic modeling done
UserSimilarity: All users size 2605
UserSimilarity: All distinct users:2605
UserSimilarity: users_topic_interests=(2605, 25)
UserSimilarity: Just one topic? False, Binary topic? True, Threshold: 0.2
2605 users has twitted in 2010-12-17 00:00:00
